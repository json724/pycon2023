{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhjcHL/mKLCUXKTE+nG5NX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7725046e9c349d0a8ad0c08094c77d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2c79311cb8d44f294078ce0a4516468",
              "IPY_MODEL_82ae4c64639644d3bcc13dda73920566",
              "IPY_MODEL_a4ae18eea3074337bd5599a900c80099"
            ],
            "layout": "IPY_MODEL_b4d7e2925ad442c1a28b7bd8b45af6f0"
          }
        },
        "d2c79311cb8d44f294078ce0a4516468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6971668e781f4714bf0bc8dd9f78ac7c",
            "placeholder": "​",
            "style": "IPY_MODEL_fa24311c0426492ba3d64b7944466e61",
            "value": "Downloading (…)e9125/.gitattributes: 100%"
          }
        },
        "82ae4c64639644d3bcc13dda73920566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cefd48f8d96e4360b3a81374448c3f0c",
            "max": 1175,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75b1be251d1b483eb872cd617a0a1a8f",
            "value": 1175
          }
        },
        "a4ae18eea3074337bd5599a900c80099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2665694a2e7e4fecb501b907f6210f74",
            "placeholder": "​",
            "style": "IPY_MODEL_fb0fe6af8a61419e93d89b9e2dcb5d54",
            "value": " 1.18k/1.18k [00:00&lt;00:00, 80.5kB/s]"
          }
        },
        "b4d7e2925ad442c1a28b7bd8b45af6f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6971668e781f4714bf0bc8dd9f78ac7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa24311c0426492ba3d64b7944466e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cefd48f8d96e4360b3a81374448c3f0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b1be251d1b483eb872cd617a0a1a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2665694a2e7e4fecb501b907f6210f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb0fe6af8a61419e93d89b9e2dcb5d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66c94d08bd5447a6bd11c752ce4fa609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b9f655d55ae460dbb059e06c4d5a4f2",
              "IPY_MODEL_baa0db6980e6413f971aae428ba56003",
              "IPY_MODEL_4f62814e5bbc47c1936e952a54fb0765"
            ],
            "layout": "IPY_MODEL_ed1453a1b471477aa829bcc9597b56a2"
          }
        },
        "3b9f655d55ae460dbb059e06c4d5a4f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f40283483fc450292e998650fee3d4b",
            "placeholder": "​",
            "style": "IPY_MODEL_bf678d576426446a855ee6ebc371b28b",
            "value": "Downloading (…)_Pooling/config.json: 100%"
          }
        },
        "baa0db6980e6413f971aae428ba56003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bd1a18b400a430cb182af219b85989c",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6744d3c0309345a684ece2dc321022ea",
            "value": 190
          }
        },
        "4f62814e5bbc47c1936e952a54fb0765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd4bcde6c9794284a234be576bbfcdff",
            "placeholder": "​",
            "style": "IPY_MODEL_5d62bf985d6f4d1090dd4b96d562691b",
            "value": " 190/190 [00:00&lt;00:00, 15.9kB/s]"
          }
        },
        "ed1453a1b471477aa829bcc9597b56a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f40283483fc450292e998650fee3d4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf678d576426446a855ee6ebc371b28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bd1a18b400a430cb182af219b85989c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6744d3c0309345a684ece2dc321022ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd4bcde6c9794284a234be576bbfcdff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d62bf985d6f4d1090dd4b96d562691b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6fba38d6d5f4a3db94d6722cec99da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93648fc402fc47d0a91848e910bc93c9",
              "IPY_MODEL_c305636ef93d4b489aa363238fd9fabf",
              "IPY_MODEL_19403e00193b47de96e4374ee543183f"
            ],
            "layout": "IPY_MODEL_3284408d329147caa83671f5c65a12c9"
          }
        },
        "93648fc402fc47d0a91848e910bc93c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb01333d1e904957ae8c832cd7324cb9",
            "placeholder": "​",
            "style": "IPY_MODEL_bbda2327904d40cdb5b54122296467ad",
            "value": "Downloading (…)7e55de9125/README.md: 100%"
          }
        },
        "c305636ef93d4b489aa363238fd9fabf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ee8f012e7474a32bdf5fca371bc1b25",
            "max": 10610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fca04c2ff4fb40a68c4dbe802b9167a5",
            "value": 10610
          }
        },
        "19403e00193b47de96e4374ee543183f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9a662ef78804baa9e434e489ec8cad2",
            "placeholder": "​",
            "style": "IPY_MODEL_49e3e2638f8a48d2bf0f4e4533a4daba",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 702kB/s]"
          }
        },
        "3284408d329147caa83671f5c65a12c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb01333d1e904957ae8c832cd7324cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbda2327904d40cdb5b54122296467ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ee8f012e7474a32bdf5fca371bc1b25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fca04c2ff4fb40a68c4dbe802b9167a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9a662ef78804baa9e434e489ec8cad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49e3e2638f8a48d2bf0f4e4533a4daba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81769f55edab4afd862d99a10a316cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4920fed905584029b215123ff0adb1c7",
              "IPY_MODEL_62fddd129cab4a04b5bb7ab0e90d1d95",
              "IPY_MODEL_8de9b33a00ab451fbbd09ee704697f05"
            ],
            "layout": "IPY_MODEL_45e2ad9d2c03477cb9b62c41b59b2f5a"
          }
        },
        "4920fed905584029b215123ff0adb1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae006f3ba55b487c97890d511a911cd4",
            "placeholder": "​",
            "style": "IPY_MODEL_8ad11d49086c4431bbe70d9ce30a4370",
            "value": "Downloading (…)55de9125/config.json: 100%"
          }
        },
        "62fddd129cab4a04b5bb7ab0e90d1d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0e92a4b9f47420bbf49ee89f81c22c0",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32185cd0a899445b911e50b43d081eb0",
            "value": 612
          }
        },
        "8de9b33a00ab451fbbd09ee704697f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ded271f69704dc281740de57f24b40e",
            "placeholder": "​",
            "style": "IPY_MODEL_15e8cf0d496c4393bb49961be840f7c2",
            "value": " 612/612 [00:00&lt;00:00, 37.1kB/s]"
          }
        },
        "45e2ad9d2c03477cb9b62c41b59b2f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae006f3ba55b487c97890d511a911cd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad11d49086c4431bbe70d9ce30a4370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0e92a4b9f47420bbf49ee89f81c22c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32185cd0a899445b911e50b43d081eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ded271f69704dc281740de57f24b40e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15e8cf0d496c4393bb49961be840f7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b4f13fdd39242a8b1b6e99d0529073f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd774274bad44619bcf7304c58c7572d",
              "IPY_MODEL_53298433ae434666b4bf75498b7036d0",
              "IPY_MODEL_1d03255e80d54cbaad136f847ba420e2"
            ],
            "layout": "IPY_MODEL_e139202777a14fb1b902add336366796"
          }
        },
        "cd774274bad44619bcf7304c58c7572d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bac459a660b4e75be0b3e7844f41bcc",
            "placeholder": "​",
            "style": "IPY_MODEL_cbdbe05177e94226b4333262d30a9166",
            "value": "Downloading (…)ce_transformers.json: 100%"
          }
        },
        "53298433ae434666b4bf75498b7036d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c1a0beda1034a628ea1bf3743e87b57",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10be183ca5de4440886c1a959e41434d",
            "value": 116
          }
        },
        "1d03255e80d54cbaad136f847ba420e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3bbf326a2ec430284bc159b2722c65d",
            "placeholder": "​",
            "style": "IPY_MODEL_4709bc17e8e344a8ac6a418deec7995c",
            "value": " 116/116 [00:00&lt;00:00, 8.51kB/s]"
          }
        },
        "e139202777a14fb1b902add336366796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bac459a660b4e75be0b3e7844f41bcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbdbe05177e94226b4333262d30a9166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c1a0beda1034a628ea1bf3743e87b57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10be183ca5de4440886c1a959e41434d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3bbf326a2ec430284bc159b2722c65d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4709bc17e8e344a8ac6a418deec7995c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b27c0d1ff464297aaaf90229594b9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9dc582ac37f442adaa00f53170b394c6",
              "IPY_MODEL_ebc7f758b079443a94684eecc1d73f5c",
              "IPY_MODEL_bcd2caea17df405fbbee4fdaee98a230"
            ],
            "layout": "IPY_MODEL_c0411fd8d6e2419fbaf1b69172fae707"
          }
        },
        "9dc582ac37f442adaa00f53170b394c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b769dcd13bb4ac3bcdc0a095ff1a835",
            "placeholder": "​",
            "style": "IPY_MODEL_057d5a2a20094b5cb3bab9fddf0d1873",
            "value": "Downloading (…)125/data_config.json: 100%"
          }
        },
        "ebc7f758b079443a94684eecc1d73f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d47fc4f4d4446f6ad39817d06d83c46",
            "max": 39265,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_175a6340e01340549a6c19bd1e86804e",
            "value": 39265
          }
        },
        "bcd2caea17df405fbbee4fdaee98a230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b398541e2a904d409092b586877ed002",
            "placeholder": "​",
            "style": "IPY_MODEL_ca9730acdf9946db8cb25134a40b8a47",
            "value": " 39.3k/39.3k [00:00&lt;00:00, 1.88MB/s]"
          }
        },
        "c0411fd8d6e2419fbaf1b69172fae707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b769dcd13bb4ac3bcdc0a095ff1a835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "057d5a2a20094b5cb3bab9fddf0d1873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d47fc4f4d4446f6ad39817d06d83c46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175a6340e01340549a6c19bd1e86804e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b398541e2a904d409092b586877ed002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca9730acdf9946db8cb25134a40b8a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86d3b3d9ab304e1a9356bdd76e1b8a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2214cf97cd814d0297abc6776a969843",
              "IPY_MODEL_f2cf06bb0ee7498990b9d71eff4f1b7e",
              "IPY_MODEL_71de75ebcb104d80b07c2028fec2a463"
            ],
            "layout": "IPY_MODEL_29ff56b1159149238a73d653fa14945a"
          }
        },
        "2214cf97cd814d0297abc6776a969843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b155d498dc24e1b8168672ddeffd11f",
            "placeholder": "​",
            "style": "IPY_MODEL_934cf236b8a144629b2747989cac93f5",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "f2cf06bb0ee7498990b9d71eff4f1b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd2f753824ee413a966ddddd1d087475",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e28d993f288c4b7a85c7639504135af3",
            "value": 90888945
          }
        },
        "71de75ebcb104d80b07c2028fec2a463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2401e6276c3f43c9beb2d84fefac5417",
            "placeholder": "​",
            "style": "IPY_MODEL_34051f9f44a74a76acc485c19ea4d6ac",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 191MB/s]"
          }
        },
        "29ff56b1159149238a73d653fa14945a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b155d498dc24e1b8168672ddeffd11f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "934cf236b8a144629b2747989cac93f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd2f753824ee413a966ddddd1d087475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28d993f288c4b7a85c7639504135af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2401e6276c3f43c9beb2d84fefac5417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34051f9f44a74a76acc485c19ea4d6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0415aa9f75ba49c8ac12573c540fa6d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ca2f04afdad49a7a7a21049b90f2da3",
              "IPY_MODEL_f1599e3572b24232939082dba77ce9cb",
              "IPY_MODEL_faaefb602ac04d03937aa7119bf4992e"
            ],
            "layout": "IPY_MODEL_a32389fe8f7a4f07af04e908a66cc2f3"
          }
        },
        "9ca2f04afdad49a7a7a21049b90f2da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ee77023f9694d8d844a5490c6f3bbf3",
            "placeholder": "​",
            "style": "IPY_MODEL_932e9b5af41c4fc28ec4bc81b11b9b1d",
            "value": "Downloading (…)nce_bert_config.json: 100%"
          }
        },
        "f1599e3572b24232939082dba77ce9cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95b1e2d0e2e44581821cfba578dea7a7",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93b77b703afc49b8bba75e53f29aa8ad",
            "value": 53
          }
        },
        "faaefb602ac04d03937aa7119bf4992e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eaf40df4b0f473eab472c4b9372472e",
            "placeholder": "​",
            "style": "IPY_MODEL_1273fde65ad94e2696ec415a01416394",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.75kB/s]"
          }
        },
        "a32389fe8f7a4f07af04e908a66cc2f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ee77023f9694d8d844a5490c6f3bbf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "932e9b5af41c4fc28ec4bc81b11b9b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95b1e2d0e2e44581821cfba578dea7a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93b77b703afc49b8bba75e53f29aa8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2eaf40df4b0f473eab472c4b9372472e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1273fde65ad94e2696ec415a01416394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa47f32514044ba396dd29796d5c4605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_552c2a7da502454db6ed87cf0f031eaf",
              "IPY_MODEL_752c0d1bd7444a8ca7519b7a933e3152",
              "IPY_MODEL_ef2fc71322b24d52b40d00e2918506a3"
            ],
            "layout": "IPY_MODEL_2749684b7cf4409ea3047ac8a91b05cf"
          }
        },
        "552c2a7da502454db6ed87cf0f031eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_885241aeb23f45869e3f953cacf3ca07",
            "placeholder": "​",
            "style": "IPY_MODEL_0d457d6eccf046f68cb424842d381b86",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "752c0d1bd7444a8ca7519b7a933e3152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_245388a5367e400ea8948e779e8c5f2f",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ffbd6d479a04ec3b0e7e7f5693e478c",
            "value": 112
          }
        },
        "ef2fc71322b24d52b40d00e2918506a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b426508b405b4d39ac77fa9ba86d48e1",
            "placeholder": "​",
            "style": "IPY_MODEL_10ce1af01c554ee1858ae01b61d7df45",
            "value": " 112/112 [00:00&lt;00:00, 8.86kB/s]"
          }
        },
        "2749684b7cf4409ea3047ac8a91b05cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "885241aeb23f45869e3f953cacf3ca07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d457d6eccf046f68cb424842d381b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "245388a5367e400ea8948e779e8c5f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ffbd6d479a04ec3b0e7e7f5693e478c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b426508b405b4d39ac77fa9ba86d48e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ce1af01c554ee1858ae01b61d7df45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4342b2f5fda4ed9a29ab875e1c62c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a30073c099649bd975d6783fd59fb16",
              "IPY_MODEL_f76157b4b99441eba5c177fa4d5b95c0",
              "IPY_MODEL_9aaac1e9727749f2bcc41edb76164311"
            ],
            "layout": "IPY_MODEL_c9ae7a2048254da6a33f91a4006a0321"
          }
        },
        "5a30073c099649bd975d6783fd59fb16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d984075e2984876be970a63161ac7ee",
            "placeholder": "​",
            "style": "IPY_MODEL_5913edf81336465c8231ff17b105355a",
            "value": "Downloading (…)e9125/tokenizer.json: 100%"
          }
        },
        "f76157b4b99441eba5c177fa4d5b95c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a06a965c1184052af911597c726d0e3",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7e34946b0c342ebb2985e427b9ee677",
            "value": 466247
          }
        },
        "9aaac1e9727749f2bcc41edb76164311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_237460d18a8d460d81226738061de73f",
            "placeholder": "​",
            "style": "IPY_MODEL_6b98f3e193d14c2799155c19475d7ab9",
            "value": " 466k/466k [00:00&lt;00:00, 6.17MB/s]"
          }
        },
        "c9ae7a2048254da6a33f91a4006a0321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d984075e2984876be970a63161ac7ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5913edf81336465c8231ff17b105355a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a06a965c1184052af911597c726d0e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7e34946b0c342ebb2985e427b9ee677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "237460d18a8d460d81226738061de73f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b98f3e193d14c2799155c19475d7ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d45a4ae1e784c56ac7804c64a200f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc7f6b75f8d0431c8639f86c6d01e152",
              "IPY_MODEL_554708d31e6f490ba091bdfabeeafb61",
              "IPY_MODEL_634fc48bd7904cf78c9b998a7eab131e"
            ],
            "layout": "IPY_MODEL_eb432f0a06094142a21306598e315052"
          }
        },
        "dc7f6b75f8d0431c8639f86c6d01e152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e66b531fbae84576b84be06c70ff571e",
            "placeholder": "​",
            "style": "IPY_MODEL_c73e65bdab5b4a7280594c163cb2bd1f",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "554708d31e6f490ba091bdfabeeafb61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0db86bd2cb542238efb538b5207f415",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51d142d54b4a4435af8c962e1d657b46",
            "value": 350
          }
        },
        "634fc48bd7904cf78c9b998a7eab131e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84a131b8ee844fa7b5a4ae603df4dc81",
            "placeholder": "​",
            "style": "IPY_MODEL_9f8a25e0f55a4d539135eae0bad8a9a0",
            "value": " 350/350 [00:00&lt;00:00, 28.3kB/s]"
          }
        },
        "eb432f0a06094142a21306598e315052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e66b531fbae84576b84be06c70ff571e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c73e65bdab5b4a7280594c163cb2bd1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0db86bd2cb542238efb538b5207f415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51d142d54b4a4435af8c962e1d657b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84a131b8ee844fa7b5a4ae603df4dc81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f8a25e0f55a4d539135eae0bad8a9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db800c48916d485799c95bfa90e13ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06721bfc794e45c8bf3416cbd61286c8",
              "IPY_MODEL_61ffdca4c2df4eaa8ef55fb15c8b2108",
              "IPY_MODEL_fd1137f7d08b4308b0bea399b26ca408"
            ],
            "layout": "IPY_MODEL_dfc5e0dea0b94451a23fe9e767263d3f"
          }
        },
        "06721bfc794e45c8bf3416cbd61286c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bddf0fa368346158fd36b96e4182610",
            "placeholder": "​",
            "style": "IPY_MODEL_3f2611dd97bc4ab89fa3c1240eb29658",
            "value": "Downloading (…)9125/train_script.py: 100%"
          }
        },
        "61ffdca4c2df4eaa8ef55fb15c8b2108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b173363d984468d9ccb7685ab79d997",
            "max": 13156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_098e538997884e7281b53149707d6d8a",
            "value": 13156
          }
        },
        "fd1137f7d08b4308b0bea399b26ca408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c38956f078a643fc807c8717b5fd72af",
            "placeholder": "​",
            "style": "IPY_MODEL_ed341c3731da4b7ca18340be668fb6aa",
            "value": " 13.2k/13.2k [00:00&lt;00:00, 607kB/s]"
          }
        },
        "dfc5e0dea0b94451a23fe9e767263d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bddf0fa368346158fd36b96e4182610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f2611dd97bc4ab89fa3c1240eb29658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b173363d984468d9ccb7685ab79d997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "098e538997884e7281b53149707d6d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c38956f078a643fc807c8717b5fd72af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed341c3731da4b7ca18340be668fb6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3145e680dbd740fa9ff678b9dc28e82f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebe157faf4bb477eb23e06f23f8feaff",
              "IPY_MODEL_9581ae0f99e54bfea5400ad803eb573d",
              "IPY_MODEL_0ddceb407a344702a64d6ea7c80fcbba"
            ],
            "layout": "IPY_MODEL_6fc7874c081f4ab5afec4bf163722693"
          }
        },
        "ebe157faf4bb477eb23e06f23f8feaff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cff70debcc447788d447c10b1a6e0e5",
            "placeholder": "​",
            "style": "IPY_MODEL_17be188ae9b744b6b33796ef3a05f760",
            "value": "Downloading (…)7e55de9125/vocab.txt: 100%"
          }
        },
        "9581ae0f99e54bfea5400ad803eb573d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62e20816ff274f909f8a266a0d8eeaee",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_625d4f1f3c3f4c3d8dff8d8731662b08",
            "value": 231508
          }
        },
        "0ddceb407a344702a64d6ea7c80fcbba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b68df0c5d4064e4ebc77fa8423ff4254",
            "placeholder": "​",
            "style": "IPY_MODEL_4d92e0070218494d817432b929fbcc47",
            "value": " 232k/232k [00:00&lt;00:00, 10.0MB/s]"
          }
        },
        "6fc7874c081f4ab5afec4bf163722693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cff70debcc447788d447c10b1a6e0e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17be188ae9b744b6b33796ef3a05f760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62e20816ff274f909f8a266a0d8eeaee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "625d4f1f3c3f4c3d8dff8d8731662b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b68df0c5d4064e4ebc77fa8423ff4254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d92e0070218494d817432b929fbcc47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cac90c7cde36411082a5c7de2aa2d364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d7dccabc5854d8ea037ac77df4590b8",
              "IPY_MODEL_124d0cfd57d648f28c54e60fca0a401d",
              "IPY_MODEL_cfac92a7357a4a5cbe3f6c2630a52177"
            ],
            "layout": "IPY_MODEL_b616743e58f24b3e999e8d759c6961ed"
          }
        },
        "7d7dccabc5854d8ea037ac77df4590b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da57121f37324da2b25e8ade9917c8d8",
            "placeholder": "​",
            "style": "IPY_MODEL_be68ea7c5b0c46b0be497ca1cf064b11",
            "value": "Downloading (…)5de9125/modules.json: 100%"
          }
        },
        "124d0cfd57d648f28c54e60fca0a401d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9bea44725c14386875ec58707a07425",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b43551aa6ee46a2abbe6b2ab9043858",
            "value": 349
          }
        },
        "cfac92a7357a4a5cbe3f6c2630a52177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_027ae06d35944ccd9efb69ec011d284e",
            "placeholder": "​",
            "style": "IPY_MODEL_a19733b1b0e341eaa67a640db48a6a59",
            "value": " 349/349 [00:00&lt;00:00, 26.7kB/s]"
          }
        },
        "b616743e58f24b3e999e8d759c6961ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da57121f37324da2b25e8ade9917c8d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be68ea7c5b0c46b0be497ca1cf064b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9bea44725c14386875ec58707a07425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b43551aa6ee46a2abbe6b2ab9043858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "027ae06d35944ccd9efb69ec011d284e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a19733b1b0e341eaa67a640db48a6a59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/json724/pycon2023/blob/embeddings_vectordb/pycon2023_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgpRZvnZGdbq"
      },
      "outputs": [],
      "source": [
        "!apt update &&  apt install ffmpeg -y\n",
        "!pip install -U sentence-transformers\n",
        "!pip install tqdm\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!pip install pytube\n",
        "!pip install pinecone-client\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "gdrive_folder_link='https://drive.google.com/drive/folders/1f3v_CKRVecCqpdX07PQg5mg19mWRaVJC?usp=sharing'\n",
        "gdown.download_folder(gdrive_folder_link, quiet=True)"
      ],
      "metadata": {
        "id": "qJ6AjQRZHsNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h5UULZdH43J",
        "outputId": "c95b9f8f-7419-40a7-fda5-4fa4525f7153"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'PyCon-co audios'   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os \n",
        "import re\n",
        "from tqdm import tqdm "
      ],
      "metadata": {
        "id": "LLKVu4oWIASO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = []\n",
        "url = []\n",
        "path = []\n",
        "patron = r'\\[(.*?)\\]'\n",
        "for _ in os.listdir(\"/content/PyCon-co audios/audios\"):\n",
        "  title.append(_.split('[]')[0])\n",
        "  url.append(re.findall(patron, _)[0])\n",
        "  path.append(\"/content/PyCon-co audios/audios/\" + _)\n"
      ],
      "metadata": {
        "id": "YR8YM1ceIO-u"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_video = pd.DataFrame({'title': title, 'url': url, 'path': path})"
      ],
      "metadata": {
        "id": "XbkxjU1pImV0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_video['url'] = df_video['url'].apply(lambda x: \"https://www.youtube.com/watch?v=\" + x)"
      ],
      "metadata": {
        "id": "3PPepQsmJn50"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_video.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "DzMYcRWDKAiM",
        "outputId": "839c93fc-6b06-4cb9-cfe6-415bd3003f4b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Jonathan Diaz - Sanic StorageService. Usando S...   \n",
              "1  José Benitez - The road so far on building a w...   \n",
              "2  Jorge Gonzalez - Real driving data to improve ...   \n",
              "3  Interview Flavio Percoco - Elastic - PyCon Col...   \n",
              "4  Rodolfo Edelmann & Carlos de la Torre - Conect...   \n",
              "\n",
              "                                           url  \\\n",
              "0  https://www.youtube.com/watch?v=d1Dz5oHE6PU   \n",
              "1  https://www.youtube.com/watch?v=7NlKbzz1y0M   \n",
              "2  https://www.youtube.com/watch?v=E_rPy0h5fXI   \n",
              "3  https://www.youtube.com/watch?v=wfWzKnILBVs   \n",
              "4  https://www.youtube.com/watch?v=N3czkxo2JJw   \n",
              "\n",
              "                                                path  \n",
              "0  /content/PyCon-co audios/audios/Jonathan Diaz ...  \n",
              "1  /content/PyCon-co audios/audios/José Benitez -...  \n",
              "2  /content/PyCon-co audios/audios/Jorge Gonzalez...  \n",
              "3  /content/PyCon-co audios/audios/Interview Flav...  \n",
              "4  /content/PyCon-co audios/audios/Rodolfo Edelma...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46f63864-7563-4b65-a3d3-9f0be60c8300\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jonathan Diaz - Sanic StorageService. Usando S...</td>\n",
              "      <td>https://www.youtube.com/watch?v=d1Dz5oHE6PU</td>\n",
              "      <td>/content/PyCon-co audios/audios/Jonathan Diaz ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>José Benitez - The road so far on building a w...</td>\n",
              "      <td>https://www.youtube.com/watch?v=7NlKbzz1y0M</td>\n",
              "      <td>/content/PyCon-co audios/audios/José Benitez -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jorge Gonzalez - Real driving data to improve ...</td>\n",
              "      <td>https://www.youtube.com/watch?v=E_rPy0h5fXI</td>\n",
              "      <td>/content/PyCon-co audios/audios/Jorge Gonzalez...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Interview Flavio Percoco - Elastic - PyCon Col...</td>\n",
              "      <td>https://www.youtube.com/watch?v=wfWzKnILBVs</td>\n",
              "      <td>/content/PyCon-co audios/audios/Interview Flav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rodolfo Edelmann &amp; Carlos de la Torre - Conect...</td>\n",
              "      <td>https://www.youtube.com/watch?v=N3czkxo2JJw</td>\n",
              "      <td>/content/PyCon-co audios/audios/Rodolfo Edelma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46f63864-7563-4b65-a3d3-9f0be60c8300')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46f63864-7563-4b65-a3d3-9f0be60c8300 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46f63864-7563-4b65-a3d3-9f0be60c8300');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube"
      ],
      "metadata": {
        "id": "S1PpkgoKKBhE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metadata(url):\n",
        "  yt = YouTube(url)\n",
        "  return pd.Series([yt.views, yt.author, yt.publish_date, yt.keywords])"
      ],
      "metadata": {
        "id": "LJJpF8G2LI7-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_video[['views', 'author', 'publish_date', 'keywords']]= df_video['url'].apply(lambda x: get_metadata(x))"
      ],
      "metadata": {
        "id": "p9n29R0GLQSv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_video.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "NJzQ2sG6LxjC",
        "outputId": "50d7827c-a711-4ab4-fe4e-7c766b481cb4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Jonathan Diaz - Sanic StorageService. Usando S...   \n",
              "1  José Benitez - The road so far on building a w...   \n",
              "2  Jorge Gonzalez - Real driving data to improve ...   \n",
              "3  Interview Flavio Percoco - Elastic - PyCon Col...   \n",
              "4  Rodolfo Edelmann & Carlos de la Torre - Conect...   \n",
              "\n",
              "                                           url  \\\n",
              "0  https://www.youtube.com/watch?v=d1Dz5oHE6PU   \n",
              "1  https://www.youtube.com/watch?v=7NlKbzz1y0M   \n",
              "2  https://www.youtube.com/watch?v=E_rPy0h5fXI   \n",
              "3  https://www.youtube.com/watch?v=wfWzKnILBVs   \n",
              "4  https://www.youtube.com/watch?v=N3czkxo2JJw   \n",
              "\n",
              "                                                path  views          author  \\\n",
              "0  /content/PyCon-co audios/audios/Jonathan Diaz ...     90  PyCon Colombia   \n",
              "1  /content/PyCon-co audios/audios/José Benitez -...     96  PyCon Colombia   \n",
              "2  /content/PyCon-co audios/audios/Jorge Gonzalez...    543  PyCon Colombia   \n",
              "3  /content/PyCon-co audios/audios/Interview Flav...    109  PyCon Colombia   \n",
              "4  /content/PyCon-co audios/audios/Rodolfo Edelma...    503  PyCon Colombia   \n",
              "\n",
              "  publish_date keywords  \n",
              "0   2021-08-15       []  \n",
              "1   2020-03-05       []  \n",
              "2   2019-07-25       []  \n",
              "3   2020-04-04       []  \n",
              "4   2020-04-20       []  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c9b5e78-a56c-4536-b980-4b0dc134cf81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>path</th>\n",
              "      <th>views</th>\n",
              "      <th>author</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jonathan Diaz - Sanic StorageService. Usando S...</td>\n",
              "      <td>https://www.youtube.com/watch?v=d1Dz5oHE6PU</td>\n",
              "      <td>/content/PyCon-co audios/audios/Jonathan Diaz ...</td>\n",
              "      <td>90</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2021-08-15</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>José Benitez - The road so far on building a w...</td>\n",
              "      <td>https://www.youtube.com/watch?v=7NlKbzz1y0M</td>\n",
              "      <td>/content/PyCon-co audios/audios/José Benitez -...</td>\n",
              "      <td>96</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2020-03-05</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jorge Gonzalez - Real driving data to improve ...</td>\n",
              "      <td>https://www.youtube.com/watch?v=E_rPy0h5fXI</td>\n",
              "      <td>/content/PyCon-co audios/audios/Jorge Gonzalez...</td>\n",
              "      <td>543</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2019-07-25</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Interview Flavio Percoco - Elastic - PyCon Col...</td>\n",
              "      <td>https://www.youtube.com/watch?v=wfWzKnILBVs</td>\n",
              "      <td>/content/PyCon-co audios/audios/Interview Flav...</td>\n",
              "      <td>109</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2020-04-04</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rodolfo Edelmann &amp; Carlos de la Torre - Conect...</td>\n",
              "      <td>https://www.youtube.com/watch?v=N3czkxo2JJw</td>\n",
              "      <td>/content/PyCon-co audios/audios/Rodolfo Edelma...</td>\n",
              "      <td>503</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2020-04-20</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c9b5e78-a56c-4536-b980-4b0dc134cf81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c9b5e78-a56c-4536-b980-4b0dc134cf81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c9b5e78-a56c-4536-b980-4b0dc134cf81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_video.path[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "JvCeIfOnNBoR",
        "outputId": "ffc65f8e-df56-4e17-dca9-c87ee6bed3e6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/PyCon-co audios/audios/Rodolfo Edelmann & Carlos de la Torre - Conectando microservicios con Python [N3czkxo2JJw].mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(df_video.path[4])\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOqVBJDnMOkv",
        "outputId": "3a245a70-2453-43a4-c46e-9ae88ce12c8a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 64.1MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Bueno, quién soy Rodolfo Edelman, me van a escuchar ahí que me dicen Rudy. Tiengan cuidado si me llaman Digan Rudy con Deno con B. Larga, porque con Ferencia Python se pueden ojar a alguien. Hace 5 años estoy trabajando con Python antes de trabajar con Ruby, eso no lo voy a contermas. Trabajé mucho tiempo a la Universidad Nacional de Córdoba, a esa foto en el Cláster de la Universidad Nacional de Córdoba. Hace mucho de Robots, después abancé a Bakken, de Bakken, empezó a hacer Machine Learning y actualmente estoy como técnica al Manaller en Mercado de Libre, desarrollando productos, servicios internos de la compañía que nos sirven para poner modelos de Machine Learning en producción. Hola, yo soy Litox, Carlos de la Torre, me dicen Litox en la Uroschatz y en las comunidades de Python y en la tele, pero eso todavía no se se llenó nunca. Trabajo con Ruy hace muchos años, también soy técnica al Manaller, tengo un recorrido de su licencia informática y de desarrollador, técnica leader, retabajado en empresas nacionales, en Argentina, en Pymes, pequeñas empresas, ahora en Mercado de Libre estamos como hizo Rudy armando la infraestructura para ejecutar. Machine Learning en producción y a escala. Bueno, queremos entonces contarles un poquito de qué va a ser la charla. Primero que todos para entender el motivo de la charla tenemos que entender porque creamos microsや servicios, ¿cómo hacemos esto en Python? Está normalmente, ¿cuáles son los insas que fuimos sacando, teniendo en estos años de desarrollo, un poco eso y algunos casos de uso que vamos a ver. Monalito, ¿todo saben qué es monalito? Levanta la mano. Normalmente bueno, por accidente. Normalmente una cuando empieza a construir el primer producto, empieza, no quiere hacer algo complejo, quiere empezar por algo que sea fácil de poner en producción rápido para validar una idea. De esta manera es que empezamos a hacer un monalito. En la arquitectura monalito es construcción sobre un solo material. Se hace una analogía cuando el diseño de software que tiene que ver con un estat tecnológico. El ejeimo en estat tecnológico y construimos sobre ese estat. ¿Qué quiere decir? El ejeimo Python, Django, MySQL y alguna cola de mensajes. Pero esto paría producción fantástico. Vamos rápido, pero empiezan a ocurrir problemas. Cuando crece son miles y miles de líneas de códigos y esta línea de códigos se vuelven a complejas, hay una interdependencia. Si queremos modificar una parte seguramente tengamos que tocar otra parte del código o romper cosas, los test son gigantescos y empezamos a encontrarnos con que viene el mano y nos dice che, ahora queremos hacer Machine Learning y nosotros estamos trabajando en God, por ejemplo. Y sabemos que integrar algo de Python dentro de un monolito en God es muy complicado. Entonces por estos motivos es que las compañías cuando crecen y empiezan a hacer software mucho más complejo, empiezan a tomar decisiones de separar este monolito en pequeñas piezas. Estas pequeñas piezas que hoy les llamamos micros servicios, nos dan la inventaja de que podemos elegir el stack que nos interesa para resolver el problema. O sea el martizo para clavar, el serrucho para cortan madera. Este imagen que se ve acá, que no se ve mucho detalle, pero son muchos puntitos y muchas líneas azul. Esos puntitos representan micros servicios. Son cada uno de esos puntitos de micros servicios y cada línea azul es una comunicación. Entonces si bien resolvimos problemas de escalidad, resolimos problemas que hay. Ahora tenemos equipo dedicados para los problemas que necesitamos resolver, podemos hacer mucho más diplóvimas rápido, se empiezan a aparecer otros problemas, que es el problema de la comunicación. ¿Qué significa? Ante una comunicación era una llamada una función, una llamada un método, era un 2 o 3 ciclo de CPU y ya teníamos una respuesta. Ahora tenemos un cable de red, una placa de red, tenemos de NS, tenemos un sistema mucho más complejo para poder sacar un mensaje de un micros servicio al otro. Nosotros cuando empezamos a trabajar con Python en mercado de libre fuerte, que empezamos a hacer Machine Learning, nos dimos cuenta que en las performan de todas las APIs o los micros servicios, que hacíamos en Python, no se comparaban con lo que ya estaba hecho un go, por ejemplo. Y pero no tenía mucho sentido porque estábamos haciendo cosas sencillas del principio. Entonces empezamos a investigar un poquito y hay un poco de esta charla de los insens que sacamos. Entonces les queremos contar un poquito que hicimos y en general que se hace para conectar micros servicios con Python. En realidad conectar micros servicios a este nivel es hacer una llamada HTTP, es hacer un request como el que hace el navegador, cuando no entra una página, hace un request, ha sido un servidor, eso va a vuelve y en la degarlo renériz algo, en nuestro caso, mandamos un mensaje y recibimos una respuesta y trabajamos. El caso de una arquitectura de micros servicios, cuando nosotros montamos nuestra solución con este diseño, por lo que real corremos en infraestructura de red que está optimizada para esto. No es lo mismo yo acá entrando a Google que tengo que atravesar un montón de continentes hasta que llegue el rico, es el servidor y vuelva, cuando yo el mi empresa voy a armar en infraestructura de micros servicios, por lo general voy a intentar que la capa de tráfico, la capa de red, se ha óptima chica, velos, entonces voy a montar por ejemplo todo en AWS para que el tráfico esté contenido adentro de tráfico de fibra y de backbone, eso es super eficientes. Entonces lo que realmente pasa a nivel código pasa hacer relevante, ¿eh? Entonces típicamente que hacemos el mundo Python para hacer un request HTTP, quieren conocer a librería requests, levanten la mano por favor, casi todos bien, perfecto, el 78,29%. Casi todo, sí, request es lo que se usa en Python y tiene sentido porque la librería request nos abstracte los BMoles, el protocol HTTP, ¿qué significa un request HTTP? Hay cierto estrin formateado con un formalismo que tiene que viajar hacia un servidor que lo vas a recibir y que me va a devolver con cierta formalidad o mensaje. Eso es un protocolo que se monta sobre un montón de cosas, sobre en particular la red. Entonces por ejemplo que yo quiero en mi aplicación que calcula el tiempo de envío y un paquete, estípicamente voy a depender de otros servicios, voy a depender de servicios externos, porque yo voy a querer calcular para determinado usuario y determinado producto, bueno, ¿cuánto tal ese producto en llegar a su casa? Entonces yo voy a tener que pedirle a la API de direcciones de usuarios que me diga las direcciones de usuario y voy a querer pedir a otro endpoint que es la información de los vendedores, que me de información y después a la información de las direcciones de los vendedores. Entonces en una esquema de microservicios típicamente vamos a tener una serie de llamadas, una serie de requests a otros servicios, posiblemente aún mismo servicio, yo le quiero pegar muchas veces. Este código cada vez que llegó request ustedes de entrar al mercado libre al marketplace, entre la verulítem y en algún momento le dice por ejemplo cuánto mataró a llegar aproximadamente el sistema a su casa. Eso significa que con cada rico es que llega al mercado libre, este código se ejecuta y al mercado libre tenemos cientos de miles de ricos por minuto. Y significa que este endpoint se va a llamar cientos de miles de veces por minuto. Entonces estas llamadas mi microservicio le va a estar pegando los otros microservicios de una manera exponencial con respecto al tráfico que recibo. Entonces ¿qué pasa cada vez que yo le pego otro microservicio? ¿Bien esto que en mi computadora se desmejor? Esta tiene que ver más o menos con la explicación del protocolo tcp, la capa de red. ¿Qué pasa cuando yo le envío desde mi cliente a un mensaje al servidor? Se establece una comunicación a nivel red donde primero hay que ir al DNS para ver cuál es la IP del servidor que tiene que llegar porque yo le digo una URL, una string. Entonces da de ese IP tengo que empezar a mandar ciertos mensajes de conexión a ese otro servidor. Entonces esos son un montón de mensajes entre mi entre la máquina original y la máquina de destino. Le va a tu mensaje para que se conecte y una vez que se conecta tiene que haber si estoy en un esquema de ese cl o de seguridad, hay todo un intercambio de protocolos, asociado a que voy a asegurarme de que está protegida, la conexión, esto se unir y vueltas de mensajes. Para que finalmente yo le pueda mandar el payload de mi mensaje, para que fíjense que nosotros en Python le dijimos mandar un get y traer este resultado, internamente que nos resolvió request y hizo toda esta comunicación, mandó el mensaje y cerró la conexión. Y eso lo hizo cada vez resolución de DNS, ese se conectó, ese cl, le mandó el payload y la cerró. Con cada vez y los cientos de miles de veces que yo me conecto con el otro servidor, request aseto. Porque bueno, porque el que se hace es fácil, con muy poco, hace mucho. Ahora yo estoy en una esquema de micro-serizo, yo voy a conectar muchas veces con el mismo servidor, era un esquema seguro. Yo no quisiera estar abriendo y cerrando esta conexión cada vez, yo no quisiera estar intercambiando, certificado, ese cl. Entonces en realidad yo me gustaría quedarme con una partecita muy chiquita todo lo que está haciendo, request. Entonces la librería request con muy poco me permite ganar esa optimización. Uno tiene que leer la documentación de request, tiene que pasar del getting start, de quick start de request y empezar a ver los features como en todas las librerías que estamos usando en general. Tenemos un quick start pero después tenemos que ver cuáles son los parámetros un poquito más avanzados. Fíjense que con muy pocos cambios, yo request le puedo decir no quiero usar la de top level, request le digo che de alguna sesión. Che. Bueno, no sé. Hola. Riqueste. La buena sesión. Y después yo puedo usar esa sesión. Esa sesión significa justamente ganar todas esas optimizaciones. Riquest establece una sesión de comunicación con un servidor y ya mantiene abierta la conexión. Entonces yo después cada vez que mando un mensaje solamente envía el payload. Para ahí agrego algo, esto está escalando. Que realmente cuando uno hace micro servicio el payload es una ID, es un string, es muy chiquito, no estás pasando un imagen de dos digas. Entonces es realmente es muchísimo lo que uno gana si puede hacer use of optimo de los tiempos esto que estamos haciendo. Y si yo lo único que voy a hacer en aplicaciones, una vez por ahora peguirle algo a Google y volver, no esté queriendo activizar esto. Y luego pensemos en la escala en la que mi arquitectura entera los miles de ricos que atiendo por segundo se transforman en cientos de miles de ricos adentro de mis istevas. Cada mil y segundo que yo le gane va a ser un mil y segundo menos de cómputo, mil y segundo menos de tráfico y eso se transforma por lo que creen costos. Bien, el mejor es en costos. Entonces los otros vivimos que se estaba usando de forma naive, Riquest, trabajamos con múltiples equipos entre la organización. Veamos que estaban usando Riquest así no más como Quick Start y hicimos algunos benchmarks usando session y en particular el happy que hacemos con Rudy empezamos a usar sessions. Claro. Y vimos mejoras impresionantes con realmente como poco cambio. Por ejemplo, la cantidad de ricos que puedo hacer eso por segundo con el primer vea su eco, digo, son alrededor de 500. Usando sessions se duplicó, se duplicó la cantidad de ricos que puedo hacer eso en un segundo haciendo tres líneas de código de cambio. Bien, acá bueno el vea no me quiero hacer refoco en el benchmark si pero bueno hicimos esto es una prueba local, obviamente la cantidad de ricos que puedan hacer por segundo va a vender 1 millón de cosas. Cuando probas R, tratas de australerte de la RID y usas tu propia interfaz de tu máquina como para tener algo consistente. Entonces realmente por hacer tres líneas de código de cambio ganamos una performance en cuanto a la cantidad rico que podemos hacer por segundo del doble. También es más impresionante en una esquema chiste de TPS donde toda la negociación de certificados de SCL, metetanto a Vergette, que yo podía hacer 146 ricos por segundo, habría desarrollándolo con acción y pasando sesiones, pasó a mil, o sea el cambio y la gana se realmente impresionante. Entonces bueno y también todo el que priori no habíamos pensado pero que terminó sucediendo es que el uso de CPU, el mi aplicación, casi pasó la mitad. Porque todas estas cosas que estaban haciendo ricos por abajo no las tiene que hacer más y si estamos pagando por CPU, por ejemplo comprando instancias en la 9, tal vez si tengo múltiples instancias, bueno usarla menos significa costo, mejoras en costos, o si tienen datos entre en su pieza, no sé menos calor, algo pero... La ventaja para todos, entonces bueno a ver por qué estamos usando ricos, porque estábamos usando ricos, tiene una interfaz espectacular, realmente muy amigable, muy simple hacer un llamado de Jueves, después tiene un montón de ventajas asociadas a las aplicaciones web tradicionales, no necesariamente a micro-servings, entonces manejos de cookies, verificaciones de cosas de seguridad, decodificación de contenido, streaming, chunking de vio de datos, tiene un montón de ventajas que están buenísimas, de las cuales a nosotros prácticamente no nos interesa ninguna. Está bien, te va a ir a empezar muy rápido, pero en el fondo usa un relícter. Hay alguna aclaración, esto no se trata de comparar cosas, no queremos hacer comparaciones, las comparaciones son odiosas, en realidad estamos tratando de ver distintas herramientas, yo oí lo veo como rico es una herramienta para resolver algunos tipos problemas y Jueves relíctres, que es lo que voy a hablar un poquito ahora, es una herramienta para resolver otro tipo de problema, que estamos comparando que una es mejor que otra, son cosas diferentes, en el caso de web relíctres, lo primero que fuimos a analizar es ¿qué tan diferente es la interfaz? Porque esto lo tenemos a replicar en 300 equipos, tenemos aligo un mensaje a 300 equipos de heche, deberíamos empezar a utilizar este herramienta porque ahí lo vamos a ver más adelante, y nos encontramos que si bien no están amigables, acá no puede utilizar como así con rico es de no hacer una sesión, acá realmente hay que hacer un pull, lo sision de rico es en el fondo, hace un pull de web relíctres, hay que ser más explícito en los parámetros, no es tan que los adivinos mágicamente, igual son dos parámetros, uno dice a cuántos dominios diferente va a mantener una conexión, por ejemplo si me conecto a 5 microservicios, el número de pull es 5, el maxize que está ahí como 10 es la cantidad de hilos que vamos a tener abierto por cada pull, entonces si estamos trabajando con un unicornbudo lsg y estamos haciendo Tridin y vamos a poner 10 hilos, sabemos que ahí tenemos que poner un número 10 o más, esto no es un número duro, no es que si de repente hay más hilos corriendo insestables en más conexiones no nos va a permitir, lo que va a pasar, que cuando se cumple un timeout va a ir eliminando conexiones y siempre va a dejar 10 establecidas y las otras se van a tener establecer cuando siguen inicion, después en el uso y es un poco raro en realidad el get no es un método y es un parámetro, los fields, hay cosas que realmente el interfaz rico es tan buenísima y no la tenemos en un lugar relíctres, pero haciendo un análisis rápido tampoco es inentendible, no es que hoy vemos esto todo lo que estamos acá y vamos a entender que eso quiere hacer un get a esta URL y que le quiere pasar esta parámetros, y simolas mivas pruebas que veníamos haciendo exactamente el mismo escenario y encontramos que con solo esos cambios que no son menores, si uno ya tiene un proveo de acto que está establecido, que es grande y tiene muchos testes escritos con ricos y ricos most, son cambios importantes pero ya teníamos un 30% de adancia y no es poco un 30%, 30% es un montón cuando tienen millones de ricos que se están ejecutando, entonces pasamos de mil que le teníamos antes a mil 300, en ese momento ya estamos en canchila, habíamos pasado de un mes, no sé si algo que usan acá o una mala palabra que van a Cualombia, si no, no es la de la idea, o sea habíamos trabajado un mes aproximadamente haciendo estas pruebas y estos cambios probándolo en API y ya estamos al doble y un poquito más del doble y que muy bueno, investimos un poquito más, vamos más allá, somos una compañía grande, tenemos muchas apes que escrita en Python, tenemos tiempos para hacer estas cosas, entonces bueno juguemos, empezamos a investigar y obviamente ir de Python a C, que es Pycool, está hecho en C, sabíamos que vamos a tener alguna ventaja en tiempo, ahora teníamos enalizar cuáles son las desventajas de usar Pycool, porque no todo de gratis en la vida, entonces empezamos a investigar Cool, lo primero que vimos en la documentación es que es para usuarios avanzados, para hacer docena de conexiones con currentes, esos fichules sustificados y la documentación está escrito en HTML1.0, yo que venía de Rit de Doc, si tuviste estas cosas bonitas y con buscadores en pese a leer esa documentación y dije no, o porque me estoy metiendo acá, pero bueno, nada, tenía el tiempo, somos informáticos, nos gusta hacer estas cosas, investe un poquito más, empecé a jugar y dije bueno voy a hacer mi primer get in Pycool. Esto es copy page de la documentación de Pycool, cual disclaíbero en la web page, está buenísimo, el que habéis anotradición. Y está muy bien, ¿por qué, ¿quién usted usa Pycool? Un valiente, o relíptr… O relíptr… O relíptr… ¿quién usa? Ahí está, va, vámonos. Tengo que trabajar con los audicios, hablemos en un rato. Pero sí, acá Pycool está diciendo, sin necesitas docenas de llamadas con currentes y unos confusios sofisticados, entonces ya está avisando que, también, si lo que único que queréis hacerle un post a la lista de, no sé qué pública, no hace falta, pero capaz de una vez que más microsaricios, donde queréis hacer docenas de concurrentes ricos, si tenés advanced developers que se la banquen, puede llegar a tener sentido. Igual vamos a llegar a esa parte, avance de nivel, pero sí, vamos a hacer falta. Lo primero que vimos cuando hicimos las pruebas es que ya duplicamos lo que habíamos duplicado. La verdad está, súper contento, eso tenía muchísimas ganas de implementar esto, decirlo a todo el mundo. Por favor, usted, en Pycool, es la que va, me junté con listos, con Javi, un poco analizar el Javi, es un batuchivo de trabajo con nosotros, analizar esto y empezamos a ver un poco cómo se hace el gays y cómo se usa y no los convencía mucho. Esto es importantísimo, el uso de CPU se fue al 0.73% La gente que está usando mucho Python y en mercado libre hace machine learning cada porcentaje de CPU que le liberamos, es jugo para eso. Tenemos que salir con esto rápido producción, ¿cómo hacemos? Es un get in Pycool. Se recuerdan, bueno, todo usado, un rico es rico es punto get y ya estás haciendo un get. Y acá hay tan color al tovard 1, no sé si un color ambia bardo significa lo mismo que significa de Argentina. Un gran problema, uno. Un gran problema, uno, un gran problema. La forma que uno le tiene que pasar los parámetros, no es un diccionario común, realmente es súper complejo, súper confuso. Yo hace 5 años estoy con Python y venía a esto y decía por qué, por favor, ¿por qué es así? Pero bueno, tiene sus ventajas, tiene la ventaja de duplicar la cantidad rico de Google, de USB3, de uso de CPU, tenemos que ver que así. Creo que el post no se lo puse, bueno, el post, un get in Pycool es doblemente lo arduo. Imagínense, te esté a adreso, es como te esté a este oeste de pedazo de código, como reparto este código en 300 o 400 aplicaciones. Muy difícil. Te he ganado de cuenta que todos conocen ricos, nosotros también conocíamos ricos, entonces, ¿cuándo tienes que hacer una solución? ¿Ustedes ricos? El momento 0, no te lo preguntaste, lo cual es un problema en un contexto productivo, si están haciendo un apoc, si están haciendo un prototipo, si están haciendo una prueba, hay preguntas que no necesitan trabajarnos. Pero cuando vamos a un entorno productivo, sobre todo de escala, tenemos que ser mucho más detallas. Entonces, haber elegido ricos como librería de comunicación entre procesos, es de auto-tech. Es un riesgo que estamos tomando y que en algún momento nos puede costar y que en algún momento, ese costo, como cualquier deuda, con sus literes, se va a ser más caro. Y nosotros no nos dimos cuenta. Y nos dimos cuenta cuando nos dimos cuenta que había que implementar esto. Con cada rico es que teníamos en cada una de los hoy por hoy cientos de micros servicios de pliego en Python que tenemos. Son muchos equipos de trabajo trabajando y si cada una de esos equipos se le digo, esa línea no, repasar las por estas 75 que tenemos acá. Y listo. Otra cosa que teníamos en Python y que era súper interesante y no logramos hacer con ricos y vos relic tres. En un entorno productivo hacer monitoring es súper importante medir. Hay que medir todo lo que se pueda. En mercado de libre nos gusta medir mucho y medimos cada cosa que sucede. Por ejemplo, si val de NS, nos queremos medir por cada rico, es que sale cuánto tiempo tardó y en ir y volver al NS. Si hay una conexión cuánto tiempo se tardó en establecer esa conexión. Si el payload cuánto tiempo tardó todos esos detalles en librerías de bajo nivel como parical podíamos obtener las y en el de alto nivel, realmente teníamos de entrar a muyificar el código en la librería y era bastante complejo. Entonces hay un poco gran y veíamos como la ventaja de poder monitorear muchísimo mejor los micros servicios que te veníamos y era otra cosa a favor que nos decías che tenemos aquí por este camino. ¿Tío, ¿no? Insay, un poco lo que venimos charlando, lo que venimos contando. Ricos desde alto nivel, está buenísimo para empezar. Está buenísimo si una cedata science y tiene que hacer algunas búsqueda. No quiero un mail que me diga después che, me dijiste paico de buenísimo, mirad, tenía que hacer un rico Google para sacar algo estuve tres días. No estamos vendiendo eso. Ricos es un excelente herramienta para utilizarla en el contexto que se tiene que utilizar. Hay opciones de optimizaciones, hay que leerla, a mí me he dado mucho la atención que la opción de optimización de esto decision en Ricos está en uso avanzado. Personalmente considero que no están avanzados, me parece bastante sencillo poder utilizar un feature como eso, capaz que entender en el fondo que lo que hace puede ser complejo, pero como feature de la librería es algo relativamente básico. Como toda optimización, siempre, avoy de early optimization, early optimization, is the root of all evil, dijo algún viejo pop de la informática. Bueno, no acabamos de optimizar la entrada, entonces sí, a camismo estamos viendo que informas de optimizar la manera de hacer ricos, tengo la en cuenta de función de su caso de uso. Después, las buenas prácticas en que nierías aplican para todos, las prácticas que conocemos, de no optimizar antes de tiempo, de empezar, esto es algo que me lo discuta, a mí me gusta empezar a desarrollar pensando que está todo bien y después pensar en las cosas que pueden fallar, creo que una charla hace unos días, de 100 todos los contrarios, a mí me gusta hacer optimista y después ir agregando complejidad. Entonces, esas buenas prácticas que hay que hemos estudiado sirven para los macros y para los micros también, en este caso. Entonces bueno, les mostramos lo que estamos haciendo, les contamos que encontramos formas de optimizarlo, entonces ahora le queremos contarlo el próximo paso, no el final, sino el próximo paso, que hicimos en Mercado Libre con todo esto o por lo menos en el marco nuestros equipos, primero lo queremos esta filmina de marketing, es un poco para que entienda la cuestión de envergadura y de escala, que realmente en nuestro caso, porque tiene sentido hacer lo que hicimos, lo que lo podemos demostrar, en Mercado Libre hay 6 mil busques por segundo, una búsqueda desde el browser dispara un montón de ricos, y cada uno de esos ricos adentro nuestro sistema se multiplica, entonces imagínese el volumen de transacciones con los envíos, con las compras, con cada uno de los pagos a través de mercados pagos cada item que se crea cada usuario que entra, son literalmente millones de ricos por segundo, que se multiplica dentro nuestro sistema, probablemente se no sea el caso de uso de todos ustedes, lo cual no significa que les cala, la que esté trabajando, no sea importante considerar esto lo mismo, pero para nosotros que veníamos de la empresa más chica, que en Mercado Libre del Quirio nos encontramos con esta escala y el día de hoy sigue siendo impresionante, porque lo vemos en el día de día, entonces quéis hicimos con todo esto de sabemos que podemos optimizar la forma de conectar microciarizos en Python, básicamente hicimos una librería, una rest client, una abstractión de la capa de comunicación HTTP, hay que poder que podriamos haber hecho desde el inicio, lo que pasa es que esa rico es tan fácil, no veíamos la necesidad de hacerlo raper. Sí, a partir de eso yo recuerdo entre en un proyecto el primer día y dije, bueno, cinco mil ricos, voy a tener dos mil ricos, esto lo hizo una prueba en mi máquina esta bandar, después salió producción, tenía 200 mil ricos por segundo, entonces ahí me di cuenta que ahí me va a discutirme el che para, hay que hacer cosas con esto, no es tan senciso, El happy, en Mercado Libre no funciona, el approach naive de entrada, no funciona nunca, de entrada tienes que pensar entre 10 mil y 50 mil ricos por minuto, el 10KRPB, el 50KRPB, es algo que para nosotros todavía es chico, cuando queremos probar infraestructuras, por ejemplo, haremos un happy de 600, 700KRPB, son happy que se les está pegando fuerte, pero no son la más grande del sitio, se nos va a meter el escalje grande, cuando estamos en esta máquina, nos metemos al medio de casi todos los flujos importantes del negocio, perdiciendo, categorizando, recomendando, entonces por más que hay mucho go dando vuelta en la compañía, pero utilizar estas cosas es mucho jable en el lógica de negocios, Python de repente con una capillaria muy grande, apalancado por el Machine Learning, se ve a ti, entonces lo que hicimos hace poco es esta hora librería para que los desarrolladores ahora instancia en una librería un res client, que esconder todos los detalles de implementación y toda la lógica de negocios relacionada a conectar microservices de la compañía y obviamente ya que nos gustaba tanto el interfaz rico, si intentamos hacer algo, realmente parecido y ahí varios desafíos, toda la comunidad patónica que está trabajando, están muy familiarizadas con rico, entonces no fue solamente hacer una buena interfaz parecida a la de rico, es para esta herramienta, sino que después nos encontramos que todas las herramientas que hay alrededor de rico es como rico es mo, para testiarla nos dejaban de servir, entonces también tuvimos que desarrollar herramientas para testiar nuestro res client que sean parecidas, porque la comunidad estaba acostumbrada, no fue trivial de sentarse una, dos semanas y grabiéral algo, sino que realmente hubo que sentarse, hacer ni que ni hería, diseñarlo, pensarlo, probarlo ir y volver y algunas cosas interesantes que sucedieron, hoy por una cuestión de que uno no puede aplicar un cambio masivamente en toda la compañía, porque es muy riesgoso, el res client nosotros vamos agregando lo que llamamos en jeans, que básicamente empezamos con un rico es en el fondo, que estamos seguro que andaba con sesión, despagaramos un relipter y de a poquito fuimos migrando algunas apicas, usan esta implementación y después anpaiculi, simulos mismos fuimos migrando, y fue muy interesante ver como equipos hacían los diploi y decían, mira no sé qué hicimos, no es súper rapidora, nosotros estamos haciendo todo a H, me parece que está funcionando esto, pero esto que se lo cuento como chiste es, es el valor de por poder tener herramientas de la compañía que impacten en toda la compañía con un solo cambio, nosotros hacemos una nueva versión de esta librería y estamos impactando en todos los microservicios que están en Python, que si no lo hubiéramos hecho tendríamos que haber hecho que decía delito que decir che bueno esta línea ahora la cambia en por esta 70, entonces tomar decisión y adicuñar es parte de comunicar microservicio, no es solamente una cuestión de optimizar la performance. Bueno luego que llevamos con partidos este es un caso de uso propio es parte de lo que lo que nos sirvió tiene sus prois sus contras, porque ahora esta librería le tiene que mantener a alguien, si el sistema de recomendaciones de mercado libre encuentro un vaga o una limitación de esta librería obviamente alguien lo tiene que resolver y ese alguien en este caso somos nosotros, entonces de nuevo depende el caso de uso hay que responsabilizarse por las herramientas que hacemos, como dice Rudy los pros son muchísimos, las contras no tantas como para que nos animamos, lo que tenemos el Thermal Marcha, ¡Uchan ausosIO!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKHnb2_zNKu9",
        "outputId": "e70f7aaf-be7e-4323-c931-ea305135d535"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ' Bueno, quién soy Rodolfo Edelman, me van a escuchar ahí que me dicen Rudy. Tiengan cuidado si me llaman Digan Rudy con Deno con B. Larga, porque con Ferencia Python se pueden ojar a alguien. Hace 5 años estoy trabajando con Python antes de trabajar con Ruby, eso no lo voy a contermas. Trabajé mucho tiempo a la Universidad Nacional de Córdoba, a esa foto en el Cláster de la Universidad Nacional de Córdoba. Hace mucho de Robots, después abancé a Bakken, de Bakken, empezó a hacer Machine Learning y actualmente estoy como técnica al Manaller en Mercado de Libre, desarrollando productos, servicios internos de la compañía que nos sirven para poner modelos de Machine Learning en producción. Hola, yo soy Litox, Carlos de la Torre, me dicen Litox en la Uroschatz y en las comunidades de Python y en la tele, pero eso todavía no se se llenó nunca. Trabajo con Ruy hace muchos años, también soy técnica al Manaller, tengo un recorrido de su licencia informática y de desarrollador, técnica leader, retabajado en empresas nacionales, en Argentina, en Pymes, pequeñas empresas, ahora en Mercado de Libre estamos como hizo Rudy armando la infraestructura para ejecutar. Machine Learning en producción y a escala. Bueno, queremos entonces contarles un poquito de qué va a ser la charla. Primero que todos para entender el motivo de la charla tenemos que entender porque creamos microsや servicios, ¿cómo hacemos esto en Python? Está normalmente, ¿cuáles son los insas que fuimos sacando, teniendo en estos años de desarrollo, un poco eso y algunos casos de uso que vamos a ver. Monalito, ¿todo saben qué es monalito? Levanta la mano. Normalmente bueno, por accidente. Normalmente una cuando empieza a construir el primer producto, empieza, no quiere hacer algo complejo, quiere empezar por algo que sea fácil de poner en producción rápido para validar una idea. De esta manera es que empezamos a hacer un monalito. En la arquitectura monalito es construcción sobre un solo material. Se hace una analogía cuando el diseño de software que tiene que ver con un estat tecnológico. El ejeimo en estat tecnológico y construimos sobre ese estat. ¿Qué quiere decir? El ejeimo Python, Django, MySQL y alguna cola de mensajes. Pero esto paría producción fantástico. Vamos rápido, pero empiezan a ocurrir problemas. Cuando crece son miles y miles de líneas de códigos y esta línea de códigos se vuelven a complejas, hay una interdependencia. Si queremos modificar una parte seguramente tengamos que tocar otra parte del código o romper cosas, los test son gigantescos y empezamos a encontrarnos con que viene el mano y nos dice che, ahora queremos hacer Machine Learning y nosotros estamos trabajando en God, por ejemplo. Y sabemos que integrar algo de Python dentro de un monolito en God es muy complicado. Entonces por estos motivos es que las compañías cuando crecen y empiezan a hacer software mucho más complejo, empiezan a tomar decisiones de separar este monolito en pequeñas piezas. Estas pequeñas piezas que hoy les llamamos micros servicios, nos dan la inventaja de que podemos elegir el stack que nos interesa para resolver el problema. O sea el martizo para clavar, el serrucho para cortan madera. Este imagen que se ve acá, que no se ve mucho detalle, pero son muchos puntitos y muchas líneas azul. Esos puntitos representan micros servicios. Son cada uno de esos puntitos de micros servicios y cada línea azul es una comunicación. Entonces si bien resolvimos problemas de escalidad, resolimos problemas que hay. Ahora tenemos equipo dedicados para los problemas que necesitamos resolver, podemos hacer mucho más diplóvimas rápido, se empiezan a aparecer otros problemas, que es el problema de la comunicación. ¿Qué significa? Ante una comunicación era una llamada una función, una llamada un método, era un 2 o 3 ciclo de CPU y ya teníamos una respuesta. Ahora tenemos un cable de red, una placa de red, tenemos de NS, tenemos un sistema mucho más complejo para poder sacar un mensaje de un micros servicio al otro. Nosotros cuando empezamos a trabajar con Python en mercado de libre fuerte, que empezamos a hacer Machine Learning, nos dimos cuenta que en las performan de todas las APIs o los micros servicios, que hacíamos en Python, no se comparaban con lo que ya estaba hecho un go, por ejemplo. Y pero no tenía mucho sentido porque estábamos haciendo cosas sencillas del principio. Entonces empezamos a investigar un poquito y hay un poco de esta charla de los insens que sacamos. Entonces les queremos contar un poquito que hicimos y en general que se hace para conectar micros servicios con Python. En realidad conectar micros servicios a este nivel es hacer una llamada HTTP, es hacer un request como el que hace el navegador, cuando no entra una página, hace un request, ha sido un servidor, eso va a vuelve y en la degarlo renériz algo, en nuestro caso, mandamos un mensaje y recibimos una respuesta y trabajamos. El caso de una arquitectura de micros servicios, cuando nosotros montamos nuestra solución con este diseño, por lo que real corremos en infraestructura de red que está optimizada para esto. No es lo mismo yo acá entrando a Google que tengo que atravesar un montón de continentes hasta que llegue el rico, es el servidor y vuelva, cuando yo el mi empresa voy a armar en infraestructura de micros servicios, por lo general voy a intentar que la capa de tráfico, la capa de red, se ha óptima chica, velos, entonces voy a montar por ejemplo todo en AWS para que el tráfico esté contenido adentro de tráfico de fibra y de backbone, eso es super eficientes. Entonces lo que realmente pasa a nivel código pasa hacer relevante, ¿eh? Entonces típicamente que hacemos el mundo Python para hacer un request HTTP, quieren conocer a librería requests, levanten la mano por favor, casi todos bien, perfecto, el 78,29%. Casi todo, sí, request es lo que se usa en Python y tiene sentido porque la librería request nos abstracte los BMoles, el protocol HTTP, ¿qué significa un request HTTP? Hay cierto estrin formateado con un formalismo que tiene que viajar hacia un servidor que lo vas a recibir y que me va a devolver con cierta formalidad o mensaje. Eso es un protocolo que se monta sobre un montón de cosas, sobre en particular la red. Entonces por ejemplo que yo quiero en mi aplicación que calcula el tiempo de envío y un paquete, estípicamente voy a depender de otros servicios, voy a depender de servicios externos, porque yo voy a querer calcular para determinado usuario y determinado producto, bueno, ¿cuánto tal ese producto en llegar a su casa? Entonces yo voy a tener que pedirle a la API de direcciones de usuarios que me diga las direcciones de usuario y voy a querer pedir a otro endpoint que es la información de los vendedores, que me de información y después a la información de las direcciones de los vendedores. Entonces en una esquema de microservicios típicamente vamos a tener una serie de llamadas, una serie de requests a otros servicios, posiblemente aún mismo servicio, yo le quiero pegar muchas veces. Este código cada vez que llegó request ustedes de entrar al mercado libre al marketplace, entre la verulítem y en algún momento le dice por ejemplo cuánto mataró a llegar aproximadamente el sistema a su casa. Eso significa que con cada rico es que llega al mercado libre, este código se ejecuta y al mercado libre tenemos cientos de miles de ricos por minuto. Y significa que este endpoint se va a llamar cientos de miles de veces por minuto. Entonces estas llamadas mi microservicio le va a estar pegando los otros microservicios de una manera exponencial con respecto al tráfico que recibo. Entonces ¿qué pasa cada vez que yo le pego otro microservicio? ¿Bien esto que en mi computadora se desmejor? Esta tiene que ver más o menos con la explicación del protocolo tcp, la capa de red. ¿Qué pasa cuando yo le envío desde mi cliente a un mensaje al servidor? Se establece una comunicación a nivel red donde primero hay que ir al DNS para ver cuál es la IP del servidor que tiene que llegar porque yo le digo una URL, una string. Entonces da de ese IP tengo que empezar a mandar ciertos mensajes de conexión a ese otro servidor. Entonces esos son un montón de mensajes entre mi entre la máquina original y la máquina de destino. Le va a tu mensaje para que se conecte y una vez que se conecta tiene que haber si estoy en un esquema de ese cl o de seguridad, hay todo un intercambio de protocolos, asociado a que voy a asegurarme de que está protegida, la conexión, esto se unir y vueltas de mensajes. Para que finalmente yo le pueda mandar el payload de mi mensaje, para que fíjense que nosotros en Python le dijimos mandar un get y traer este resultado, internamente que nos resolvió request y hizo toda esta comunicación, mandó el mensaje y cerró la conexión. Y eso lo hizo cada vez resolución de DNS, ese se conectó, ese cl, le mandó el payload y la cerró. Con cada vez y los cientos de miles de veces que yo me conecto con el otro servidor, request aseto. Porque bueno, porque el que se hace es fácil, con muy poco, hace mucho. Ahora yo estoy en una esquema de micro-serizo, yo voy a conectar muchas veces con el mismo servidor, era un esquema seguro. Yo no quisiera estar abriendo y cerrando esta conexión cada vez, yo no quisiera estar intercambiando, certificado, ese cl. Entonces en realidad yo me gustaría quedarme con una partecita muy chiquita todo lo que está haciendo, request. Entonces la librería request con muy poco me permite ganar esa optimización. Uno tiene que leer la documentación de request, tiene que pasar del getting start, de quick start de request y empezar a ver los features como en todas las librerías que estamos usando en general. Tenemos un quick start pero después tenemos que ver cuáles son los parámetros un poquito más avanzados. Fíjense que con muy pocos cambios, yo request le puedo decir no quiero usar la de top level, request le digo che de alguna sesión. Che. Bueno, no sé. Hola. Riqueste. La buena sesión. Y después yo puedo usar esa sesión. Esa sesión significa justamente ganar todas esas optimizaciones. Riquest establece una sesión de comunicación con un servidor y ya mantiene abierta la conexión. Entonces yo después cada vez que mando un mensaje solamente envía el payload. Para ahí agrego algo, esto está escalando. Que realmente cuando uno hace micro servicio el payload es una ID, es un string, es muy chiquito, no estás pasando un imagen de dos digas. Entonces es realmente es muchísimo lo que uno gana si puede hacer use of optimo de los tiempos esto que estamos haciendo. Y si yo lo único que voy a hacer en aplicaciones, una vez por ahora peguirle algo a Google y volver, no esté queriendo activizar esto. Y luego pensemos en la escala en la que mi arquitectura entera los miles de ricos que atiendo por segundo se transforman en cientos de miles de ricos adentro de mis istevas. Cada mil y segundo que yo le gane va a ser un mil y segundo menos de cómputo, mil y segundo menos de tráfico y eso se transforma por lo que creen costos. Bien, el mejor es en costos. Entonces los otros vivimos que se estaba usando de forma naive, Riquest, trabajamos con múltiples equipos entre la organización. Veamos que estaban usando Riquest así no más como Quick Start y hicimos algunos benchmarks usando session y en particular el happy que hacemos con Rudy empezamos a usar sessions. Claro. Y vimos mejoras impresionantes con realmente como poco cambio. Por ejemplo, la cantidad de ricos que puedo hacer eso por segundo con el primer vea su eco, digo, son alrededor de 500. Usando sessions se duplicó, se duplicó la cantidad de ricos que puedo hacer eso en un segundo haciendo tres líneas de código de cambio. Bien, acá bueno el vea no me quiero hacer refoco en el benchmark si pero bueno hicimos esto es una prueba local, obviamente la cantidad de ricos que puedan hacer por segundo va a vender 1 millón de cosas. Cuando probas R, tratas de australerte de la RID y usas tu propia interfaz de tu máquina como para tener algo consistente. Entonces realmente por hacer tres líneas de código de cambio ganamos una performance en cuanto a la cantidad rico que podemos hacer por segundo del doble. También es más impresionante en una esquema chiste de TPS donde toda la negociación de certificados de SCL, metetanto a Vergette, que yo podía hacer 146 ricos por segundo, habría desarrollándolo con acción y pasando sesiones, pasó a mil, o sea el cambio y la gana se realmente impresionante. Entonces bueno y también todo el que priori no habíamos pensado pero que terminó sucediendo es que el uso de CPU, el mi aplicación, casi pasó la mitad. Porque todas estas cosas que estaban haciendo ricos por abajo no las tiene que hacer más y si estamos pagando por CPU, por ejemplo comprando instancias en la 9, tal vez si tengo múltiples instancias, bueno usarla menos significa costo, mejoras en costos, o si tienen datos entre en su pieza, no sé menos calor, algo pero... La ventaja para todos, entonces bueno a ver por qué estamos usando ricos, porque estábamos usando ricos, tiene una interfaz espectacular, realmente muy amigable, muy simple hacer un llamado de Jueves, después tiene un montón de ventajas asociadas a las aplicaciones web tradicionales, no necesariamente a micro-servings, entonces manejos de cookies, verificaciones de cosas de seguridad, decodificación de contenido, streaming, chunking de vio de datos, tiene un montón de ventajas que están buenísimas, de las cuales a nosotros prácticamente no nos interesa ninguna. Está bien, te va a ir a empezar muy rápido, pero en el fondo usa un relícter. Hay alguna aclaración, esto no se trata de comparar cosas, no queremos hacer comparaciones, las comparaciones son odiosas, en realidad estamos tratando de ver distintas herramientas, yo oí lo veo como rico es una herramienta para resolver algunos tipos problemas y Jueves relíctres, que es lo que voy a hablar un poquito ahora, es una herramienta para resolver otro tipo de problema, que estamos comparando que una es mejor que otra, son cosas diferentes, en el caso de web relíctres, lo primero que fuimos a analizar es ¿qué tan diferente es la interfaz? Porque esto lo tenemos a replicar en 300 equipos, tenemos aligo un mensaje a 300 equipos de heche, deberíamos empezar a utilizar este herramienta porque ahí lo vamos a ver más adelante, y nos encontramos que si bien no están amigables, acá no puede utilizar como así con rico es de no hacer una sesión, acá realmente hay que hacer un pull, lo sision de rico es en el fondo, hace un pull de web relíctres, hay que ser más explícito en los parámetros, no es tan que los adivinos mágicamente, igual son dos parámetros, uno dice a cuántos dominios diferente va a mantener una conexión, por ejemplo si me conecto a 5 microservicios, el número de pull es 5, el maxize que está ahí como 10 es la cantidad de hilos que vamos a tener abierto por cada pull, entonces si estamos trabajando con un unicornbudo lsg y estamos haciendo Tridin y vamos a poner 10 hilos, sabemos que ahí tenemos que poner un número 10 o más, esto no es un número duro, no es que si de repente hay más hilos corriendo insestables en más conexiones no nos va a permitir, lo que va a pasar, que cuando se cumple un timeout va a ir eliminando conexiones y siempre va a dejar 10 establecidas y las otras se van a tener establecer cuando siguen inicion, después en el uso y es un poco raro en realidad el get no es un método y es un parámetro, los fields, hay cosas que realmente el interfaz rico es tan buenísima y no la tenemos en un lugar relíctres, pero haciendo un análisis rápido tampoco es inentendible, no es que hoy vemos esto todo lo que estamos acá y vamos a entender que eso quiere hacer un get a esta URL y que le quiere pasar esta parámetros, y simolas mivas pruebas que veníamos haciendo exactamente el mismo escenario y encontramos que con solo esos cambios que no son menores, si uno ya tiene un proveo de acto que está establecido, que es grande y tiene muchos testes escritos con ricos y ricos most, son cambios importantes pero ya teníamos un 30% de adancia y no es poco un 30%, 30% es un montón cuando tienen millones de ricos que se están ejecutando, entonces pasamos de mil que le teníamos antes a mil 300, en ese momento ya estamos en canchila, habíamos pasado de un mes, no sé si algo que usan acá o una mala palabra que van a Cualombia, si no, no es la de la idea, o sea habíamos trabajado un mes aproximadamente haciendo estas pruebas y estos cambios probándolo en API y ya estamos al doble y un poquito más del doble y que muy bueno, investimos un poquito más, vamos más allá, somos una compañía grande, tenemos muchas apes que escrita en Python, tenemos tiempos para hacer estas cosas, entonces bueno juguemos, empezamos a investigar y obviamente ir de Python a C, que es Pycool, está hecho en C, sabíamos que vamos a tener alguna ventaja en tiempo, ahora teníamos enalizar cuáles son las desventajas de usar Pycool, porque no todo de gratis en la vida, entonces empezamos a investigar Cool, lo primero que vimos en la documentación es que es para usuarios avanzados, para hacer docena de conexiones con currentes, esos fichules sustificados y la documentación está escrito en HTML1.0, yo que venía de Rit de Doc, si tuviste estas cosas bonitas y con buscadores en pese a leer esa documentación y dije no, o porque me estoy metiendo acá, pero bueno, nada, tenía el tiempo, somos informáticos, nos gusta hacer estas cosas, investe un poquito más, empecé a jugar y dije bueno voy a hacer mi primer get in Pycool. Esto es copy page de la documentación de Pycool, cual disclaíbero en la web page, está buenísimo, el que habéis anotradición. Y está muy bien, ¿por qué, ¿quién usted usa Pycool? Un valiente, o relíptr… O relíptr… O relíptr… ¿quién usa? Ahí está, va, vámonos. Tengo que trabajar con los audicios, hablemos en un rato. Pero sí, acá Pycool está diciendo, sin necesitas docenas de llamadas con currentes y unos confusios sofisticados, entonces ya está avisando que, también, si lo que único que queréis hacerle un post a la lista de, no sé qué pública, no hace falta, pero capaz de una vez que más microsaricios, donde queréis hacer docenas de concurrentes ricos, si tenés advanced developers que se la banquen, puede llegar a tener sentido. Igual vamos a llegar a esa parte, avance de nivel, pero sí, vamos a hacer falta. Lo primero que vimos cuando hicimos las pruebas es que ya duplicamos lo que habíamos duplicado. La verdad está, súper contento, eso tenía muchísimas ganas de implementar esto, decirlo a todo el mundo. Por favor, usted, en Pycool, es la que va, me junté con listos, con Javi, un poco analizar el Javi, es un batuchivo de trabajo con nosotros, analizar esto y empezamos a ver un poco cómo se hace el gays y cómo se usa y no los convencía mucho. Esto es importantísimo, el uso de CPU se fue al 0.73% La gente que está usando mucho Python y en mercado libre hace machine learning cada porcentaje de CPU que le liberamos, es jugo para eso. Tenemos que salir con esto rápido producción, ¿cómo hacemos? Es un get in Pycool. Se recuerdan, bueno, todo usado, un rico es rico es punto get y ya estás haciendo un get. Y acá hay tan color al tovard 1, no sé si un color ambia bardo significa lo mismo que significa de Argentina. Un gran problema, uno. Un gran problema, uno, un gran problema. La forma que uno le tiene que pasar los parámetros, no es un diccionario común, realmente es súper complejo, súper confuso. Yo hace 5 años estoy con Python y venía a esto y decía por qué, por favor, ¿por qué es así? Pero bueno, tiene sus ventajas, tiene la ventaja de duplicar la cantidad rico de Google, de USB3, de uso de CPU, tenemos que ver que así. Creo que el post no se lo puse, bueno, el post, un get in Pycool es doblemente lo arduo. Imagínense, te esté a adreso, es como te esté a este oeste de pedazo de código, como reparto este código en 300 o 400 aplicaciones. Muy difícil. Te he ganado de cuenta que todos conocen ricos, nosotros también conocíamos ricos, entonces, ¿cuándo tienes que hacer una solución? ¿Ustedes ricos? El momento 0, no te lo preguntaste, lo cual es un problema en un contexto productivo, si están haciendo un apoc, si están haciendo un prototipo, si están haciendo una prueba, hay preguntas que no necesitan trabajarnos. Pero cuando vamos a un entorno productivo, sobre todo de escala, tenemos que ser mucho más detallas. Entonces, haber elegido ricos como librería de comunicación entre procesos, es de auto-tech. Es un riesgo que estamos tomando y que en algún momento nos puede costar y que en algún momento, ese costo, como cualquier deuda, con sus literes, se va a ser más caro. Y nosotros no nos dimos cuenta. Y nos dimos cuenta cuando nos dimos cuenta que había que implementar esto. Con cada rico es que teníamos en cada una de los hoy por hoy cientos de micros servicios de pliego en Python que tenemos. Son muchos equipos de trabajo trabajando y si cada una de esos equipos se le digo, esa línea no, repasar las por estas 75 que tenemos acá. Y listo. Otra cosa que teníamos en Python y que era súper interesante y no logramos hacer con ricos y vos relic tres. En un entorno productivo hacer monitoring es súper importante medir. Hay que medir todo lo que se pueda. En mercado de libre nos gusta medir mucho y medimos cada cosa que sucede. Por ejemplo, si val de NS, nos queremos medir por cada rico, es que sale cuánto tiempo tardó y en ir y volver al NS. Si hay una conexión cuánto tiempo se tardó en establecer esa conexión. Si el payload cuánto tiempo tardó todos esos detalles en librerías de bajo nivel como parical podíamos obtener las y en el de alto nivel, realmente teníamos de entrar a muyificar el código en la librería y era bastante complejo. Entonces hay un poco gran y veíamos como la ventaja de poder monitorear muchísimo mejor los micros servicios que te veníamos y era otra cosa a favor que nos decías che tenemos aquí por este camino. ¿Tío, ¿no? Insay, un poco lo que venimos charlando, lo que venimos contando. Ricos desde alto nivel, está buenísimo para empezar. Está buenísimo si una cedata science y tiene que hacer algunas búsqueda. No quiero un mail que me diga después che, me dijiste paico de buenísimo, mirad, tenía que hacer un rico Google para sacar algo estuve tres días. No estamos vendiendo eso. Ricos es un excelente herramienta para utilizarla en el contexto que se tiene que utilizar. Hay opciones de optimizaciones, hay que leerla, a mí me he dado mucho la atención que la opción de optimización de esto decision en Ricos está en uso avanzado. Personalmente considero que no están avanzados, me parece bastante sencillo poder utilizar un feature como eso, capaz que entender en el fondo que lo que hace puede ser complejo, pero como feature de la librería es algo relativamente básico. Como toda optimización, siempre, avoy de early optimization, early optimization, is the root of all evil, dijo algún viejo pop de la informática. Bueno, no acabamos de optimizar la entrada, entonces sí, a camismo estamos viendo que informas de optimizar la manera de hacer ricos, tengo la en cuenta de función de su caso de uso. Después, las buenas prácticas en que nierías aplican para todos, las prácticas que conocemos, de no optimizar antes de tiempo, de empezar, esto es algo que me lo discuta, a mí me gusta empezar a desarrollar pensando que está todo bien y después pensar en las cosas que pueden fallar, creo que una charla hace unos días, de 100 todos los contrarios, a mí me gusta hacer optimista y después ir agregando complejidad. Entonces, esas buenas prácticas que hay que hemos estudiado sirven para los macros y para los micros también, en este caso. Entonces bueno, les mostramos lo que estamos haciendo, les contamos que encontramos formas de optimizarlo, entonces ahora le queremos contarlo el próximo paso, no el final, sino el próximo paso, que hicimos en Mercado Libre con todo esto o por lo menos en el marco nuestros equipos, primero lo queremos esta filmina de marketing, es un poco para que entienda la cuestión de envergadura y de escala, que realmente en nuestro caso, porque tiene sentido hacer lo que hicimos, lo que lo podemos demostrar, en Mercado Libre hay 6 mil busques por segundo, una búsqueda desde el browser dispara un montón de ricos, y cada uno de esos ricos adentro nuestro sistema se multiplica, entonces imagínese el volumen de transacciones con los envíos, con las compras, con cada uno de los pagos a través de mercados pagos cada item que se crea cada usuario que entra, son literalmente millones de ricos por segundo, que se multiplica dentro nuestro sistema, probablemente se no sea el caso de uso de todos ustedes, lo cual no significa que les cala, la que esté trabajando, no sea importante considerar esto lo mismo, pero para nosotros que veníamos de la empresa más chica, que en Mercado Libre del Quirio nos encontramos con esta escala y el día de hoy sigue siendo impresionante, porque lo vemos en el día de día, entonces quéis hicimos con todo esto de sabemos que podemos optimizar la forma de conectar microciarizos en Python, básicamente hicimos una librería, una rest client, una abstractión de la capa de comunicación HTTP, hay que poder que podriamos haber hecho desde el inicio, lo que pasa es que esa rico es tan fácil, no veíamos la necesidad de hacerlo raper. Sí, a partir de eso yo recuerdo entre en un proyecto el primer día y dije, bueno, cinco mil ricos, voy a tener dos mil ricos, esto lo hizo una prueba en mi máquina esta bandar, después salió producción, tenía 200 mil ricos por segundo, entonces ahí me di cuenta que ahí me va a discutirme el che para, hay que hacer cosas con esto, no es tan senciso, El happy, en Mercado Libre no funciona, el approach naive de entrada, no funciona nunca, de entrada tienes que pensar entre 10 mil y 50 mil ricos por minuto, el 10KRPB, el 50KRPB, es algo que para nosotros todavía es chico, cuando queremos probar infraestructuras, por ejemplo, haremos un happy de 600, 700KRPB, son happy que se les está pegando fuerte, pero no son la más grande del sitio, se nos va a meter el escalje grande, cuando estamos en esta máquina, nos metemos al medio de casi todos los flujos importantes del negocio, perdiciendo, categorizando, recomendando, entonces por más que hay mucho go dando vuelta en la compañía, pero utilizar estas cosas es mucho jable en el lógica de negocios, Python de repente con una capillaria muy grande, apalancado por el Machine Learning, se ve a ti, entonces lo que hicimos hace poco es esta hora librería para que los desarrolladores ahora instancia en una librería un res client, que esconder todos los detalles de implementación y toda la lógica de negocios relacionada a conectar microservices de la compañía y obviamente ya que nos gustaba tanto el interfaz rico, si intentamos hacer algo, realmente parecido y ahí varios desafíos, toda la comunidad patónica que está trabajando, están muy familiarizadas con rico, entonces no fue solamente hacer una buena interfaz parecida a la de rico, es para esta herramienta, sino que después nos encontramos que todas las herramientas que hay alrededor de rico es como rico es mo, para testiarla nos dejaban de servir, entonces también tuvimos que desarrollar herramientas para testiar nuestro res client que sean parecidas, porque la comunidad estaba acostumbrada, no fue trivial de sentarse una, dos semanas y grabiéral algo, sino que realmente hubo que sentarse, hacer ni que ni hería, diseñarlo, pensarlo, probarlo ir y volver y algunas cosas interesantes que sucedieron, hoy por una cuestión de que uno no puede aplicar un cambio masivamente en toda la compañía, porque es muy riesgoso, el res client nosotros vamos agregando lo que llamamos en jeans, que básicamente empezamos con un rico es en el fondo, que estamos seguro que andaba con sesión, despagaramos un relipter y de a poquito fuimos migrando algunas apicas, usan esta implementación y después anpaiculi, simulos mismos fuimos migrando, y fue muy interesante ver como equipos hacían los diploi y decían, mira no sé qué hicimos, no es súper rapidora, nosotros estamos haciendo todo a H, me parece que está funcionando esto, pero esto que se lo cuento como chiste es, es el valor de por poder tener herramientas de la compañía que impacten en toda la compañía con un solo cambio, nosotros hacemos una nueva versión de esta librería y estamos impactando en todos los microservicios que están en Python, que si no lo hubiéramos hecho tendríamos que haber hecho que decía delito que decir che bueno esta línea ahora la cambia en por esta 70, entonces tomar decisión y adicuñar es parte de comunicar microservicio, no es solamente una cuestión de optimizar la performance. Bueno luego que llevamos con partidos este es un caso de uso propio es parte de lo que lo que nos sirvió tiene sus prois sus contras, porque ahora esta librería le tiene que mantener a alguien, si el sistema de recomendaciones de mercado libre encuentro un vaga o una limitación de esta librería obviamente alguien lo tiene que resolver y ese alguien en este caso somos nosotros, entonces de nuevo depende el caso de uso hay que responsabilizarse por las herramientas que hacemos, como dice Rudy los pros son muchísimos, las contras no tantas como para que nos animamos, lo que tenemos el Thermal Marcha, ¡Uchan ausosIO!',\n",
              " 'segments': [{'id': 0,\n",
              "   'seek': 0,\n",
              "   'start': 0.0,\n",
              "   'end': 24.400000000000002,\n",
              "   'text': ' Bueno, quién soy Rodolfo Edelman, me van a escuchar ahí que me dicen Rudy.',\n",
              "   'tokens': [50364,\n",
              "    16046,\n",
              "    11,\n",
              "    35327,\n",
              "    8812,\n",
              "    11097,\n",
              "    7491,\n",
              "    78,\n",
              "    3977,\n",
              "    338,\n",
              "    1601,\n",
              "    11,\n",
              "    385,\n",
              "    3161,\n",
              "    257,\n",
              "    22483,\n",
              "    289,\n",
              "    12571,\n",
              "    631,\n",
              "    385,\n",
              "    33816,\n",
              "    38690,\n",
              "    13,\n",
              "    51584],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.5263050886300894,\n",
              "   'compression_ratio': 0.9382716049382716,\n",
              "   'no_speech_prob': 0.06435789912939072},\n",
              "  {'id': 1,\n",
              "   'seek': 2440,\n",
              "   'start': 24.4,\n",
              "   'end': 32.4,\n",
              "   'text': ' Tiengan cuidado si me llaman Digan Rudy con Deno con B. Larga, porque con Ferencia Python se pueden ojar a alguien.',\n",
              "   'tokens': [50364,\n",
              "    314,\n",
              "    1053,\n",
              "    1275,\n",
              "    31891,\n",
              "    1511,\n",
              "    385,\n",
              "    4849,\n",
              "    6147,\n",
              "    413,\n",
              "    9552,\n",
              "    38690,\n",
              "    416,\n",
              "    6458,\n",
              "    78,\n",
              "    416,\n",
              "    363,\n",
              "    13,\n",
              "    11569,\n",
              "    3680,\n",
              "    11,\n",
              "    4021,\n",
              "    416,\n",
              "    479,\n",
              "    5170,\n",
              "    2755,\n",
              "    15329,\n",
              "    369,\n",
              "    14714,\n",
              "    277,\n",
              "    10150,\n",
              "    257,\n",
              "    25814,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4298181339186065,\n",
              "   'compression_ratio': 1.5363636363636364,\n",
              "   'no_speech_prob': 0.5033178925514221},\n",
              "  {'id': 2,\n",
              "   'seek': 2440,\n",
              "   'start': 33.4,\n",
              "   'end': 39.4,\n",
              "   'text': ' Hace 5 años estoy trabajando con Python antes de trabajar con Ruby, eso no lo voy a contermas.',\n",
              "   'tokens': [50814,\n",
              "    389,\n",
              "    617,\n",
              "    1025,\n",
              "    11424,\n",
              "    15796,\n",
              "    40473,\n",
              "    416,\n",
              "    15329,\n",
              "    11014,\n",
              "    368,\n",
              "    30793,\n",
              "    416,\n",
              "    19907,\n",
              "    11,\n",
              "    7287,\n",
              "    572,\n",
              "    450,\n",
              "    7552,\n",
              "    257,\n",
              "    660,\n",
              "    966,\n",
              "    296,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4298181339186065,\n",
              "   'compression_ratio': 1.5363636363636364,\n",
              "   'no_speech_prob': 0.5033178925514221},\n",
              "  {'id': 3,\n",
              "   'seek': 2440,\n",
              "   'start': 40.4,\n",
              "   'end': 45.4,\n",
              "   'text': ' Trabajé mucho tiempo a la Universidad Nacional de Córdoba, a esa foto en el Cláster de la Universidad Nacional de Córdoba.',\n",
              "   'tokens': [51164,\n",
              "    314,\n",
              "    5305,\n",
              "    1805,\n",
              "    526,\n",
              "    9824,\n",
              "    11772,\n",
              "    257,\n",
              "    635,\n",
              "    14052,\n",
              "    4580,\n",
              "    36623,\n",
              "    368,\n",
              "    41306,\n",
              "    7800,\n",
              "    19481,\n",
              "    11,\n",
              "    257,\n",
              "    11342,\n",
              "    19176,\n",
              "    465,\n",
              "    806,\n",
              "    2033,\n",
              "    842,\n",
              "    3120,\n",
              "    368,\n",
              "    635,\n",
              "    14052,\n",
              "    4580,\n",
              "    36623,\n",
              "    368,\n",
              "    41306,\n",
              "    7800,\n",
              "    19481,\n",
              "    13,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4298181339186065,\n",
              "   'compression_ratio': 1.5363636363636364,\n",
              "   'no_speech_prob': 0.5033178925514221},\n",
              "  {'id': 4,\n",
              "   'seek': 4540,\n",
              "   'start': 45.4,\n",
              "   'end': 62.4,\n",
              "   'text': ' Hace mucho de Robots, después abancé a Bakken, de Bakken, empezó a hacer Machine Learning y actualmente estoy como técnica al Manaller en Mercado de Libre, desarrollando productos, servicios internos de la compañía que nos sirven para poner modelos de Machine Learning en producción.',\n",
              "   'tokens': [50364,\n",
              "    389,\n",
              "    617,\n",
              "    9824,\n",
              "    368,\n",
              "    5424,\n",
              "    1971,\n",
              "    11,\n",
              "    15283,\n",
              "    410,\n",
              "    282,\n",
              "    13523,\n",
              "    257,\n",
              "    12063,\n",
              "    2653,\n",
              "    11,\n",
              "    368,\n",
              "    12063,\n",
              "    2653,\n",
              "    11,\n",
              "    18730,\n",
              "    812,\n",
              "    257,\n",
              "    6720,\n",
              "    22155,\n",
              "    15205,\n",
              "    288,\n",
              "    3539,\n",
              "    4082,\n",
              "    15796,\n",
              "    2617,\n",
              "    45411,\n",
              "    419,\n",
              "    2458,\n",
              "    336,\n",
              "    260,\n",
              "    465,\n",
              "    18897,\n",
              "    1573,\n",
              "    368,\n",
              "    15834,\n",
              "    265,\n",
              "    11,\n",
              "    32501,\n",
              "    1806,\n",
              "    46363,\n",
              "    11,\n",
              "    42722,\n",
              "    2154,\n",
              "    329,\n",
              "    368,\n",
              "    635,\n",
              "    29953,\n",
              "    2686,\n",
              "    631,\n",
              "    3269,\n",
              "    4735,\n",
              "    553,\n",
              "    1690,\n",
              "    19149,\n",
              "    2316,\n",
              "    329,\n",
              "    368,\n",
              "    22155,\n",
              "    15205,\n",
              "    465,\n",
              "    48586,\n",
              "    13,\n",
              "    51214],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.49465243917115975,\n",
              "   'compression_ratio': 1.4427860696517414,\n",
              "   'no_speech_prob': 0.15044036507606506},\n",
              "  {'id': 5,\n",
              "   'seek': 6240,\n",
              "   'start': 62.4,\n",
              "   'end': 74.4,\n",
              "   'text': ' Hola, yo soy Litox, Carlos de la Torre, me dicen Litox en la Uroschatz y en las comunidades de Python y en la tele, pero eso todavía no se se llenó nunca.',\n",
              "   'tokens': [50364,\n",
              "    22637,\n",
              "    11,\n",
              "    5290,\n",
              "    8812,\n",
              "    441,\n",
              "    3528,\n",
              "    87,\n",
              "    11,\n",
              "    19646,\n",
              "    368,\n",
              "    635,\n",
              "    7160,\n",
              "    265,\n",
              "    11,\n",
              "    385,\n",
              "    33816,\n",
              "    441,\n",
              "    3528,\n",
              "    87,\n",
              "    465,\n",
              "    635,\n",
              "    624,\n",
              "    2635,\n",
              "    339,\n",
              "    10300,\n",
              "    288,\n",
              "    465,\n",
              "    2439,\n",
              "    11040,\n",
              "    10284,\n",
              "    368,\n",
              "    15329,\n",
              "    288,\n",
              "    465,\n",
              "    635,\n",
              "    4304,\n",
              "    11,\n",
              "    4768,\n",
              "    7287,\n",
              "    28388,\n",
              "    572,\n",
              "    369,\n",
              "    369,\n",
              "    4849,\n",
              "    268,\n",
              "    812,\n",
              "    13768,\n",
              "    13,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.39367282838749706,\n",
              "   'compression_ratio': 1.5533980582524272,\n",
              "   'no_speech_prob': 0.41979941725730896},\n",
              "  {'id': 6,\n",
              "   'seek': 6240,\n",
              "   'start': 75.4,\n",
              "   'end': 91.4,\n",
              "   'text': ' Trabajo con Ruy hace muchos años, también soy técnica al Manaller, tengo un recorrido de su licencia informática y de desarrollador, técnica leader, retabajado en empresas nacionales, en Argentina, en Pymes, pequeñas empresas, ahora en Mercado de Libre estamos como hizo Rudy armando la infraestructura para ejecutar.',\n",
              "   'tokens': [51014,\n",
              "    314,\n",
              "    5305,\n",
              "    13440,\n",
              "    416,\n",
              "    497,\n",
              "    7493,\n",
              "    10032,\n",
              "    17061,\n",
              "    11424,\n",
              "    11,\n",
              "    6407,\n",
              "    8812,\n",
              "    45411,\n",
              "    419,\n",
              "    2458,\n",
              "    336,\n",
              "    260,\n",
              "    11,\n",
              "    13989,\n",
              "    517,\n",
              "    850,\n",
              "    24362,\n",
              "    2925,\n",
              "    368,\n",
              "    459,\n",
              "    6169,\n",
              "    10974,\n",
              "    1356,\n",
              "    23432,\n",
              "    288,\n",
              "    368,\n",
              "    32501,\n",
              "    5409,\n",
              "    11,\n",
              "    45411,\n",
              "    5263,\n",
              "    11,\n",
              "    319,\n",
              "    1328,\n",
              "    9338,\n",
              "    1573,\n",
              "    465,\n",
              "    26433,\n",
              "    29836,\n",
              "    279,\n",
              "    11,\n",
              "    465,\n",
              "    18336,\n",
              "    11,\n",
              "    465,\n",
              "    430,\n",
              "    4199,\n",
              "    279,\n",
              "    11,\n",
              "    19132,\n",
              "    32448,\n",
              "    26433,\n",
              "    11,\n",
              "    9923,\n",
              "    465,\n",
              "    18897,\n",
              "    1573,\n",
              "    368,\n",
              "    15834,\n",
              "    265,\n",
              "    10382,\n",
              "    2617,\n",
              "    28803,\n",
              "    38690,\n",
              "    3726,\n",
              "    1806,\n",
              "    635,\n",
              "    23654,\n",
              "    43056,\n",
              "    2991,\n",
              "    1690,\n",
              "    39564,\n",
              "    6672,\n",
              "    289,\n",
              "    13,\n",
              "    51814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.39367282838749706,\n",
              "   'compression_ratio': 1.5533980582524272,\n",
              "   'no_speech_prob': 0.41979941725730896},\n",
              "  {'id': 7,\n",
              "   'seek': 9240,\n",
              "   'start': 92.4,\n",
              "   'end': 99.4,\n",
              "   'text': ' Machine Learning en producción y a escala. Bueno, queremos entonces contarles un poquito de qué va a ser la charla.',\n",
              "   'tokens': [50364,\n",
              "    22155,\n",
              "    15205,\n",
              "    465,\n",
              "    48586,\n",
              "    288,\n",
              "    257,\n",
              "    4721,\n",
              "    5159,\n",
              "    13,\n",
              "    16046,\n",
              "    11,\n",
              "    26813,\n",
              "    13003,\n",
              "    27045,\n",
              "    904,\n",
              "    517,\n",
              "    28229,\n",
              "    368,\n",
              "    8057,\n",
              "    2773,\n",
              "    257,\n",
              "    816,\n",
              "    635,\n",
              "    1290,\n",
              "    875,\n",
              "    13,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31025491976270486,\n",
              "   'compression_ratio': 1.537037037037037,\n",
              "   'no_speech_prob': 0.007691541220992804},\n",
              "  {'id': 8,\n",
              "   'seek': 9240,\n",
              "   'start': 101.4,\n",
              "   'end': 110.4,\n",
              "   'text': ' Primero que todos para entender el motivo de la charla tenemos que entender porque creamos microsや servicios, ¿cómo hacemos esto en Python?',\n",
              "   'tokens': [50814,\n",
              "    19671,\n",
              "    2032,\n",
              "    631,\n",
              "    6321,\n",
              "    1690,\n",
              "    20054,\n",
              "    806,\n",
              "    35804,\n",
              "    368,\n",
              "    635,\n",
              "    1290,\n",
              "    875,\n",
              "    9914,\n",
              "    631,\n",
              "    20054,\n",
              "    4021,\n",
              "    1197,\n",
              "    2151,\n",
              "    15547,\n",
              "    7355,\n",
              "    42722,\n",
              "    11,\n",
              "    3841,\n",
              "    46614,\n",
              "    33839,\n",
              "    7433,\n",
              "    465,\n",
              "    15329,\n",
              "    30,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31025491976270486,\n",
              "   'compression_ratio': 1.537037037037037,\n",
              "   'no_speech_prob': 0.007691541220992804},\n",
              "  {'id': 9,\n",
              "   'seek': 9240,\n",
              "   'start': 110.4,\n",
              "   'end': 118.4,\n",
              "   'text': ' Está normalmente, ¿cuáles son los insas que fuimos sacando, teniendo en estos años de desarrollo, un poco eso y algunos casos de uso que vamos a ver.',\n",
              "   'tokens': [51264,\n",
              "    4410,\n",
              "    842,\n",
              "    38217,\n",
              "    11,\n",
              "    3841,\n",
              "    12032,\n",
              "    842,\n",
              "    904,\n",
              "    1872,\n",
              "    1750,\n",
              "    1028,\n",
              "    296,\n",
              "    631,\n",
              "    8536,\n",
              "    8372,\n",
              "    4899,\n",
              "    1806,\n",
              "    11,\n",
              "    2064,\n",
              "    7304,\n",
              "    465,\n",
              "    12585,\n",
              "    11424,\n",
              "    368,\n",
              "    38295,\n",
              "    11,\n",
              "    517,\n",
              "    10639,\n",
              "    7287,\n",
              "    288,\n",
              "    21078,\n",
              "    25135,\n",
              "    368,\n",
              "    22728,\n",
              "    631,\n",
              "    5295,\n",
              "    257,\n",
              "    1306,\n",
              "    13,\n",
              "    51664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31025491976270486,\n",
              "   'compression_ratio': 1.537037037037037,\n",
              "   'no_speech_prob': 0.007691541220992804},\n",
              "  {'id': 10,\n",
              "   'seek': 11840,\n",
              "   'start': 119.4,\n",
              "   'end': 124.4,\n",
              "   'text': ' Monalito, ¿todo saben qué es monalito? Levanta la mano.',\n",
              "   'tokens': [50414,\n",
              "    4713,\n",
              "    304,\n",
              "    3528,\n",
              "    11,\n",
              "    3841,\n",
              "    83,\n",
              "    17423,\n",
              "    36670,\n",
              "    8057,\n",
              "    785,\n",
              "    1108,\n",
              "    304,\n",
              "    3528,\n",
              "    30,\n",
              "    1456,\n",
              "    5219,\n",
              "    64,\n",
              "    635,\n",
              "    18384,\n",
              "    13,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.29526551564534503,\n",
              "   'compression_ratio': 1.476923076923077,\n",
              "   'no_speech_prob': 0.016391964629292488},\n",
              "  {'id': 11,\n",
              "   'seek': 11840,\n",
              "   'start': 127.4,\n",
              "   'end': 140.4,\n",
              "   'text': ' Normalmente bueno, por accidente. Normalmente una cuando empieza a construir el primer producto, empieza, no quiere hacer algo complejo, quiere empezar por algo que sea fácil de poner en producción rápido para validar una idea.',\n",
              "   'tokens': [50814,\n",
              "    21277,\n",
              "    4082,\n",
              "    11974,\n",
              "    11,\n",
              "    1515,\n",
              "    6398,\n",
              "    68,\n",
              "    13,\n",
              "    21277,\n",
              "    4082,\n",
              "    2002,\n",
              "    7767,\n",
              "    44577,\n",
              "    257,\n",
              "    38445,\n",
              "    806,\n",
              "    12595,\n",
              "    47583,\n",
              "    11,\n",
              "    44577,\n",
              "    11,\n",
              "    572,\n",
              "    23877,\n",
              "    6720,\n",
              "    8655,\n",
              "    44424,\n",
              "    5134,\n",
              "    11,\n",
              "    23877,\n",
              "    31168,\n",
              "    1515,\n",
              "    8655,\n",
              "    631,\n",
              "    4158,\n",
              "    17474,\n",
              "    368,\n",
              "    19149,\n",
              "    465,\n",
              "    48586,\n",
              "    24893,\n",
              "    1690,\n",
              "    7363,\n",
              "    289,\n",
              "    2002,\n",
              "    1558,\n",
              "    13,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.29526551564534503,\n",
              "   'compression_ratio': 1.476923076923077,\n",
              "   'no_speech_prob': 0.016391964629292488},\n",
              "  {'id': 12,\n",
              "   'seek': 14040,\n",
              "   'start': 141.4,\n",
              "   'end': 148.4,\n",
              "   'text': ' De esta manera es que empezamos a hacer un monalito. En la arquitectura monalito es construcción sobre un solo material.',\n",
              "   'tokens': [50414,\n",
              "    1346,\n",
              "    5283,\n",
              "    13913,\n",
              "    785,\n",
              "    631,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    6720,\n",
              "    517,\n",
              "    1108,\n",
              "    304,\n",
              "    3528,\n",
              "    13,\n",
              "    2193,\n",
              "    635,\n",
              "    40258,\n",
              "    5739,\n",
              "    2991,\n",
              "    1108,\n",
              "    304,\n",
              "    3528,\n",
              "    785,\n",
              "    12946,\n",
              "    14735,\n",
              "    5473,\n",
              "    517,\n",
              "    6944,\n",
              "    2527,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2465373363691507,\n",
              "   'compression_ratio': 1.5168067226890756,\n",
              "   'no_speech_prob': 0.017695236951112747},\n",
              "  {'id': 13,\n",
              "   'seek': 14040,\n",
              "   'start': 149.4,\n",
              "   'end': 154.4,\n",
              "   'text': ' Se hace una analogía cuando el diseño de software que tiene que ver con un estat tecnológico.',\n",
              "   'tokens': [50814,\n",
              "    1100,\n",
              "    10032,\n",
              "    2002,\n",
              "    16660,\n",
              "    2686,\n",
              "    7767,\n",
              "    806,\n",
              "    3814,\n",
              "    7716,\n",
              "    368,\n",
              "    4722,\n",
              "    631,\n",
              "    7066,\n",
              "    631,\n",
              "    1306,\n",
              "    416,\n",
              "    517,\n",
              "    30883,\n",
              "    20105,\n",
              "    27629,\n",
              "    2789,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2465373363691507,\n",
              "   'compression_ratio': 1.5168067226890756,\n",
              "   'no_speech_prob': 0.017695236951112747},\n",
              "  {'id': 14,\n",
              "   'seek': 14040,\n",
              "   'start': 154.4,\n",
              "   'end': 162.4,\n",
              "   'text': ' El ejeimo en estat tecnológico y construimos sobre ese estat. ¿Qué quiere decir? El ejeimo Python, Django, MySQL y alguna cola de mensajes.',\n",
              "   'tokens': [51064,\n",
              "    2699,\n",
              "    39564,\n",
              "    6934,\n",
              "    465,\n",
              "    30883,\n",
              "    20105,\n",
              "    27629,\n",
              "    2789,\n",
              "    288,\n",
              "    12946,\n",
              "    8372,\n",
              "    5473,\n",
              "    10167,\n",
              "    30883,\n",
              "    13,\n",
              "    3841,\n",
              "    15137,\n",
              "    23877,\n",
              "    10235,\n",
              "    30,\n",
              "    2699,\n",
              "    39564,\n",
              "    6934,\n",
              "    15329,\n",
              "    11,\n",
              "    33464,\n",
              "    17150,\n",
              "    11,\n",
              "    1222,\n",
              "    39934,\n",
              "    288,\n",
              "    20651,\n",
              "    40495,\n",
              "    368,\n",
              "    10923,\n",
              "    29362,\n",
              "    13,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2465373363691507,\n",
              "   'compression_ratio': 1.5168067226890756,\n",
              "   'no_speech_prob': 0.017695236951112747},\n",
              "  {'id': 15,\n",
              "   'seek': 16240,\n",
              "   'start': 163.4,\n",
              "   'end': 177.4,\n",
              "   'text': ' Pero esto paría producción fantástico. Vamos rápido, pero empiezan a ocurrir problemas. Cuando crece son miles y miles de líneas de códigos y esta línea de códigos se vuelven a complejas, hay una interdependencia.',\n",
              "   'tokens': [50414,\n",
              "    9377,\n",
              "    7433,\n",
              "    971,\n",
              "    2686,\n",
              "    48586,\n",
              "    4115,\n",
              "    44855,\n",
              "    13,\n",
              "    10894,\n",
              "    24893,\n",
              "    11,\n",
              "    4768,\n",
              "    4012,\n",
              "    18812,\n",
              "    282,\n",
              "    257,\n",
              "    26430,\n",
              "    10949,\n",
              "    20720,\n",
              "    13,\n",
              "    21907,\n",
              "    1197,\n",
              "    384,\n",
              "    1872,\n",
              "    6193,\n",
              "    288,\n",
              "    6193,\n",
              "    368,\n",
              "    16118,\n",
              "    716,\n",
              "    296,\n",
              "    368,\n",
              "    40210,\n",
              "    13348,\n",
              "    288,\n",
              "    5283,\n",
              "    37452,\n",
              "    368,\n",
              "    40210,\n",
              "    13348,\n",
              "    369,\n",
              "    20126,\n",
              "    553,\n",
              "    257,\n",
              "    44424,\n",
              "    19221,\n",
              "    11,\n",
              "    4842,\n",
              "    2002,\n",
              "    728,\n",
              "    36763,\n",
              "    10974,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26554446750217015,\n",
              "   'compression_ratio': 1.62987012987013,\n",
              "   'no_speech_prob': 0.03204371780157089},\n",
              "  {'id': 16,\n",
              "   'seek': 16240,\n",
              "   'start': 177.4,\n",
              "   'end': 191.4,\n",
              "   'text': ' Si queremos modificar una parte seguramente tengamos que tocar otra parte del código o romper cosas, los test son gigantescos y empezamos a encontrarnos con que viene el mano y nos dice che, ahora queremos hacer Machine Learning y nosotros estamos trabajando en God, por ejemplo.',\n",
              "   'tokens': [51114,\n",
              "    4909,\n",
              "    26813,\n",
              "    1072,\n",
              "    25625,\n",
              "    2002,\n",
              "    6975,\n",
              "    22179,\n",
              "    3439,\n",
              "    10370,\n",
              "    2151,\n",
              "    631,\n",
              "    35631,\n",
              "    13623,\n",
              "    6975,\n",
              "    1103,\n",
              "    44195,\n",
              "    277,\n",
              "    7438,\n",
              "    610,\n",
              "    12218,\n",
              "    11,\n",
              "    1750,\n",
              "    1500,\n",
              "    1872,\n",
              "    8741,\n",
              "    9327,\n",
              "    6877,\n",
              "    288,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    10176,\n",
              "    81,\n",
              "    24979,\n",
              "    416,\n",
              "    631,\n",
              "    19561,\n",
              "    806,\n",
              "    18384,\n",
              "    288,\n",
              "    3269,\n",
              "    10313,\n",
              "    947,\n",
              "    11,\n",
              "    9923,\n",
              "    26813,\n",
              "    6720,\n",
              "    22155,\n",
              "    15205,\n",
              "    288,\n",
              "    13863,\n",
              "    10382,\n",
              "    40473,\n",
              "    465,\n",
              "    1265,\n",
              "    11,\n",
              "    1515,\n",
              "    13358,\n",
              "    13,\n",
              "    51814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26554446750217015,\n",
              "   'compression_ratio': 1.62987012987013,\n",
              "   'no_speech_prob': 0.03204371780157089},\n",
              "  {'id': 17,\n",
              "   'seek': 19240,\n",
              "   'start': 192.4,\n",
              "   'end': 197.4,\n",
              "   'text': ' Y sabemos que integrar algo de Python dentro de un monolito en God es muy complicado.',\n",
              "   'tokens': [50364,\n",
              "    398,\n",
              "    27200,\n",
              "    631,\n",
              "    3572,\n",
              "    289,\n",
              "    8655,\n",
              "    368,\n",
              "    15329,\n",
              "    10856,\n",
              "    368,\n",
              "    517,\n",
              "    1108,\n",
              "    401,\n",
              "    3528,\n",
              "    465,\n",
              "    1265,\n",
              "    785,\n",
              "    5323,\n",
              "    49850,\n",
              "    13,\n",
              "    50614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.14352378138789423,\n",
              "   'compression_ratio': 1.6349809885931559,\n",
              "   'no_speech_prob': 0.0029342363122850657},\n",
              "  {'id': 18,\n",
              "   'seek': 19240,\n",
              "   'start': 197.4,\n",
              "   'end': 208.4,\n",
              "   'text': ' Entonces por estos motivos es que las compañías cuando crecen y empiezan a hacer software mucho más complejo, empiezan a tomar decisiones de separar este monolito en pequeñas piezas.',\n",
              "   'tokens': [50614,\n",
              "    15097,\n",
              "    1515,\n",
              "    12585,\n",
              "    5426,\n",
              "    329,\n",
              "    785,\n",
              "    631,\n",
              "    2439,\n",
              "    29953,\n",
              "    10025,\n",
              "    7767,\n",
              "    1197,\n",
              "    13037,\n",
              "    288,\n",
              "    4012,\n",
              "    18812,\n",
              "    282,\n",
              "    257,\n",
              "    6720,\n",
              "    4722,\n",
              "    9824,\n",
              "    3573,\n",
              "    44424,\n",
              "    5134,\n",
              "    11,\n",
              "    4012,\n",
              "    18812,\n",
              "    282,\n",
              "    257,\n",
              "    22048,\n",
              "    3537,\n",
              "    279,\n",
              "    368,\n",
              "    3128,\n",
              "    289,\n",
              "    4065,\n",
              "    1108,\n",
              "    401,\n",
              "    3528,\n",
              "    465,\n",
              "    19132,\n",
              "    32448,\n",
              "    1730,\n",
              "    24561,\n",
              "    13,\n",
              "    51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.14352378138789423,\n",
              "   'compression_ratio': 1.6349809885931559,\n",
              "   'no_speech_prob': 0.0029342363122850657},\n",
              "  {'id': 19,\n",
              "   'seek': 19240,\n",
              "   'start': 208.4,\n",
              "   'end': 216.4,\n",
              "   'text': ' Estas pequeñas piezas que hoy les llamamos micros servicios, nos dan la inventaja de que podemos elegir el stack que nos interesa para resolver el problema.',\n",
              "   'tokens': [51164,\n",
              "    4410,\n",
              "    296,\n",
              "    19132,\n",
              "    32448,\n",
              "    1730,\n",
              "    24561,\n",
              "    631,\n",
              "    13775,\n",
              "    1512,\n",
              "    16848,\n",
              "    2151,\n",
              "    15547,\n",
              "    42722,\n",
              "    11,\n",
              "    3269,\n",
              "    3277,\n",
              "    635,\n",
              "    7962,\n",
              "    12908,\n",
              "    368,\n",
              "    631,\n",
              "    12234,\n",
              "    14459,\n",
              "    347,\n",
              "    806,\n",
              "    8630,\n",
              "    631,\n",
              "    3269,\n",
              "    728,\n",
              "    13708,\n",
              "    1690,\n",
              "    34480,\n",
              "    806,\n",
              "    12395,\n",
              "    13,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.14352378138789423,\n",
              "   'compression_ratio': 1.6349809885931559,\n",
              "   'no_speech_prob': 0.0029342363122850657},\n",
              "  {'id': 20,\n",
              "   'seek': 21640,\n",
              "   'start': 216.4,\n",
              "   'end': 221.4,\n",
              "   'text': ' O sea el martizo para clavar, el serrucho para cortan madera.',\n",
              "   'tokens': [50364,\n",
              "    422,\n",
              "    4158,\n",
              "    806,\n",
              "    12396,\n",
              "    19055,\n",
              "    1690,\n",
              "    596,\n",
              "    706,\n",
              "    289,\n",
              "    11,\n",
              "    806,\n",
              "    816,\n",
              "    81,\n",
              "    625,\n",
              "    78,\n",
              "    1690,\n",
              "    11278,\n",
              "    282,\n",
              "    5244,\n",
              "    1663,\n",
              "    13,\n",
              "    50614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2195517903282529,\n",
              "   'compression_ratio': 1.639344262295082,\n",
              "   'no_speech_prob': 0.04739801213145256},\n",
              "  {'id': 21,\n",
              "   'seek': 21640,\n",
              "   'start': 221.4,\n",
              "   'end': 228.4,\n",
              "   'text': ' Este imagen que se ve acá, que no se ve mucho detalle, pero son muchos puntitos y muchas líneas azul.',\n",
              "   'tokens': [50614,\n",
              "    16105,\n",
              "    40652,\n",
              "    631,\n",
              "    369,\n",
              "    1241,\n",
              "    23496,\n",
              "    11,\n",
              "    631,\n",
              "    572,\n",
              "    369,\n",
              "    1241,\n",
              "    9824,\n",
              "    1141,\n",
              "    11780,\n",
              "    11,\n",
              "    4768,\n",
              "    1872,\n",
              "    17061,\n",
              "    18212,\n",
              "    11343,\n",
              "    288,\n",
              "    16072,\n",
              "    16118,\n",
              "    716,\n",
              "    296,\n",
              "    39580,\n",
              "    13,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2195517903282529,\n",
              "   'compression_ratio': 1.639344262295082,\n",
              "   'no_speech_prob': 0.04739801213145256},\n",
              "  {'id': 22,\n",
              "   'seek': 21640,\n",
              "   'start': 228.4,\n",
              "   'end': 237.4,\n",
              "   'text': ' Esos puntitos representan micros servicios. Son cada uno de esos puntitos de micros servicios y cada línea azul es una comunicación.',\n",
              "   'tokens': [50964,\n",
              "    2313,\n",
              "    329,\n",
              "    18212,\n",
              "    11343,\n",
              "    2906,\n",
              "    282,\n",
              "    15547,\n",
              "    42722,\n",
              "    13,\n",
              "    5185,\n",
              "    8411,\n",
              "    8526,\n",
              "    368,\n",
              "    22411,\n",
              "    18212,\n",
              "    11343,\n",
              "    368,\n",
              "    15547,\n",
              "    42722,\n",
              "    288,\n",
              "    8411,\n",
              "    37452,\n",
              "    39580,\n",
              "    785,\n",
              "    2002,\n",
              "    31710,\n",
              "    3482,\n",
              "    13,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2195517903282529,\n",
              "   'compression_ratio': 1.639344262295082,\n",
              "   'no_speech_prob': 0.04739801213145256},\n",
              "  {'id': 23,\n",
              "   'seek': 23740,\n",
              "   'start': 237.4,\n",
              "   'end': 245.4,\n",
              "   'text': ' Entonces si bien resolvimos problemas de escalidad, resolimos problemas que hay. Ahora tenemos equipo dedicados para los problemas que necesitamos resolver,',\n",
              "   'tokens': [50364,\n",
              "    15097,\n",
              "    1511,\n",
              "    3610,\n",
              "    7923,\n",
              "    85,\n",
              "    8372,\n",
              "    20720,\n",
              "    368,\n",
              "    17871,\n",
              "    4580,\n",
              "    11,\n",
              "    7923,\n",
              "    8372,\n",
              "    20720,\n",
              "    631,\n",
              "    4842,\n",
              "    13,\n",
              "    18840,\n",
              "    9914,\n",
              "    30048,\n",
              "    37071,\n",
              "    4181,\n",
              "    1690,\n",
              "    1750,\n",
              "    20720,\n",
              "    631,\n",
              "    38661,\n",
              "    2151,\n",
              "    34480,\n",
              "    11,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27911153520856585,\n",
              "   'compression_ratio': 1.6653846153846155,\n",
              "   'no_speech_prob': 0.02095353603363037},\n",
              "  {'id': 24,\n",
              "   'seek': 23740,\n",
              "   'start': 245.4,\n",
              "   'end': 251.4,\n",
              "   'text': ' podemos hacer mucho más diplóvimas rápido, se empiezan a aparecer otros problemas, que es el problema de la comunicación.',\n",
              "   'tokens': [50764,\n",
              "    12234,\n",
              "    6720,\n",
              "    9824,\n",
              "    3573,\n",
              "    11432,\n",
              "    812,\n",
              "    85,\n",
              "    17957,\n",
              "    24893,\n",
              "    11,\n",
              "    369,\n",
              "    4012,\n",
              "    18812,\n",
              "    282,\n",
              "    257,\n",
              "    43336,\n",
              "    16422,\n",
              "    20720,\n",
              "    11,\n",
              "    631,\n",
              "    785,\n",
              "    806,\n",
              "    12395,\n",
              "    368,\n",
              "    635,\n",
              "    31710,\n",
              "    3482,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27911153520856585,\n",
              "   'compression_ratio': 1.6653846153846155,\n",
              "   'no_speech_prob': 0.02095353603363037},\n",
              "  {'id': 25,\n",
              "   'seek': 23740,\n",
              "   'start': 251.4,\n",
              "   'end': 258.4,\n",
              "   'text': ' ¿Qué significa? Ante una comunicación era una llamada una función, una llamada un método, era un 2 o 3 ciclo de CPU y ya teníamos una respuesta.',\n",
              "   'tokens': [51064,\n",
              "    3841,\n",
              "    15137,\n",
              "    19957,\n",
              "    30,\n",
              "    5130,\n",
              "    68,\n",
              "    2002,\n",
              "    31710,\n",
              "    3482,\n",
              "    4249,\n",
              "    2002,\n",
              "    16848,\n",
              "    1538,\n",
              "    2002,\n",
              "    43735,\n",
              "    11,\n",
              "    2002,\n",
              "    16848,\n",
              "    1538,\n",
              "    517,\n",
              "    20275,\n",
              "    17423,\n",
              "    11,\n",
              "    4249,\n",
              "    517,\n",
              "    568,\n",
              "    277,\n",
              "    805,\n",
              "    27464,\n",
              "    752,\n",
              "    368,\n",
              "    13199,\n",
              "    288,\n",
              "    2478,\n",
              "    2064,\n",
              "    16275,\n",
              "    2002,\n",
              "    40585,\n",
              "    13,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27911153520856585,\n",
              "   'compression_ratio': 1.6653846153846155,\n",
              "   'no_speech_prob': 0.02095353603363037},\n",
              "  {'id': 26,\n",
              "   'seek': 25840,\n",
              "   'start': 258.4,\n",
              "   'end': 267.4,\n",
              "   'text': ' Ahora tenemos un cable de red, una placa de red, tenemos de NS, tenemos un sistema mucho más complejo para poder sacar un mensaje de un micros servicio al otro.',\n",
              "   'tokens': [50364,\n",
              "    18840,\n",
              "    9914,\n",
              "    517,\n",
              "    8220,\n",
              "    368,\n",
              "    2182,\n",
              "    11,\n",
              "    2002,\n",
              "    499,\n",
              "    6628,\n",
              "    368,\n",
              "    2182,\n",
              "    11,\n",
              "    9914,\n",
              "    368,\n",
              "    15943,\n",
              "    11,\n",
              "    9914,\n",
              "    517,\n",
              "    13245,\n",
              "    9824,\n",
              "    3573,\n",
              "    44424,\n",
              "    5134,\n",
              "    1690,\n",
              "    8152,\n",
              "    43823,\n",
              "    517,\n",
              "    10923,\n",
              "    11153,\n",
              "    368,\n",
              "    517,\n",
              "    15547,\n",
              "    43078,\n",
              "    419,\n",
              "    11921,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26082931246076313,\n",
              "   'compression_ratio': 1.6081081081081081,\n",
              "   'no_speech_prob': 0.38755208253860474},\n",
              "  {'id': 27,\n",
              "   'seek': 25840,\n",
              "   'start': 267.4,\n",
              "   'end': 278.4,\n",
              "   'text': ' Nosotros cuando empezamos a trabajar con Python en mercado de libre fuerte, que empezamos a hacer Machine Learning, nos dimos cuenta que en las performan de todas las APIs o los micros servicios,',\n",
              "   'tokens': [50814,\n",
              "    18749,\n",
              "    11792,\n",
              "    7767,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    30793,\n",
              "    416,\n",
              "    15329,\n",
              "    465,\n",
              "    24775,\n",
              "    368,\n",
              "    29976,\n",
              "    37129,\n",
              "    11,\n",
              "    631,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    6720,\n",
              "    22155,\n",
              "    15205,\n",
              "    11,\n",
              "    3269,\n",
              "    5013,\n",
              "    329,\n",
              "    17868,\n",
              "    631,\n",
              "    465,\n",
              "    2439,\n",
              "    2042,\n",
              "    282,\n",
              "    368,\n",
              "    10906,\n",
              "    2439,\n",
              "    21445,\n",
              "    277,\n",
              "    1750,\n",
              "    15547,\n",
              "    42722,\n",
              "    11,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.26082931246076313,\n",
              "   'compression_ratio': 1.6081081081081081,\n",
              "   'no_speech_prob': 0.38755208253860474},\n",
              "  {'id': 28,\n",
              "   'seek': 27840,\n",
              "   'start': 278.4,\n",
              "   'end': 286.4,\n",
              "   'text': ' que hacíamos en Python, no se comparaban con lo que ya estaba hecho un go, por ejemplo. Y pero no tenía mucho sentido porque estábamos haciendo cosas sencillas del principio.',\n",
              "   'tokens': [50364,\n",
              "    631,\n",
              "    46093,\n",
              "    16275,\n",
              "    465,\n",
              "    15329,\n",
              "    11,\n",
              "    572,\n",
              "    369,\n",
              "    6311,\n",
              "    18165,\n",
              "    416,\n",
              "    450,\n",
              "    631,\n",
              "    2478,\n",
              "    17544,\n",
              "    13064,\n",
              "    517,\n",
              "    352,\n",
              "    11,\n",
              "    1515,\n",
              "    13358,\n",
              "    13,\n",
              "    398,\n",
              "    4768,\n",
              "    572,\n",
              "    23718,\n",
              "    9824,\n",
              "    19850,\n",
              "    4021,\n",
              "    3192,\n",
              "    65,\n",
              "    2151,\n",
              "    20509,\n",
              "    12218,\n",
              "    46749,\n",
              "    296,\n",
              "    1103,\n",
              "    34308,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27714826705607964,\n",
              "   'compression_ratio': 1.6708860759493671,\n",
              "   'no_speech_prob': 0.12568050622940063},\n",
              "  {'id': 29,\n",
              "   'seek': 27840,\n",
              "   'start': 286.4,\n",
              "   'end': 291.4,\n",
              "   'text': ' Entonces empezamos a investigar un poquito y hay un poco de esta charla de los insens que sacamos.',\n",
              "   'tokens': [50764,\n",
              "    15097,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    4557,\n",
              "    289,\n",
              "    517,\n",
              "    28229,\n",
              "    288,\n",
              "    4842,\n",
              "    517,\n",
              "    10639,\n",
              "    368,\n",
              "    5283,\n",
              "    1290,\n",
              "    875,\n",
              "    368,\n",
              "    1750,\n",
              "    1028,\n",
              "    694,\n",
              "    631,\n",
              "    4899,\n",
              "    2151,\n",
              "    13,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27714826705607964,\n",
              "   'compression_ratio': 1.6708860759493671,\n",
              "   'no_speech_prob': 0.12568050622940063},\n",
              "  {'id': 30,\n",
              "   'seek': 27840,\n",
              "   'start': 291.4,\n",
              "   'end': 299.4,\n",
              "   'text': ' Entonces les queremos contar un poquito que hicimos y en general que se hace para conectar micros servicios con Python.',\n",
              "   'tokens': [51014,\n",
              "    15097,\n",
              "    1512,\n",
              "    26813,\n",
              "    27045,\n",
              "    517,\n",
              "    28229,\n",
              "    631,\n",
              "    23697,\n",
              "    8372,\n",
              "    288,\n",
              "    465,\n",
              "    2674,\n",
              "    631,\n",
              "    369,\n",
              "    10032,\n",
              "    1690,\n",
              "    30458,\n",
              "    289,\n",
              "    15547,\n",
              "    42722,\n",
              "    416,\n",
              "    15329,\n",
              "    13,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27714826705607964,\n",
              "   'compression_ratio': 1.6708860759493671,\n",
              "   'no_speech_prob': 0.12568050622940063},\n",
              "  {'id': 31,\n",
              "   'seek': 29940,\n",
              "   'start': 300.4,\n",
              "   'end': 314.4,\n",
              "   'text': ' En realidad conectar micros servicios a este nivel es hacer una llamada HTTP, es hacer un request como el que hace el navegador, cuando no entra una página, hace un request, ha sido un servidor, eso va a vuelve y en la degarlo renériz algo, en nuestro caso, mandamos un mensaje y recibimos una respuesta y trabajamos.',\n",
              "   'tokens': [50414,\n",
              "    2193,\n",
              "    25635,\n",
              "    30458,\n",
              "    289,\n",
              "    15547,\n",
              "    42722,\n",
              "    257,\n",
              "    4065,\n",
              "    24423,\n",
              "    785,\n",
              "    6720,\n",
              "    2002,\n",
              "    16848,\n",
              "    1538,\n",
              "    33283,\n",
              "    11,\n",
              "    785,\n",
              "    6720,\n",
              "    517,\n",
              "    5308,\n",
              "    2617,\n",
              "    806,\n",
              "    631,\n",
              "    10032,\n",
              "    806,\n",
              "    39376,\n",
              "    70,\n",
              "    5409,\n",
              "    11,\n",
              "    7767,\n",
              "    572,\n",
              "    22284,\n",
              "    2002,\n",
              "    36960,\n",
              "    11,\n",
              "    10032,\n",
              "    517,\n",
              "    5308,\n",
              "    11,\n",
              "    324,\n",
              "    14444,\n",
              "    517,\n",
              "    1658,\n",
              "    29718,\n",
              "    11,\n",
              "    7287,\n",
              "    2773,\n",
              "    257,\n",
              "    20126,\n",
              "    303,\n",
              "    288,\n",
              "    465,\n",
              "    635,\n",
              "    368,\n",
              "    2976,\n",
              "    752,\n",
              "    8124,\n",
              "    526,\n",
              "    24959,\n",
              "    8655,\n",
              "    11,\n",
              "    465,\n",
              "    14726,\n",
              "    9666,\n",
              "    11,\n",
              "    7411,\n",
              "    2151,\n",
              "    517,\n",
              "    10923,\n",
              "    11153,\n",
              "    288,\n",
              "    46387,\n",
              "    8372,\n",
              "    2002,\n",
              "    40585,\n",
              "    288,\n",
              "    9618,\n",
              "    2151,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3437791617519884,\n",
              "   'compression_ratio': 1.5560975609756098,\n",
              "   'no_speech_prob': 0.04599738121032715},\n",
              "  {'id': 32,\n",
              "   'seek': 31440,\n",
              "   'start': 315.4,\n",
              "   'end': 327.4,\n",
              "   'text': ' El caso de una arquitectura de micros servicios, cuando nosotros montamos nuestra solución con este diseño, por lo que real corremos en infraestructura de red que está optimizada para esto.',\n",
              "   'tokens': [50414,\n",
              "    2699,\n",
              "    9666,\n",
              "    368,\n",
              "    2002,\n",
              "    40258,\n",
              "    5739,\n",
              "    2991,\n",
              "    368,\n",
              "    15547,\n",
              "    42722,\n",
              "    11,\n",
              "    7767,\n",
              "    13863,\n",
              "    8143,\n",
              "    2151,\n",
              "    16825,\n",
              "    24807,\n",
              "    5687,\n",
              "    416,\n",
              "    4065,\n",
              "    3814,\n",
              "    7716,\n",
              "    11,\n",
              "    1515,\n",
              "    450,\n",
              "    631,\n",
              "    957,\n",
              "    1181,\n",
              "    28343,\n",
              "    465,\n",
              "    23654,\n",
              "    43056,\n",
              "    2991,\n",
              "    368,\n",
              "    2182,\n",
              "    631,\n",
              "    3192,\n",
              "    5028,\n",
              "    39600,\n",
              "    1690,\n",
              "    7433,\n",
              "    13,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.19010218635934298,\n",
              "   'compression_ratio': 1.7683823529411764,\n",
              "   'no_speech_prob': 0.3804977834224701},\n",
              "  {'id': 33,\n",
              "   'seek': 31440,\n",
              "   'start': 327.4,\n",
              "   'end': 340.4,\n",
              "   'text': ' No es lo mismo yo acá entrando a Google que tengo que atravesar un montón de continentes hasta que llegue el rico, es el servidor y vuelva, cuando yo el mi empresa voy a armar en infraestructura de micros servicios, por lo general voy a intentar que la capa de tráfico, la capa de red,',\n",
              "   'tokens': [51014,\n",
              "    883,\n",
              "    785,\n",
              "    450,\n",
              "    12461,\n",
              "    5290,\n",
              "    23496,\n",
              "    948,\n",
              "    19845,\n",
              "    257,\n",
              "    3329,\n",
              "    631,\n",
              "    13989,\n",
              "    631,\n",
              "    44192,\n",
              "    977,\n",
              "    289,\n",
              "    517,\n",
              "    45259,\n",
              "    368,\n",
              "    1421,\n",
              "    9240,\n",
              "    10764,\n",
              "    631,\n",
              "    11234,\n",
              "    622,\n",
              "    806,\n",
              "    41529,\n",
              "    11,\n",
              "    785,\n",
              "    806,\n",
              "    1658,\n",
              "    29718,\n",
              "    288,\n",
              "    20126,\n",
              "    2757,\n",
              "    11,\n",
              "    7767,\n",
              "    5290,\n",
              "    806,\n",
              "    2752,\n",
              "    22682,\n",
              "    7552,\n",
              "    257,\n",
              "    3726,\n",
              "    289,\n",
              "    465,\n",
              "    23654,\n",
              "    43056,\n",
              "    2991,\n",
              "    368,\n",
              "    15547,\n",
              "    42722,\n",
              "    11,\n",
              "    1515,\n",
              "    450,\n",
              "    2674,\n",
              "    7552,\n",
              "    257,\n",
              "    46596,\n",
              "    631,\n",
              "    635,\n",
              "    1410,\n",
              "    64,\n",
              "    368,\n",
              "    504,\n",
              "    23858,\n",
              "    78,\n",
              "    11,\n",
              "    635,\n",
              "    1410,\n",
              "    64,\n",
              "    368,\n",
              "    2182,\n",
              "    11,\n",
              "    51664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.19010218635934298,\n",
              "   'compression_ratio': 1.7683823529411764,\n",
              "   'no_speech_prob': 0.3804977834224701},\n",
              "  {'id': 34,\n",
              "   'seek': 34040,\n",
              "   'start': 340.4,\n",
              "   'end': 350.4,\n",
              "   'text': ' se ha óptima chica, velos, entonces voy a montar por ejemplo todo en AWS para que el tráfico esté contenido adentro de tráfico de fibra y de backbone, eso es super eficientes.',\n",
              "   'tokens': [50364,\n",
              "    369,\n",
              "    324,\n",
              "    11857,\n",
              "    662,\n",
              "    4775,\n",
              "    417,\n",
              "    2262,\n",
              "    11,\n",
              "    1241,\n",
              "    9389,\n",
              "    11,\n",
              "    13003,\n",
              "    7552,\n",
              "    257,\n",
              "    8143,\n",
              "    289,\n",
              "    1515,\n",
              "    13358,\n",
              "    5149,\n",
              "    465,\n",
              "    17650,\n",
              "    1690,\n",
              "    631,\n",
              "    806,\n",
              "    504,\n",
              "    23858,\n",
              "    78,\n",
              "    34584,\n",
              "    21795,\n",
              "    2925,\n",
              "    614,\n",
              "    317,\n",
              "    340,\n",
              "    368,\n",
              "    504,\n",
              "    23858,\n",
              "    78,\n",
              "    368,\n",
              "    13116,\n",
              "    424,\n",
              "    288,\n",
              "    368,\n",
              "    34889,\n",
              "    11,\n",
              "    7287,\n",
              "    785,\n",
              "    1687,\n",
              "    49510,\n",
              "    20135,\n",
              "    13,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.29850196838378906,\n",
              "   'compression_ratio': 1.5298245614035089,\n",
              "   'no_speech_prob': 0.06366432458162308},\n",
              "  {'id': 35,\n",
              "   'seek': 34040,\n",
              "   'start': 350.4,\n",
              "   'end': 367.4,\n",
              "   'text': ' Entonces lo que realmente pasa a nivel código pasa hacer relevante, ¿eh? Entonces típicamente que hacemos el mundo Python para hacer un request HTTP, quieren conocer a librería requests, levanten la mano por favor, casi todos bien, perfecto, el 78,29%.',\n",
              "   'tokens': [50864,\n",
              "    15097,\n",
              "    450,\n",
              "    631,\n",
              "    14446,\n",
              "    20260,\n",
              "    257,\n",
              "    24423,\n",
              "    44195,\n",
              "    20260,\n",
              "    6720,\n",
              "    25916,\n",
              "    2879,\n",
              "    11,\n",
              "    3841,\n",
              "    13301,\n",
              "    30,\n",
              "    15097,\n",
              "    256,\n",
              "    28236,\n",
              "    23653,\n",
              "    631,\n",
              "    33839,\n",
              "    806,\n",
              "    7968,\n",
              "    15329,\n",
              "    1690,\n",
              "    6720,\n",
              "    517,\n",
              "    5308,\n",
              "    33283,\n",
              "    11,\n",
              "    36706,\n",
              "    35241,\n",
              "    257,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    12475,\n",
              "    11,\n",
              "    30612,\n",
              "    268,\n",
              "    635,\n",
              "    18384,\n",
              "    1515,\n",
              "    2294,\n",
              "    11,\n",
              "    22567,\n",
              "    6321,\n",
              "    3610,\n",
              "    11,\n",
              "    2176,\n",
              "    78,\n",
              "    11,\n",
              "    806,\n",
              "    26369,\n",
              "    11,\n",
              "    11871,\n",
              "    6856,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.29850196838378906,\n",
              "   'compression_ratio': 1.5298245614035089,\n",
              "   'no_speech_prob': 0.06366432458162308},\n",
              "  {'id': 36,\n",
              "   'seek': 36740,\n",
              "   'start': 368.4,\n",
              "   'end': 380.4,\n",
              "   'text': ' Casi todo, sí, request es lo que se usa en Python y tiene sentido porque la librería request nos abstracte los BMoles, el protocol HTTP, ¿qué significa un request HTTP?',\n",
              "   'tokens': [50414,\n",
              "    383,\n",
              "    8483,\n",
              "    5149,\n",
              "    11,\n",
              "    8600,\n",
              "    11,\n",
              "    5308,\n",
              "    785,\n",
              "    450,\n",
              "    631,\n",
              "    369,\n",
              "    29909,\n",
              "    465,\n",
              "    15329,\n",
              "    288,\n",
              "    7066,\n",
              "    19850,\n",
              "    4021,\n",
              "    635,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    5308,\n",
              "    3269,\n",
              "    12649,\n",
              "    68,\n",
              "    1750,\n",
              "    363,\n",
              "    44,\n",
              "    7456,\n",
              "    11,\n",
              "    806,\n",
              "    10336,\n",
              "    33283,\n",
              "    11,\n",
              "    3841,\n",
              "    16412,\n",
              "    19957,\n",
              "    517,\n",
              "    5308,\n",
              "    33283,\n",
              "    30,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2883637396843879,\n",
              "   'compression_ratio': 1.4955357142857142,\n",
              "   'no_speech_prob': 0.11579056829214096},\n",
              "  {'id': 37,\n",
              "   'seek': 36740,\n",
              "   'start': 380.4,\n",
              "   'end': 390.4,\n",
              "   'text': ' Hay cierto estrin formateado con un formalismo que tiene que viajar hacia un servidor que lo vas a recibir y que me va a devolver con cierta formalidad o mensaje.',\n",
              "   'tokens': [51014,\n",
              "    8721,\n",
              "    28558,\n",
              "    785,\n",
              "    6903,\n",
              "    259,\n",
              "    1254,\n",
              "    473,\n",
              "    1573,\n",
              "    416,\n",
              "    517,\n",
              "    9860,\n",
              "    6882,\n",
              "    631,\n",
              "    7066,\n",
              "    631,\n",
              "    5766,\n",
              "    10150,\n",
              "    21365,\n",
              "    517,\n",
              "    1658,\n",
              "    29718,\n",
              "    631,\n",
              "    450,\n",
              "    11481,\n",
              "    257,\n",
              "    49703,\n",
              "    288,\n",
              "    631,\n",
              "    385,\n",
              "    2773,\n",
              "    257,\n",
              "    1905,\n",
              "    401,\n",
              "    331,\n",
              "    416,\n",
              "    39769,\n",
              "    1328,\n",
              "    9860,\n",
              "    4580,\n",
              "    277,\n",
              "    10923,\n",
              "    11153,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2883637396843879,\n",
              "   'compression_ratio': 1.4955357142857142,\n",
              "   'no_speech_prob': 0.11579056829214096},\n",
              "  {'id': 38,\n",
              "   'seek': 39040,\n",
              "   'start': 390.4,\n",
              "   'end': 403.4,\n",
              "   'text': ' Eso es un protocolo que se monta sobre un montón de cosas, sobre en particular la red. Entonces por ejemplo que yo quiero en mi aplicación que calcula el tiempo de envío y un paquete, estípicamente voy a depender de otros servicios,',\n",
              "   'tokens': [50364,\n",
              "    27795,\n",
              "    785,\n",
              "    517,\n",
              "    10336,\n",
              "    78,\n",
              "    631,\n",
              "    369,\n",
              "    8143,\n",
              "    64,\n",
              "    5473,\n",
              "    517,\n",
              "    45259,\n",
              "    368,\n",
              "    12218,\n",
              "    11,\n",
              "    5473,\n",
              "    465,\n",
              "    1729,\n",
              "    635,\n",
              "    2182,\n",
              "    13,\n",
              "    15097,\n",
              "    1515,\n",
              "    13358,\n",
              "    631,\n",
              "    5290,\n",
              "    16811,\n",
              "    465,\n",
              "    2752,\n",
              "    18221,\n",
              "    3482,\n",
              "    631,\n",
              "    4322,\n",
              "    64,\n",
              "    806,\n",
              "    11772,\n",
              "    368,\n",
              "    2267,\n",
              "    20492,\n",
              "    288,\n",
              "    517,\n",
              "    2502,\n",
              "    358,\n",
              "    3498,\n",
              "    11,\n",
              "    871,\n",
              "    28236,\n",
              "    23653,\n",
              "    7552,\n",
              "    257,\n",
              "    1367,\n",
              "    3216,\n",
              "    368,\n",
              "    16422,\n",
              "    42722,\n",
              "    11,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2044623847146636,\n",
              "   'compression_ratio': 1.6942148760330578,\n",
              "   'no_speech_prob': 0.13107554614543915},\n",
              "  {'id': 39,\n",
              "   'seek': 39040,\n",
              "   'start': 403.4,\n",
              "   'end': 412.4,\n",
              "   'text': ' voy a depender de servicios externos, porque yo voy a querer calcular para determinado usuario y determinado producto, bueno, ¿cuánto tal ese producto en llegar a su casa?',\n",
              "   'tokens': [51014,\n",
              "    7552,\n",
              "    257,\n",
              "    1367,\n",
              "    3216,\n",
              "    368,\n",
              "    42722,\n",
              "    30360,\n",
              "    329,\n",
              "    11,\n",
              "    4021,\n",
              "    5290,\n",
              "    7552,\n",
              "    257,\n",
              "    39318,\n",
              "    2104,\n",
              "    17792,\n",
              "    1690,\n",
              "    15957,\n",
              "    1573,\n",
              "    32247,\n",
              "    4912,\n",
              "    288,\n",
              "    15957,\n",
              "    1573,\n",
              "    47583,\n",
              "    11,\n",
              "    11974,\n",
              "    11,\n",
              "    3841,\n",
              "    12032,\n",
              "    27525,\n",
              "    78,\n",
              "    4023,\n",
              "    10167,\n",
              "    47583,\n",
              "    465,\n",
              "    24892,\n",
              "    257,\n",
              "    459,\n",
              "    9022,\n",
              "    30,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2044623847146636,\n",
              "   'compression_ratio': 1.6942148760330578,\n",
              "   'no_speech_prob': 0.13107554614543915},\n",
              "  {'id': 40,\n",
              "   'seek': 41240,\n",
              "   'start': 412.4,\n",
              "   'end': 427.4,\n",
              "   'text': ' Entonces yo voy a tener que pedirle a la API de direcciones de usuarios que me diga las direcciones de usuario y voy a querer pedir a otro endpoint que es la información de los vendedores, que me de información y después a la información de las direcciones de los vendedores.',\n",
              "   'tokens': [50364,\n",
              "    15097,\n",
              "    5290,\n",
              "    7552,\n",
              "    257,\n",
              "    11640,\n",
              "    631,\n",
              "    33533,\n",
              "    306,\n",
              "    257,\n",
              "    635,\n",
              "    9362,\n",
              "    368,\n",
              "    1264,\n",
              "    35560,\n",
              "    368,\n",
              "    32247,\n",
              "    9720,\n",
              "    631,\n",
              "    385,\n",
              "    2528,\n",
              "    64,\n",
              "    2439,\n",
              "    1264,\n",
              "    35560,\n",
              "    368,\n",
              "    32247,\n",
              "    4912,\n",
              "    288,\n",
              "    7552,\n",
              "    257,\n",
              "    39318,\n",
              "    33533,\n",
              "    257,\n",
              "    11921,\n",
              "    917,\n",
              "    6053,\n",
              "    631,\n",
              "    785,\n",
              "    635,\n",
              "    21660,\n",
              "    368,\n",
              "    1750,\n",
              "    371,\n",
              "    3502,\n",
              "    2706,\n",
              "    11,\n",
              "    631,\n",
              "    385,\n",
              "    368,\n",
              "    21660,\n",
              "    288,\n",
              "    15283,\n",
              "    257,\n",
              "    635,\n",
              "    21660,\n",
              "    368,\n",
              "    2439,\n",
              "    1264,\n",
              "    35560,\n",
              "    368,\n",
              "    1750,\n",
              "    371,\n",
              "    3502,\n",
              "    2706,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20478007223753802,\n",
              "   'compression_ratio': 1.9007936507936507,\n",
              "   'no_speech_prob': 0.1539791375398636},\n",
              "  {'id': 41,\n",
              "   'seek': 41240,\n",
              "   'start': 427.4,\n",
              "   'end': 441.4,\n",
              "   'text': ' Entonces en una esquema de microservicios típicamente vamos a tener una serie de llamadas, una serie de requests a otros servicios, posiblemente aún mismo servicio, yo le quiero pegar muchas veces.',\n",
              "   'tokens': [51114,\n",
              "    15097,\n",
              "    465,\n",
              "    2002,\n",
              "    34611,\n",
              "    5619,\n",
              "    368,\n",
              "    15547,\n",
              "    1978,\n",
              "    26817,\n",
              "    256,\n",
              "    28236,\n",
              "    23653,\n",
              "    5295,\n",
              "    257,\n",
              "    11640,\n",
              "    2002,\n",
              "    23030,\n",
              "    368,\n",
              "    16848,\n",
              "    6872,\n",
              "    11,\n",
              "    2002,\n",
              "    23030,\n",
              "    368,\n",
              "    12475,\n",
              "    257,\n",
              "    16422,\n",
              "    42722,\n",
              "    11,\n",
              "    26644,\n",
              "    4082,\n",
              "    31676,\n",
              "    12461,\n",
              "    43078,\n",
              "    11,\n",
              "    5290,\n",
              "    476,\n",
              "    16811,\n",
              "    22418,\n",
              "    16072,\n",
              "    17054,\n",
              "    13,\n",
              "    51814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.20478007223753802,\n",
              "   'compression_ratio': 1.9007936507936507,\n",
              "   'no_speech_prob': 0.1539791375398636},\n",
              "  {'id': 42,\n",
              "   'seek': 44140,\n",
              "   'start': 442.4,\n",
              "   'end': 455.4,\n",
              "   'text': ' Este código cada vez que llegó request ustedes de entrar al mercado libre al marketplace, entre la verulítem y en algún momento le dice por ejemplo cuánto mataró a llegar aproximadamente el sistema a su casa.',\n",
              "   'tokens': [50414,\n",
              "    16105,\n",
              "    44195,\n",
              "    8411,\n",
              "    5715,\n",
              "    631,\n",
              "    46182,\n",
              "    5308,\n",
              "    17110,\n",
              "    368,\n",
              "    20913,\n",
              "    419,\n",
              "    24775,\n",
              "    29976,\n",
              "    419,\n",
              "    19455,\n",
              "    11,\n",
              "    3962,\n",
              "    635,\n",
              "    1306,\n",
              "    425,\n",
              "    6712,\n",
              "    443,\n",
              "    288,\n",
              "    465,\n",
              "    26300,\n",
              "    9333,\n",
              "    476,\n",
              "    10313,\n",
              "    1515,\n",
              "    13358,\n",
              "    44256,\n",
              "    78,\n",
              "    39208,\n",
              "    812,\n",
              "    257,\n",
              "    24892,\n",
              "    48892,\n",
              "    806,\n",
              "    13245,\n",
              "    257,\n",
              "    459,\n",
              "    9022,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3892456236339751,\n",
              "   'compression_ratio': 1.6561085972850678,\n",
              "   'no_speech_prob': 0.010984868742525578},\n",
              "  {'id': 43,\n",
              "   'seek': 44140,\n",
              "   'start': 455.4,\n",
              "   'end': 467.4,\n",
              "   'text': ' Eso significa que con cada rico es que llega al mercado libre, este código se ejecuta y al mercado libre tenemos cientos de miles de ricos por minuto.',\n",
              "   'tokens': [51064,\n",
              "    27795,\n",
              "    19957,\n",
              "    631,\n",
              "    416,\n",
              "    8411,\n",
              "    41529,\n",
              "    785,\n",
              "    631,\n",
              "    40423,\n",
              "    419,\n",
              "    24775,\n",
              "    29976,\n",
              "    11,\n",
              "    4065,\n",
              "    44195,\n",
              "    369,\n",
              "    39564,\n",
              "    6672,\n",
              "    64,\n",
              "    288,\n",
              "    419,\n",
              "    24775,\n",
              "    29976,\n",
              "    9914,\n",
              "    269,\n",
              "    20370,\n",
              "    368,\n",
              "    6193,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    1515,\n",
              "    923,\n",
              "    8262,\n",
              "    13,\n",
              "    51664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3892456236339751,\n",
              "   'compression_ratio': 1.6561085972850678,\n",
              "   'no_speech_prob': 0.010984868742525578},\n",
              "  {'id': 44,\n",
              "   'seek': 46740,\n",
              "   'start': 467.4,\n",
              "   'end': 481.4,\n",
              "   'text': ' Y significa que este endpoint se va a llamar cientos de miles de veces por minuto. Entonces estas llamadas mi microservicio le va a estar pegando los otros microservicios de una manera exponencial con respecto al tráfico que recibo.',\n",
              "   'tokens': [50364,\n",
              "    398,\n",
              "    19957,\n",
              "    631,\n",
              "    4065,\n",
              "    917,\n",
              "    6053,\n",
              "    369,\n",
              "    2773,\n",
              "    257,\n",
              "    16848,\n",
              "    289,\n",
              "    269,\n",
              "    20370,\n",
              "    368,\n",
              "    6193,\n",
              "    368,\n",
              "    17054,\n",
              "    1515,\n",
              "    923,\n",
              "    8262,\n",
              "    13,\n",
              "    15097,\n",
              "    13897,\n",
              "    16848,\n",
              "    6872,\n",
              "    2752,\n",
              "    15547,\n",
              "    1978,\n",
              "    18322,\n",
              "    476,\n",
              "    2773,\n",
              "    257,\n",
              "    8755,\n",
              "    17199,\n",
              "    1806,\n",
              "    1750,\n",
              "    16422,\n",
              "    15547,\n",
              "    1978,\n",
              "    26817,\n",
              "    368,\n",
              "    2002,\n",
              "    13913,\n",
              "    12680,\n",
              "    26567,\n",
              "    416,\n",
              "    35694,\n",
              "    419,\n",
              "    504,\n",
              "    23858,\n",
              "    78,\n",
              "    631,\n",
              "    4214,\n",
              "    1763,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.155615289332503,\n",
              "   'compression_ratio': 1.5129870129870129,\n",
              "   'no_speech_prob': 0.01342442911118269},\n",
              "  {'id': 45,\n",
              "   'seek': 48140,\n",
              "   'start': 481.4,\n",
              "   'end': 490.4,\n",
              "   'text': ' Entonces ¿qué pasa cada vez que yo le pego otro microservicio? ¿Bien esto que en mi computadora se desmejor?',\n",
              "   'tokens': [50364,\n",
              "    15097,\n",
              "    3841,\n",
              "    16412,\n",
              "    20260,\n",
              "    8411,\n",
              "    5715,\n",
              "    631,\n",
              "    5290,\n",
              "    476,\n",
              "    520,\n",
              "    1571,\n",
              "    11921,\n",
              "    15547,\n",
              "    1978,\n",
              "    18322,\n",
              "    30,\n",
              "    3841,\n",
              "    33,\n",
              "    1053,\n",
              "    7433,\n",
              "    631,\n",
              "    465,\n",
              "    2752,\n",
              "    2807,\n",
              "    23020,\n",
              "    369,\n",
              "    730,\n",
              "    1398,\n",
              "    2337,\n",
              "    30,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.24913783073425294,\n",
              "   'compression_ratio': 1.3928571428571428,\n",
              "   'no_speech_prob': 0.2971368730068207},\n",
              "  {'id': 46,\n",
              "   'seek': 48140,\n",
              "   'start': 490.4,\n",
              "   'end': 500.4,\n",
              "   'text': ' Esta tiene que ver más o menos con la explicación del protocolo tcp, la capa de red. ¿Qué pasa cuando yo le envío desde mi cliente a un mensaje al servidor?',\n",
              "   'tokens': [50814,\n",
              "    20547,\n",
              "    7066,\n",
              "    631,\n",
              "    1306,\n",
              "    3573,\n",
              "    277,\n",
              "    8902,\n",
              "    416,\n",
              "    635,\n",
              "    28021,\n",
              "    3482,\n",
              "    1103,\n",
              "    10336,\n",
              "    78,\n",
              "    256,\n",
              "    66,\n",
              "    79,\n",
              "    11,\n",
              "    635,\n",
              "    1410,\n",
              "    64,\n",
              "    368,\n",
              "    2182,\n",
              "    13,\n",
              "    3841,\n",
              "    15137,\n",
              "    20260,\n",
              "    7767,\n",
              "    5290,\n",
              "    476,\n",
              "    2267,\n",
              "    20492,\n",
              "    10188,\n",
              "    2752,\n",
              "    6423,\n",
              "    68,\n",
              "    257,\n",
              "    517,\n",
              "    10923,\n",
              "    11153,\n",
              "    419,\n",
              "    1658,\n",
              "    29718,\n",
              "    30,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.24913783073425294,\n",
              "   'compression_ratio': 1.3928571428571428,\n",
              "   'no_speech_prob': 0.2971368730068207},\n",
              "  {'id': 47,\n",
              "   'seek': 50040,\n",
              "   'start': 500.4,\n",
              "   'end': 515.4,\n",
              "   'text': ' Se establece una comunicación a nivel red donde primero hay que ir al DNS para ver cuál es la IP del servidor que tiene que llegar porque yo le digo una URL, una string. Entonces da de ese IP tengo que empezar a mandar ciertos mensajes de conexión a ese otro servidor.',\n",
              "   'tokens': [50364,\n",
              "    1100,\n",
              "    37444,\n",
              "    384,\n",
              "    2002,\n",
              "    31710,\n",
              "    3482,\n",
              "    257,\n",
              "    24423,\n",
              "    2182,\n",
              "    10488,\n",
              "    21289,\n",
              "    4842,\n",
              "    631,\n",
              "    3418,\n",
              "    419,\n",
              "    35153,\n",
              "    1690,\n",
              "    1306,\n",
              "    44318,\n",
              "    785,\n",
              "    635,\n",
              "    8671,\n",
              "    1103,\n",
              "    1658,\n",
              "    29718,\n",
              "    631,\n",
              "    7066,\n",
              "    631,\n",
              "    24892,\n",
              "    4021,\n",
              "    5290,\n",
              "    476,\n",
              "    22990,\n",
              "    2002,\n",
              "    12905,\n",
              "    11,\n",
              "    2002,\n",
              "    6798,\n",
              "    13,\n",
              "    15097,\n",
              "    1120,\n",
              "    368,\n",
              "    10167,\n",
              "    8671,\n",
              "    13989,\n",
              "    631,\n",
              "    31168,\n",
              "    257,\n",
              "    48689,\n",
              "    49252,\n",
              "    329,\n",
              "    10923,\n",
              "    29362,\n",
              "    368,\n",
              "    49509,\n",
              "    2560,\n",
              "    257,\n",
              "    10167,\n",
              "    11921,\n",
              "    1658,\n",
              "    29718,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2189527361580495,\n",
              "   'compression_ratio': 1.5847457627118644,\n",
              "   'no_speech_prob': 0.4603361487388611},\n",
              "  {'id': 48,\n",
              "   'seek': 50040,\n",
              "   'start': 515.4,\n",
              "   'end': 520.4,\n",
              "   'text': ' Entonces esos son un montón de mensajes entre mi entre la máquina original y la máquina de destino.',\n",
              "   'tokens': [51114,\n",
              "    15097,\n",
              "    22411,\n",
              "    1872,\n",
              "    517,\n",
              "    45259,\n",
              "    368,\n",
              "    10923,\n",
              "    29362,\n",
              "    3962,\n",
              "    2752,\n",
              "    3962,\n",
              "    635,\n",
              "    49360,\n",
              "    3380,\n",
              "    288,\n",
              "    635,\n",
              "    49360,\n",
              "    368,\n",
              "    2677,\n",
              "    2982,\n",
              "    13,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2189527361580495,\n",
              "   'compression_ratio': 1.5847457627118644,\n",
              "   'no_speech_prob': 0.4603361487388611},\n",
              "  {'id': 49,\n",
              "   'seek': 52040,\n",
              "   'start': 520.4,\n",
              "   'end': 534.4,\n",
              "   'text': ' Le va a tu mensaje para que se conecte y una vez que se conecta tiene que haber si estoy en un esquema de ese cl o de seguridad, hay todo un intercambio de protocolos, asociado a que voy a asegurarme de que está protegida, la conexión, esto se unir y vueltas de mensajes.',\n",
              "   'tokens': [50364,\n",
              "    1456,\n",
              "    2773,\n",
              "    257,\n",
              "    2604,\n",
              "    10923,\n",
              "    11153,\n",
              "    1690,\n",
              "    631,\n",
              "    369,\n",
              "    30458,\n",
              "    68,\n",
              "    288,\n",
              "    2002,\n",
              "    5715,\n",
              "    631,\n",
              "    369,\n",
              "    30458,\n",
              "    64,\n",
              "    7066,\n",
              "    631,\n",
              "    15811,\n",
              "    1511,\n",
              "    15796,\n",
              "    465,\n",
              "    517,\n",
              "    34611,\n",
              "    5619,\n",
              "    368,\n",
              "    10167,\n",
              "    269,\n",
              "    75,\n",
              "    277,\n",
              "    368,\n",
              "    35415,\n",
              "    11,\n",
              "    4842,\n",
              "    5149,\n",
              "    517,\n",
              "    728,\n",
              "    66,\n",
              "    2173,\n",
              "    1004,\n",
              "    368,\n",
              "    10336,\n",
              "    329,\n",
              "    11,\n",
              "    382,\n",
              "    78,\n",
              "    537,\n",
              "    1573,\n",
              "    257,\n",
              "    631,\n",
              "    7552,\n",
              "    257,\n",
              "    38174,\n",
              "    28586,\n",
              "    1398,\n",
              "    368,\n",
              "    631,\n",
              "    3192,\n",
              "    49157,\n",
              "    2887,\n",
              "    11,\n",
              "    635,\n",
              "    49509,\n",
              "    2560,\n",
              "    11,\n",
              "    7433,\n",
              "    369,\n",
              "    517,\n",
              "    347,\n",
              "    288,\n",
              "    9732,\n",
              "    2018,\n",
              "    296,\n",
              "    368,\n",
              "    10923,\n",
              "    29362,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3207605430878789,\n",
              "   'compression_ratio': 1.5511363636363635,\n",
              "   'no_speech_prob': 0.3305797278881073},\n",
              "  {'id': 50,\n",
              "   'seek': 53440,\n",
              "   'start': 534.4,\n",
              "   'end': 552.4,\n",
              "   'text': ' Para que finalmente yo le pueda mandar el payload de mi mensaje, para que fíjense que nosotros en Python le dijimos mandar un get y traer este resultado, internamente que nos resolvió request y hizo toda esta comunicación, mandó el mensaje y cerró la conexión.',\n",
              "   'tokens': [50364,\n",
              "    11107,\n",
              "    631,\n",
              "    35577,\n",
              "    5290,\n",
              "    476,\n",
              "    31907,\n",
              "    48689,\n",
              "    806,\n",
              "    30918,\n",
              "    368,\n",
              "    2752,\n",
              "    10923,\n",
              "    11153,\n",
              "    11,\n",
              "    1690,\n",
              "    631,\n",
              "    283,\n",
              "    870,\n",
              "    73,\n",
              "    1288,\n",
              "    631,\n",
              "    13863,\n",
              "    465,\n",
              "    15329,\n",
              "    476,\n",
              "    47709,\n",
              "    8372,\n",
              "    48689,\n",
              "    517,\n",
              "    483,\n",
              "    288,\n",
              "    944,\n",
              "    260,\n",
              "    4065,\n",
              "    28047,\n",
              "    11,\n",
              "    2154,\n",
              "    3439,\n",
              "    631,\n",
              "    3269,\n",
              "    7923,\n",
              "    4917,\n",
              "    812,\n",
              "    5308,\n",
              "    288,\n",
              "    28803,\n",
              "    11687,\n",
              "    5283,\n",
              "    31710,\n",
              "    3482,\n",
              "    11,\n",
              "    7411,\n",
              "    812,\n",
              "    806,\n",
              "    10923,\n",
              "    11153,\n",
              "    288,\n",
              "    10146,\n",
              "    11721,\n",
              "    635,\n",
              "    49509,\n",
              "    2560,\n",
              "    13,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.23625053576569058,\n",
              "   'compression_ratio': 1.52,\n",
              "   'no_speech_prob': 0.5187823176383972},\n",
              "  {'id': 51,\n",
              "   'seek': 55240,\n",
              "   'start': 553.4,\n",
              "   'end': 561.4,\n",
              "   'text': ' Y eso lo hizo cada vez resolución de DNS, ese se conectó, ese cl, le mandó el payload y la cerró.',\n",
              "   'tokens': [50414,\n",
              "    398,\n",
              "    7287,\n",
              "    450,\n",
              "    28803,\n",
              "    8411,\n",
              "    5715,\n",
              "    7923,\n",
              "    30813,\n",
              "    368,\n",
              "    35153,\n",
              "    11,\n",
              "    10167,\n",
              "    369,\n",
              "    30458,\n",
              "    812,\n",
              "    11,\n",
              "    10167,\n",
              "    269,\n",
              "    75,\n",
              "    11,\n",
              "    476,\n",
              "    7411,\n",
              "    812,\n",
              "    806,\n",
              "    30918,\n",
              "    288,\n",
              "    635,\n",
              "    10146,\n",
              "    11721,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30930328369140625,\n",
              "   'compression_ratio': 1.6178861788617886,\n",
              "   'no_speech_prob': 0.14995577931404114},\n",
              "  {'id': 52,\n",
              "   'seek': 55240,\n",
              "   'start': 561.4,\n",
              "   'end': 566.4,\n",
              "   'text': ' Con cada vez y los cientos de miles de veces que yo me conecto con el otro servidor, request aseto.',\n",
              "   'tokens': [50814,\n",
              "    2656,\n",
              "    8411,\n",
              "    5715,\n",
              "    288,\n",
              "    1750,\n",
              "    269,\n",
              "    20370,\n",
              "    368,\n",
              "    6193,\n",
              "    368,\n",
              "    17054,\n",
              "    631,\n",
              "    5290,\n",
              "    385,\n",
              "    30458,\n",
              "    78,\n",
              "    416,\n",
              "    806,\n",
              "    11921,\n",
              "    1658,\n",
              "    29718,\n",
              "    11,\n",
              "    5308,\n",
              "    382,\n",
              "    19515,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30930328369140625,\n",
              "   'compression_ratio': 1.6178861788617886,\n",
              "   'no_speech_prob': 0.14995577931404114},\n",
              "  {'id': 53,\n",
              "   'seek': 55240,\n",
              "   'start': 566.4,\n",
              "   'end': 570.4,\n",
              "   'text': ' Porque bueno, porque el que se hace es fácil, con muy poco, hace mucho.',\n",
              "   'tokens': [51064,\n",
              "    11287,\n",
              "    11974,\n",
              "    11,\n",
              "    4021,\n",
              "    806,\n",
              "    631,\n",
              "    369,\n",
              "    10032,\n",
              "    785,\n",
              "    17474,\n",
              "    11,\n",
              "    416,\n",
              "    5323,\n",
              "    10639,\n",
              "    11,\n",
              "    10032,\n",
              "    9824,\n",
              "    13,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30930328369140625,\n",
              "   'compression_ratio': 1.6178861788617886,\n",
              "   'no_speech_prob': 0.14995577931404114},\n",
              "  {'id': 54,\n",
              "   'seek': 55240,\n",
              "   'start': 570.4,\n",
              "   'end': 575.4,\n",
              "   'text': ' Ahora yo estoy en una esquema de micro-serizo, yo voy a conectar muchas veces con el mismo servidor, era un esquema seguro.',\n",
              "   'tokens': [51264,\n",
              "    18840,\n",
              "    5290,\n",
              "    15796,\n",
              "    465,\n",
              "    2002,\n",
              "    34611,\n",
              "    5619,\n",
              "    368,\n",
              "    4532,\n",
              "    12,\n",
              "    12484,\n",
              "    19055,\n",
              "    11,\n",
              "    5290,\n",
              "    7552,\n",
              "    257,\n",
              "    30458,\n",
              "    289,\n",
              "    16072,\n",
              "    17054,\n",
              "    416,\n",
              "    806,\n",
              "    12461,\n",
              "    1658,\n",
              "    29718,\n",
              "    11,\n",
              "    4249,\n",
              "    517,\n",
              "    34611,\n",
              "    5619,\n",
              "    31424,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30930328369140625,\n",
              "   'compression_ratio': 1.6178861788617886,\n",
              "   'no_speech_prob': 0.14995577931404114},\n",
              "  {'id': 55,\n",
              "   'seek': 57540,\n",
              "   'start': 576.4,\n",
              "   'end': 583.4,\n",
              "   'text': ' Yo no quisiera estar abriendo y cerrando esta conexión cada vez, yo no quisiera estar intercambiando, certificado, ese cl.',\n",
              "   'tokens': [50414,\n",
              "    7616,\n",
              "    572,\n",
              "    37945,\n",
              "    10609,\n",
              "    8755,\n",
              "    410,\n",
              "    470,\n",
              "    3999,\n",
              "    288,\n",
              "    10146,\n",
              "    19845,\n",
              "    5283,\n",
              "    49509,\n",
              "    2560,\n",
              "    8411,\n",
              "    5715,\n",
              "    11,\n",
              "    5290,\n",
              "    572,\n",
              "    37945,\n",
              "    10609,\n",
              "    8755,\n",
              "    728,\n",
              "    66,\n",
              "    2173,\n",
              "    72,\n",
              "    1806,\n",
              "    11,\n",
              "    12378,\n",
              "    1573,\n",
              "    11,\n",
              "    10167,\n",
              "    269,\n",
              "    75,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2433231816147313,\n",
              "   'compression_ratio': 1.462962962962963,\n",
              "   'no_speech_prob': 0.07473964244127274},\n",
              "  {'id': 56,\n",
              "   'seek': 57540,\n",
              "   'start': 583.4,\n",
              "   'end': 590.4,\n",
              "   'text': ' Entonces en realidad yo me gustaría quedarme con una partecita muy chiquita todo lo que está haciendo, request.',\n",
              "   'tokens': [50764,\n",
              "    15097,\n",
              "    465,\n",
              "    25635,\n",
              "    5290,\n",
              "    385,\n",
              "    45896,\n",
              "    13617,\n",
              "    35890,\n",
              "    416,\n",
              "    2002,\n",
              "    6975,\n",
              "    66,\n",
              "    2786,\n",
              "    5323,\n",
              "    417,\n",
              "    3221,\n",
              "    2786,\n",
              "    5149,\n",
              "    450,\n",
              "    631,\n",
              "    3192,\n",
              "    20509,\n",
              "    11,\n",
              "    5308,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2433231816147313,\n",
              "   'compression_ratio': 1.462962962962963,\n",
              "   'no_speech_prob': 0.07473964244127274},\n",
              "  {'id': 57,\n",
              "   'seek': 59040,\n",
              "   'start': 591.4,\n",
              "   'end': 599.4,\n",
              "   'text': ' Entonces la librería request con muy poco me permite ganar esa optimización.',\n",
              "   'tokens': [50414,\n",
              "    15097,\n",
              "    635,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    5308,\n",
              "    416,\n",
              "    5323,\n",
              "    10639,\n",
              "    385,\n",
              "    31105,\n",
              "    7574,\n",
              "    289,\n",
              "    11342,\n",
              "    5028,\n",
              "    27603,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2375893539257264,\n",
              "   'compression_ratio': 1.63135593220339,\n",
              "   'no_speech_prob': 0.3103140592575073},\n",
              "  {'id': 58,\n",
              "   'seek': 59040,\n",
              "   'start': 599.4,\n",
              "   'end': 609.4,\n",
              "   'text': ' Uno tiene que leer la documentación de request, tiene que pasar del getting start, de quick start de request y empezar a ver los features como en todas las librerías que estamos usando en general.',\n",
              "   'tokens': [50814,\n",
              "    37468,\n",
              "    7066,\n",
              "    631,\n",
              "    34172,\n",
              "    635,\n",
              "    4166,\n",
              "    3482,\n",
              "    368,\n",
              "    5308,\n",
              "    11,\n",
              "    7066,\n",
              "    631,\n",
              "    25344,\n",
              "    1103,\n",
              "    1242,\n",
              "    722,\n",
              "    11,\n",
              "    368,\n",
              "    1702,\n",
              "    722,\n",
              "    368,\n",
              "    5308,\n",
              "    288,\n",
              "    31168,\n",
              "    257,\n",
              "    1306,\n",
              "    1750,\n",
              "    4122,\n",
              "    2617,\n",
              "    465,\n",
              "    10906,\n",
              "    2439,\n",
              "    4939,\n",
              "    260,\n",
              "    10025,\n",
              "    631,\n",
              "    10382,\n",
              "    29798,\n",
              "    465,\n",
              "    2674,\n",
              "    13,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2375893539257264,\n",
              "   'compression_ratio': 1.63135593220339,\n",
              "   'no_speech_prob': 0.3103140592575073},\n",
              "  {'id': 59,\n",
              "   'seek': 59040,\n",
              "   'start': 609.4,\n",
              "   'end': 614.4,\n",
              "   'text': ' Tenemos un quick start pero después tenemos que ver cuáles son los parámetros un poquito más avanzados.',\n",
              "   'tokens': [51314,\n",
              "    44903,\n",
              "    517,\n",
              "    1702,\n",
              "    722,\n",
              "    4768,\n",
              "    15283,\n",
              "    9914,\n",
              "    631,\n",
              "    1306,\n",
              "    2702,\n",
              "    842,\n",
              "    904,\n",
              "    1872,\n",
              "    1750,\n",
              "    971,\n",
              "    842,\n",
              "    29570,\n",
              "    517,\n",
              "    28229,\n",
              "    3573,\n",
              "    42444,\n",
              "    4181,\n",
              "    13,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2375893539257264,\n",
              "   'compression_ratio': 1.63135593220339,\n",
              "   'no_speech_prob': 0.3103140592575073},\n",
              "  {'id': 60,\n",
              "   'seek': 61440,\n",
              "   'start': 615.4,\n",
              "   'end': 621.4,\n",
              "   'text': ' Fíjense que con muy pocos cambios, yo request le puedo decir no quiero usar la de top level, request le digo che de alguna sesión.',\n",
              "   'tokens': [50414,\n",
              "    479,\n",
              "    870,\n",
              "    73,\n",
              "    1288,\n",
              "    631,\n",
              "    416,\n",
              "    5323,\n",
              "    714,\n",
              "    6877,\n",
              "    18751,\n",
              "    2717,\n",
              "    11,\n",
              "    5290,\n",
              "    5308,\n",
              "    476,\n",
              "    21612,\n",
              "    10235,\n",
              "    572,\n",
              "    16811,\n",
              "    14745,\n",
              "    635,\n",
              "    368,\n",
              "    1192,\n",
              "    1496,\n",
              "    11,\n",
              "    5308,\n",
              "    476,\n",
              "    22990,\n",
              "    947,\n",
              "    368,\n",
              "    20651,\n",
              "    5385,\n",
              "    2560,\n",
              "    13,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 61,\n",
              "   'seek': 61440,\n",
              "   'start': 621.4,\n",
              "   'end': 622.4,\n",
              "   'text': ' Che.',\n",
              "   'tokens': [50714, 3351, 13, 50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 62,\n",
              "   'seek': 61440,\n",
              "   'start': 622.4,\n",
              "   'end': 623.4,\n",
              "   'text': ' Bueno, no sé.',\n",
              "   'tokens': [50764, 16046, 11, 572, 7910, 13, 50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 63,\n",
              "   'seek': 61440,\n",
              "   'start': 623.4,\n",
              "   'end': 624.4,\n",
              "   'text': ' Hola.',\n",
              "   'tokens': [50814, 22637, 13, 50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 64,\n",
              "   'seek': 61440,\n",
              "   'start': 624.4,\n",
              "   'end': 625.4,\n",
              "   'text': ' Riqueste.',\n",
              "   'tokens': [50864, 497, 3221, 8887, 13, 50914],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 65,\n",
              "   'seek': 61440,\n",
              "   'start': 625.4,\n",
              "   'end': 626.4,\n",
              "   'text': ' La buena sesión.',\n",
              "   'tokens': [50914, 2369, 25710, 5385, 2560, 13, 50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 66,\n",
              "   'seek': 61440,\n",
              "   'start': 626.4,\n",
              "   'end': 628.4,\n",
              "   'text': ' Y después yo puedo usar esa sesión.',\n",
              "   'tokens': [50964,\n",
              "    398,\n",
              "    15283,\n",
              "    5290,\n",
              "    21612,\n",
              "    14745,\n",
              "    11342,\n",
              "    5385,\n",
              "    2560,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 67,\n",
              "   'seek': 61440,\n",
              "   'start': 628.4,\n",
              "   'end': 631.4,\n",
              "   'text': ' Esa sesión significa justamente ganar todas esas optimizaciones.',\n",
              "   'tokens': [51064,\n",
              "    2313,\n",
              "    64,\n",
              "    5385,\n",
              "    2560,\n",
              "    19957,\n",
              "    41056,\n",
              "    7574,\n",
              "    289,\n",
              "    10906,\n",
              "    23388,\n",
              "    5028,\n",
              "    590,\n",
              "    9188,\n",
              "    13,\n",
              "    51214],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 68,\n",
              "   'seek': 61440,\n",
              "   'start': 631.4,\n",
              "   'end': 637.4,\n",
              "   'text': ' Riquest establece una sesión de comunicación con un servidor y ya mantiene abierta la conexión.',\n",
              "   'tokens': [51214,\n",
              "    497,\n",
              "    3221,\n",
              "    377,\n",
              "    37444,\n",
              "    384,\n",
              "    2002,\n",
              "    5385,\n",
              "    2560,\n",
              "    368,\n",
              "    31710,\n",
              "    3482,\n",
              "    416,\n",
              "    517,\n",
              "    1658,\n",
              "    29718,\n",
              "    288,\n",
              "    2478,\n",
              "    10845,\n",
              "    10174,\n",
              "    410,\n",
              "    811,\n",
              "    1328,\n",
              "    635,\n",
              "    49509,\n",
              "    2560,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 69,\n",
              "   'seek': 61440,\n",
              "   'start': 637.4,\n",
              "   'end': 641.4,\n",
              "   'text': ' Entonces yo después cada vez que mando un mensaje solamente envía el payload.',\n",
              "   'tokens': [51514,\n",
              "    15097,\n",
              "    5290,\n",
              "    15283,\n",
              "    8411,\n",
              "    5715,\n",
              "    631,\n",
              "    7411,\n",
              "    78,\n",
              "    517,\n",
              "    10923,\n",
              "    11153,\n",
              "    27814,\n",
              "    2267,\n",
              "    2686,\n",
              "    806,\n",
              "    30918,\n",
              "    13,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3086246762956892,\n",
              "   'compression_ratio': 1.657243816254417,\n",
              "   'no_speech_prob': 0.02973751723766327},\n",
              "  {'id': 70,\n",
              "   'seek': 64140,\n",
              "   'start': 642.4,\n",
              "   'end': 645.4,\n",
              "   'text': ' Para ahí agrego algo, esto está escalando.',\n",
              "   'tokens': [50414,\n",
              "    11107,\n",
              "    12571,\n",
              "    623,\n",
              "    3375,\n",
              "    78,\n",
              "    8655,\n",
              "    11,\n",
              "    7433,\n",
              "    3192,\n",
              "    17871,\n",
              "    1806,\n",
              "    13,\n",
              "    50564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2755996834518563,\n",
              "   'compression_ratio': 1.608695652173913,\n",
              "   'no_speech_prob': 0.06271471828222275},\n",
              "  {'id': 71,\n",
              "   'seek': 64140,\n",
              "   'start': 645.4,\n",
              "   'end': 652.4,\n",
              "   'text': ' Que realmente cuando uno hace micro servicio el payload es una ID, es un string, es muy chiquito, no estás pasando un imagen de dos digas.',\n",
              "   'tokens': [50564,\n",
              "    4493,\n",
              "    14446,\n",
              "    7767,\n",
              "    8526,\n",
              "    10032,\n",
              "    4532,\n",
              "    43078,\n",
              "    806,\n",
              "    30918,\n",
              "    785,\n",
              "    2002,\n",
              "    7348,\n",
              "    11,\n",
              "    785,\n",
              "    517,\n",
              "    6798,\n",
              "    11,\n",
              "    785,\n",
              "    5323,\n",
              "    417,\n",
              "    3221,\n",
              "    3528,\n",
              "    11,\n",
              "    572,\n",
              "    24389,\n",
              "    45412,\n",
              "    517,\n",
              "    40652,\n",
              "    368,\n",
              "    4491,\n",
              "    2528,\n",
              "    296,\n",
              "    13,\n",
              "    50914],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2755996834518563,\n",
              "   'compression_ratio': 1.608695652173913,\n",
              "   'no_speech_prob': 0.06271471828222275},\n",
              "  {'id': 72,\n",
              "   'seek': 64140,\n",
              "   'start': 652.4,\n",
              "   'end': 661.4,\n",
              "   'text': ' Entonces es realmente es muchísimo lo que uno gana si puede hacer use of optimo de los tiempos esto que estamos haciendo.',\n",
              "   'tokens': [50914,\n",
              "    15097,\n",
              "    785,\n",
              "    14446,\n",
              "    785,\n",
              "    44722,\n",
              "    450,\n",
              "    631,\n",
              "    8526,\n",
              "    290,\n",
              "    2095,\n",
              "    1511,\n",
              "    8919,\n",
              "    6720,\n",
              "    764,\n",
              "    295,\n",
              "    5028,\n",
              "    78,\n",
              "    368,\n",
              "    1750,\n",
              "    7582,\n",
              "    2455,\n",
              "    329,\n",
              "    7433,\n",
              "    631,\n",
              "    10382,\n",
              "    20509,\n",
              "    13,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2755996834518563,\n",
              "   'compression_ratio': 1.608695652173913,\n",
              "   'no_speech_prob': 0.06271471828222275},\n",
              "  {'id': 73,\n",
              "   'seek': 64140,\n",
              "   'start': 663.4,\n",
              "   'end': 670.4,\n",
              "   'text': ' Y si yo lo único que voy a hacer en aplicaciones, una vez por ahora peguirle algo a Google y volver, no esté queriendo activizar esto.',\n",
              "   'tokens': [51464,\n",
              "    398,\n",
              "    1511,\n",
              "    5290,\n",
              "    450,\n",
              "    26113,\n",
              "    631,\n",
              "    7552,\n",
              "    257,\n",
              "    6720,\n",
              "    465,\n",
              "    18221,\n",
              "    9188,\n",
              "    11,\n",
              "    2002,\n",
              "    5715,\n",
              "    1515,\n",
              "    9923,\n",
              "    520,\n",
              "    2794,\n",
              "    347,\n",
              "    306,\n",
              "    8655,\n",
              "    257,\n",
              "    3329,\n",
              "    288,\n",
              "    33998,\n",
              "    11,\n",
              "    572,\n",
              "    34584,\n",
              "    7083,\n",
              "    7304,\n",
              "    2430,\n",
              "    9736,\n",
              "    7433,\n",
              "    13,\n",
              "    51814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2755996834518563,\n",
              "   'compression_ratio': 1.608695652173913,\n",
              "   'no_speech_prob': 0.06271471828222275},\n",
              "  {'id': 74,\n",
              "   'seek': 67040,\n",
              "   'start': 670.4,\n",
              "   'end': 679.4,\n",
              "   'text': ' Y luego pensemos en la escala en la que mi arquitectura entera los miles de ricos que atiendo por segundo se transforman en cientos de miles de ricos adentro de mis istevas.',\n",
              "   'tokens': [50364,\n",
              "    398,\n",
              "    17222,\n",
              "    11209,\n",
              "    3415,\n",
              "    465,\n",
              "    635,\n",
              "    4721,\n",
              "    5159,\n",
              "    465,\n",
              "    635,\n",
              "    631,\n",
              "    2752,\n",
              "    40258,\n",
              "    5739,\n",
              "    2991,\n",
              "    948,\n",
              "    1663,\n",
              "    1750,\n",
              "    6193,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    631,\n",
              "    412,\n",
              "    1174,\n",
              "    78,\n",
              "    1515,\n",
              "    17954,\n",
              "    369,\n",
              "    4088,\n",
              "    282,\n",
              "    465,\n",
              "    269,\n",
              "    20370,\n",
              "    368,\n",
              "    6193,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    614,\n",
              "    317,\n",
              "    340,\n",
              "    368,\n",
              "    3346,\n",
              "    1418,\n",
              "    68,\n",
              "    7967,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2801634335348792,\n",
              "   'compression_ratio': 1.778181818181818,\n",
              "   'no_speech_prob': 0.02095211111009121},\n",
              "  {'id': 75,\n",
              "   'seek': 67040,\n",
              "   'start': 679.4,\n",
              "   'end': 686.4,\n",
              "   'text': ' Cada mil y segundo que yo le gane va a ser un mil y segundo menos de cómputo, mil y segundo menos de tráfico y eso se transforma por lo que creen costos.',\n",
              "   'tokens': [50814,\n",
              "    38603,\n",
              "    1962,\n",
              "    288,\n",
              "    17954,\n",
              "    631,\n",
              "    5290,\n",
              "    476,\n",
              "    290,\n",
              "    1929,\n",
              "    2773,\n",
              "    257,\n",
              "    816,\n",
              "    517,\n",
              "    1962,\n",
              "    288,\n",
              "    17954,\n",
              "    8902,\n",
              "    368,\n",
              "    6333,\n",
              "    2455,\n",
              "    8262,\n",
              "    11,\n",
              "    1962,\n",
              "    288,\n",
              "    17954,\n",
              "    8902,\n",
              "    368,\n",
              "    504,\n",
              "    23858,\n",
              "    78,\n",
              "    288,\n",
              "    7287,\n",
              "    369,\n",
              "    4088,\n",
              "    64,\n",
              "    1515,\n",
              "    450,\n",
              "    631,\n",
              "    1197,\n",
              "    268,\n",
              "    2063,\n",
              "    329,\n",
              "    13,\n",
              "    51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2801634335348792,\n",
              "   'compression_ratio': 1.778181818181818,\n",
              "   'no_speech_prob': 0.02095211111009121},\n",
              "  {'id': 76,\n",
              "   'seek': 67040,\n",
              "   'start': 686.4,\n",
              "   'end': 688.4,\n",
              "   'text': ' Bien, el mejor es en costos.',\n",
              "   'tokens': [51164, 16956, 11, 806, 11479, 785, 465, 2063, 329, 13, 51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2801634335348792,\n",
              "   'compression_ratio': 1.778181818181818,\n",
              "   'no_speech_prob': 0.02095211111009121},\n",
              "  {'id': 77,\n",
              "   'seek': 67040,\n",
              "   'start': 688.4,\n",
              "   'end': 697.4,\n",
              "   'text': ' Entonces los otros vivimos que se estaba usando de forma naive, Riquest, trabajamos con múltiples equipos entre la organización.',\n",
              "   'tokens': [51264,\n",
              "    15097,\n",
              "    1750,\n",
              "    16422,\n",
              "    11005,\n",
              "    8372,\n",
              "    631,\n",
              "    369,\n",
              "    17544,\n",
              "    29798,\n",
              "    368,\n",
              "    8366,\n",
              "    29052,\n",
              "    11,\n",
              "    497,\n",
              "    3221,\n",
              "    377,\n",
              "    11,\n",
              "    9618,\n",
              "    2151,\n",
              "    416,\n",
              "    275,\n",
              "    43447,\n",
              "    72,\n",
              "    2622,\n",
              "    5037,\n",
              "    329,\n",
              "    3962,\n",
              "    635,\n",
              "    4645,\n",
              "    3482,\n",
              "    13,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2801634335348792,\n",
              "   'compression_ratio': 1.778181818181818,\n",
              "   'no_speech_prob': 0.02095211111009121},\n",
              "  {'id': 78,\n",
              "   'seek': 69740,\n",
              "   'start': 697.4,\n",
              "   'end': 707.4,\n",
              "   'text': ' Veamos que estaban usando Riquest así no más como Quick Start y hicimos algunos benchmarks usando session y en particular el happy que hacemos con Rudy empezamos a usar sessions.',\n",
              "   'tokens': [50364,\n",
              "    9706,\n",
              "    2151,\n",
              "    631,\n",
              "    36713,\n",
              "    29798,\n",
              "    497,\n",
              "    3221,\n",
              "    377,\n",
              "    8582,\n",
              "    572,\n",
              "    3573,\n",
              "    2617,\n",
              "    12101,\n",
              "    6481,\n",
              "    288,\n",
              "    23697,\n",
              "    8372,\n",
              "    21078,\n",
              "    43751,\n",
              "    29798,\n",
              "    5481,\n",
              "    288,\n",
              "    465,\n",
              "    1729,\n",
              "    806,\n",
              "    2055,\n",
              "    631,\n",
              "    33839,\n",
              "    416,\n",
              "    38690,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    14745,\n",
              "    11081,\n",
              "    13,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3376580801877109,\n",
              "   'compression_ratio': 1.510204081632653,\n",
              "   'no_speech_prob': 0.08744177222251892},\n",
              "  {'id': 79,\n",
              "   'seek': 69740,\n",
              "   'start': 707.4,\n",
              "   'end': 712.4,\n",
              "   'text': ' Claro. Y vimos mejoras impresionantes con realmente como poco cambio.',\n",
              "   'tokens': [50864,\n",
              "    33380,\n",
              "    13,\n",
              "    398,\n",
              "    49266,\n",
              "    11479,\n",
              "    296,\n",
              "    35672,\n",
              "    313,\n",
              "    9327,\n",
              "    416,\n",
              "    14446,\n",
              "    2617,\n",
              "    10639,\n",
              "    28731,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3376580801877109,\n",
              "   'compression_ratio': 1.510204081632653,\n",
              "   'no_speech_prob': 0.08744177222251892},\n",
              "  {'id': 80,\n",
              "   'seek': 69740,\n",
              "   'start': 712.4,\n",
              "   'end': 720.4,\n",
              "   'text': ' Por ejemplo, la cantidad de ricos que puedo hacer eso por segundo con el primer vea su eco, digo, son alrededor de 500.',\n",
              "   'tokens': [51114,\n",
              "    5269,\n",
              "    13358,\n",
              "    11,\n",
              "    635,\n",
              "    33757,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    631,\n",
              "    21612,\n",
              "    6720,\n",
              "    7287,\n",
              "    1515,\n",
              "    17954,\n",
              "    416,\n",
              "    806,\n",
              "    12595,\n",
              "    1241,\n",
              "    64,\n",
              "    459,\n",
              "    30226,\n",
              "    11,\n",
              "    22990,\n",
              "    11,\n",
              "    1872,\n",
              "    43663,\n",
              "    368,\n",
              "    5923,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3376580801877109,\n",
              "   'compression_ratio': 1.510204081632653,\n",
              "   'no_speech_prob': 0.08744177222251892},\n",
              "  {'id': 81,\n",
              "   'seek': 72040,\n",
              "   'start': 721.4,\n",
              "   'end': 730.4,\n",
              "   'text': ' Usando sessions se duplicó, se duplicó la cantidad de ricos que puedo hacer eso en un segundo haciendo tres líneas de código de cambio.',\n",
              "   'tokens': [50414,\n",
              "    4958,\n",
              "    1806,\n",
              "    11081,\n",
              "    369,\n",
              "    17154,\n",
              "    812,\n",
              "    11,\n",
              "    369,\n",
              "    17154,\n",
              "    812,\n",
              "    635,\n",
              "    33757,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    631,\n",
              "    21612,\n",
              "    6720,\n",
              "    7287,\n",
              "    465,\n",
              "    517,\n",
              "    17954,\n",
              "    20509,\n",
              "    15890,\n",
              "    16118,\n",
              "    716,\n",
              "    296,\n",
              "    368,\n",
              "    44195,\n",
              "    368,\n",
              "    28731,\n",
              "    13,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35028264662798714,\n",
              "   'compression_ratio': 1.671497584541063,\n",
              "   'no_speech_prob': 0.056567057967185974},\n",
              "  {'id': 82,\n",
              "   'seek': 72040,\n",
              "   'start': 730.4,\n",
              "   'end': 740.4,\n",
              "   'text': ' Bien, acá bueno el vea no me quiero hacer refoco en el benchmark si pero bueno hicimos esto es una prueba local, obviamente la cantidad de ricos que puedan hacer por segundo va a vender 1 millón de cosas.',\n",
              "   'tokens': [50864,\n",
              "    16956,\n",
              "    11,\n",
              "    23496,\n",
              "    11974,\n",
              "    806,\n",
              "    1241,\n",
              "    64,\n",
              "    572,\n",
              "    385,\n",
              "    16811,\n",
              "    6720,\n",
              "    1895,\n",
              "    11198,\n",
              "    465,\n",
              "    806,\n",
              "    18927,\n",
              "    1511,\n",
              "    4768,\n",
              "    11974,\n",
              "    23697,\n",
              "    8372,\n",
              "    7433,\n",
              "    785,\n",
              "    2002,\n",
              "    48241,\n",
              "    2654,\n",
              "    11,\n",
              "    36325,\n",
              "    635,\n",
              "    33757,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    631,\n",
              "    41241,\n",
              "    6720,\n",
              "    1515,\n",
              "    17954,\n",
              "    2773,\n",
              "    257,\n",
              "    44281,\n",
              "    502,\n",
              "    1728,\n",
              "    1801,\n",
              "    368,\n",
              "    12218,\n",
              "    13,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35028264662798714,\n",
              "   'compression_ratio': 1.671497584541063,\n",
              "   'no_speech_prob': 0.056567057967185974},\n",
              "  {'id': 83,\n",
              "   'seek': 74040,\n",
              "   'start': 740.4,\n",
              "   'end': 747.4,\n",
              "   'text': ' Cuando probas R, tratas de australerte de la RID y usas tu propia interfaz de tu máquina como para tener algo consistente.',\n",
              "   'tokens': [50364,\n",
              "    21907,\n",
              "    1239,\n",
              "    296,\n",
              "    497,\n",
              "    11,\n",
              "    21507,\n",
              "    296,\n",
              "    368,\n",
              "    34916,\n",
              "    2155,\n",
              "    10634,\n",
              "    368,\n",
              "    635,\n",
              "    497,\n",
              "    2777,\n",
              "    288,\n",
              "    505,\n",
              "    296,\n",
              "    2604,\n",
              "    40464,\n",
              "    14510,\n",
              "    921,\n",
              "    368,\n",
              "    2604,\n",
              "    49360,\n",
              "    2617,\n",
              "    1690,\n",
              "    11640,\n",
              "    8655,\n",
              "    4603,\n",
              "    1576,\n",
              "    13,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3790009442497702,\n",
              "   'compression_ratio': 1.5457627118644068,\n",
              "   'no_speech_prob': 0.1821548044681549},\n",
              "  {'id': 84,\n",
              "   'seek': 74040,\n",
              "   'start': 747.4,\n",
              "   'end': 754.4,\n",
              "   'text': ' Entonces realmente por hacer tres líneas de código de cambio ganamos una performance en cuanto a la cantidad rico que podemos hacer por segundo del doble.',\n",
              "   'tokens': [50714,\n",
              "    15097,\n",
              "    14446,\n",
              "    1515,\n",
              "    6720,\n",
              "    15890,\n",
              "    16118,\n",
              "    716,\n",
              "    296,\n",
              "    368,\n",
              "    44195,\n",
              "    368,\n",
              "    28731,\n",
              "    7574,\n",
              "    2151,\n",
              "    2002,\n",
              "    3389,\n",
              "    465,\n",
              "    36685,\n",
              "    257,\n",
              "    635,\n",
              "    33757,\n",
              "    367,\n",
              "    2789,\n",
              "    631,\n",
              "    12234,\n",
              "    6720,\n",
              "    1515,\n",
              "    17954,\n",
              "    1103,\n",
              "    360,\n",
              "    638,\n",
              "    13,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3790009442497702,\n",
              "   'compression_ratio': 1.5457627118644068,\n",
              "   'no_speech_prob': 0.1821548044681549},\n",
              "  {'id': 85,\n",
              "   'seek': 74040,\n",
              "   'start': 754.4,\n",
              "   'end': 765.4,\n",
              "   'text': ' También es más impresionante en una esquema chiste de TPS donde toda la negociación de certificados de SCL, metetanto a Vergette, que yo podía hacer 146 ricos por segundo,',\n",
              "   'tokens': [51064,\n",
              "    25682,\n",
              "    785,\n",
              "    3573,\n",
              "    35672,\n",
              "    313,\n",
              "    2879,\n",
              "    465,\n",
              "    2002,\n",
              "    34611,\n",
              "    5619,\n",
              "    417,\n",
              "    8375,\n",
              "    368,\n",
              "    314,\n",
              "    6273,\n",
              "    10488,\n",
              "    11687,\n",
              "    635,\n",
              "    26722,\n",
              "    537,\n",
              "    3482,\n",
              "    368,\n",
              "    12378,\n",
              "    4181,\n",
              "    368,\n",
              "    9028,\n",
              "    43,\n",
              "    11,\n",
              "    1131,\n",
              "    302,\n",
              "    5857,\n",
              "    257,\n",
              "    4281,\n",
              "    847,\n",
              "    975,\n",
              "    11,\n",
              "    631,\n",
              "    5290,\n",
              "    45588,\n",
              "    6720,\n",
              "    3499,\n",
              "    21,\n",
              "    367,\n",
              "    9940,\n",
              "    1515,\n",
              "    17954,\n",
              "    11,\n",
              "    51614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3790009442497702,\n",
              "   'compression_ratio': 1.5457627118644068,\n",
              "   'no_speech_prob': 0.1821548044681549},\n",
              "  {'id': 86,\n",
              "   'seek': 76540,\n",
              "   'start': 765.4,\n",
              "   'end': 772.4,\n",
              "   'text': ' habría desarrollándolo con acción y pasando sesiones, pasó a mil, o sea el cambio y la gana se realmente impresionante.',\n",
              "   'tokens': [50364,\n",
              "    32794,\n",
              "    2686,\n",
              "    32501,\n",
              "    18606,\n",
              "    7902,\n",
              "    416,\n",
              "    696,\n",
              "    5687,\n",
              "    288,\n",
              "    45412,\n",
              "    5385,\n",
              "    5411,\n",
              "    11,\n",
              "    41382,\n",
              "    257,\n",
              "    1962,\n",
              "    11,\n",
              "    277,\n",
              "    4158,\n",
              "    806,\n",
              "    28731,\n",
              "    288,\n",
              "    635,\n",
              "    290,\n",
              "    2095,\n",
              "    369,\n",
              "    14446,\n",
              "    35672,\n",
              "    313,\n",
              "    2879,\n",
              "    13,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.424698969523112,\n",
              "   'compression_ratio': 1.443298969072165,\n",
              "   'no_speech_prob': 0.03459952026605606},\n",
              "  {'id': 87,\n",
              "   'seek': 76540,\n",
              "   'start': 772.4,\n",
              "   'end': 788.4,\n",
              "   'text': ' Entonces bueno y también todo el que priori no habíamos pensado pero que terminó sucediendo es que el uso de CPU, el mi aplicación, casi pasó la mitad.',\n",
              "   'tokens': [50714,\n",
              "    15097,\n",
              "    11974,\n",
              "    288,\n",
              "    6407,\n",
              "    5149,\n",
              "    806,\n",
              "    631,\n",
              "    4059,\n",
              "    72,\n",
              "    572,\n",
              "    3025,\n",
              "    16275,\n",
              "    6099,\n",
              "    1573,\n",
              "    4768,\n",
              "    631,\n",
              "    10761,\n",
              "    812,\n",
              "    41928,\n",
              "    7304,\n",
              "    785,\n",
              "    631,\n",
              "    806,\n",
              "    22728,\n",
              "    368,\n",
              "    13199,\n",
              "    11,\n",
              "    806,\n",
              "    2752,\n",
              "    18221,\n",
              "    3482,\n",
              "    11,\n",
              "    22567,\n",
              "    1736,\n",
              "    812,\n",
              "    635,\n",
              "    46895,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.424698969523112,\n",
              "   'compression_ratio': 1.443298969072165,\n",
              "   'no_speech_prob': 0.03459952026605606},\n",
              "  {'id': 88,\n",
              "   'seek': 78840,\n",
              "   'start': 789.4,\n",
              "   'end': 798.4,\n",
              "   'text': ' Porque todas estas cosas que estaban haciendo ricos por abajo no las tiene que hacer más y si estamos pagando por CPU, por ejemplo comprando instancias en la 9,',\n",
              "   'tokens': [50414,\n",
              "    11287,\n",
              "    10906,\n",
              "    13897,\n",
              "    12218,\n",
              "    631,\n",
              "    36713,\n",
              "    20509,\n",
              "    367,\n",
              "    9940,\n",
              "    1515,\n",
              "    30613,\n",
              "    572,\n",
              "    2439,\n",
              "    7066,\n",
              "    631,\n",
              "    6720,\n",
              "    3573,\n",
              "    288,\n",
              "    1511,\n",
              "    10382,\n",
              "    11812,\n",
              "    1806,\n",
              "    1515,\n",
              "    13199,\n",
              "    11,\n",
              "    1515,\n",
              "    13358,\n",
              "    715,\n",
              "    19845,\n",
              "    1058,\n",
              "    282,\n",
              "    12046,\n",
              "    465,\n",
              "    635,\n",
              "    1722,\n",
              "    11,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3287111992059752,\n",
              "   'compression_ratio': 1.5377358490566038,\n",
              "   'no_speech_prob': 0.34799936413764954},\n",
              "  {'id': 89,\n",
              "   'seek': 78840,\n",
              "   'start': 798.4,\n",
              "   'end': 809.4,\n",
              "   'text': ' tal vez si tengo múltiples instancias, bueno usarla menos significa costo, mejoras en costos, o si tienen datos entre en su pieza, no sé menos calor, algo pero...',\n",
              "   'tokens': [50864,\n",
              "    4023,\n",
              "    5715,\n",
              "    1511,\n",
              "    13989,\n",
              "    275,\n",
              "    43447,\n",
              "    72,\n",
              "    2622,\n",
              "    1058,\n",
              "    282,\n",
              "    12046,\n",
              "    11,\n",
              "    11974,\n",
              "    14745,\n",
              "    875,\n",
              "    8902,\n",
              "    19957,\n",
              "    2063,\n",
              "    78,\n",
              "    11,\n",
              "    11479,\n",
              "    296,\n",
              "    465,\n",
              "    2063,\n",
              "    329,\n",
              "    11,\n",
              "    277,\n",
              "    1511,\n",
              "    12536,\n",
              "    27721,\n",
              "    3962,\n",
              "    465,\n",
              "    459,\n",
              "    1730,\n",
              "    2394,\n",
              "    11,\n",
              "    572,\n",
              "    7910,\n",
              "    8902,\n",
              "    31575,\n",
              "    11,\n",
              "    8655,\n",
              "    4768,\n",
              "    485,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3287111992059752,\n",
              "   'compression_ratio': 1.5377358490566038,\n",
              "   'no_speech_prob': 0.34799936413764954},\n",
              "  {'id': 90,\n",
              "   'seek': 80940,\n",
              "   'start': 810.4,\n",
              "   'end': 826.4,\n",
              "   'text': ' La ventaja para todos, entonces bueno a ver por qué estamos usando ricos, porque estábamos usando ricos, tiene una interfaz espectacular, realmente muy amigable, muy simple hacer un llamado de Jueves, después tiene un montón de ventajas asociadas a las aplicaciones web tradicionales, no necesariamente a micro-servings,',\n",
              "   'tokens': [50414,\n",
              "    2369,\n",
              "    6931,\n",
              "    12908,\n",
              "    1690,\n",
              "    6321,\n",
              "    11,\n",
              "    13003,\n",
              "    11974,\n",
              "    257,\n",
              "    1306,\n",
              "    1515,\n",
              "    8057,\n",
              "    10382,\n",
              "    29798,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    4021,\n",
              "    3192,\n",
              "    65,\n",
              "    2151,\n",
              "    29798,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    7066,\n",
              "    2002,\n",
              "    14510,\n",
              "    921,\n",
              "    38244,\n",
              "    14700,\n",
              "    11,\n",
              "    14446,\n",
              "    5323,\n",
              "    669,\n",
              "    328,\n",
              "    712,\n",
              "    11,\n",
              "    5323,\n",
              "    2199,\n",
              "    6720,\n",
              "    517,\n",
              "    47055,\n",
              "    368,\n",
              "    508,\n",
              "    622,\n",
              "    977,\n",
              "    11,\n",
              "    15283,\n",
              "    7066,\n",
              "    517,\n",
              "    45259,\n",
              "    368,\n",
              "    6931,\n",
              "    1805,\n",
              "    296,\n",
              "    382,\n",
              "    78,\n",
              "    537,\n",
              "    6872,\n",
              "    257,\n",
              "    2439,\n",
              "    18221,\n",
              "    9188,\n",
              "    3670,\n",
              "    47956,\n",
              "    279,\n",
              "    11,\n",
              "    572,\n",
              "    11909,\n",
              "    45149,\n",
              "    257,\n",
              "    4532,\n",
              "    12,\n",
              "    12484,\n",
              "    798,\n",
              "    82,\n",
              "    11,\n",
              "    51214],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4305534827999952,\n",
              "   'compression_ratio': 1.5502392344497609,\n",
              "   'no_speech_prob': 0.4756048321723938},\n",
              "  {'id': 91,\n",
              "   'seek': 82640,\n",
              "   'start': 827.4,\n",
              "   'end': 843.4,\n",
              "   'text': ' entonces manejos de cookies, verificaciones de cosas de seguridad, decodificación de contenido, streaming, chunking de vio de datos, tiene un montón de ventajas que están buenísimas, de las cuales a nosotros prácticamente no nos interesa ninguna.',\n",
              "   'tokens': [50414,\n",
              "    13003,\n",
              "    12743,\n",
              "    19136,\n",
              "    368,\n",
              "    13670,\n",
              "    11,\n",
              "    1306,\n",
              "    1089,\n",
              "    9188,\n",
              "    368,\n",
              "    12218,\n",
              "    368,\n",
              "    35415,\n",
              "    11,\n",
              "    979,\n",
              "    378,\n",
              "    40802,\n",
              "    368,\n",
              "    47117,\n",
              "    11,\n",
              "    11791,\n",
              "    11,\n",
              "    16635,\n",
              "    278,\n",
              "    368,\n",
              "    371,\n",
              "    1004,\n",
              "    368,\n",
              "    27721,\n",
              "    11,\n",
              "    7066,\n",
              "    517,\n",
              "    45259,\n",
              "    368,\n",
              "    6931,\n",
              "    1805,\n",
              "    296,\n",
              "    631,\n",
              "    10368,\n",
              "    30037,\n",
              "    5113,\n",
              "    17957,\n",
              "    11,\n",
              "    368,\n",
              "    2439,\n",
              "    46932,\n",
              "    257,\n",
              "    13863,\n",
              "    27300,\n",
              "    50250,\n",
              "    572,\n",
              "    3269,\n",
              "    728,\n",
              "    13708,\n",
              "    36073,\n",
              "    13,\n",
              "    51214],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2833041826883952,\n",
              "   'compression_ratio': 1.5120481927710843,\n",
              "   'no_speech_prob': 0.08623896539211273},\n",
              "  {'id': 92,\n",
              "   'seek': 84340,\n",
              "   'start': 844.4,\n",
              "   'end': 851.4,\n",
              "   'text': ' Está bien, te va a ir a empezar muy rápido, pero en el fondo usa un relícter.',\n",
              "   'tokens': [50414,\n",
              "    27304,\n",
              "    3610,\n",
              "    11,\n",
              "    535,\n",
              "    2773,\n",
              "    257,\n",
              "    3418,\n",
              "    257,\n",
              "    31168,\n",
              "    5323,\n",
              "    24893,\n",
              "    11,\n",
              "    4768,\n",
              "    465,\n",
              "    806,\n",
              "    38101,\n",
              "    29909,\n",
              "    517,\n",
              "    1039,\n",
              "    870,\n",
              "    349,\n",
              "    260,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.40344980027940536,\n",
              "   'compression_ratio': 0.975609756097561,\n",
              "   'no_speech_prob': 0.16860716044902802},\n",
              "  {'id': 93,\n",
              "   'seek': 85140,\n",
              "   'start': 852.4,\n",
              "   'end': 874.4,\n",
              "   'text': ' Hay alguna aclaración, esto no se trata de comparar cosas, no queremos hacer comparaciones, las comparaciones son odiosas, en realidad estamos tratando de ver distintas herramientas, yo oí lo veo como rico es una herramienta para resolver algunos tipos problemas y Jueves relíctres, que es lo que voy a hablar un poquito ahora, es una herramienta para resolver otro tipo de problema,',\n",
              "   'tokens': [50414,\n",
              "    8721,\n",
              "    20651,\n",
              "    696,\n",
              "    2200,\n",
              "    3482,\n",
              "    11,\n",
              "    7433,\n",
              "    572,\n",
              "    369,\n",
              "    31920,\n",
              "    368,\n",
              "    6311,\n",
              "    289,\n",
              "    12218,\n",
              "    11,\n",
              "    572,\n",
              "    26813,\n",
              "    6720,\n",
              "    6311,\n",
              "    9188,\n",
              "    11,\n",
              "    2439,\n",
              "    6311,\n",
              "    9188,\n",
              "    1872,\n",
              "    3611,\n",
              "    2717,\n",
              "    296,\n",
              "    11,\n",
              "    465,\n",
              "    25635,\n",
              "    10382,\n",
              "    21507,\n",
              "    1806,\n",
              "    368,\n",
              "    1306,\n",
              "    31489,\n",
              "    296,\n",
              "    38271,\n",
              "    296,\n",
              "    11,\n",
              "    5290,\n",
              "    277,\n",
              "    870,\n",
              "    450,\n",
              "    41319,\n",
              "    2617,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    2002,\n",
              "    38271,\n",
              "    64,\n",
              "    1690,\n",
              "    34480,\n",
              "    21078,\n",
              "    37105,\n",
              "    20720,\n",
              "    288,\n",
              "    508,\n",
              "    622,\n",
              "    977,\n",
              "    1039,\n",
              "    870,\n",
              "    349,\n",
              "    495,\n",
              "    11,\n",
              "    631,\n",
              "    785,\n",
              "    450,\n",
              "    631,\n",
              "    7552,\n",
              "    257,\n",
              "    21014,\n",
              "    517,\n",
              "    28229,\n",
              "    9923,\n",
              "    11,\n",
              "    785,\n",
              "    2002,\n",
              "    38271,\n",
              "    64,\n",
              "    1690,\n",
              "    34480,\n",
              "    11921,\n",
              "    9746,\n",
              "    368,\n",
              "    12395,\n",
              "    11,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.240389895695512,\n",
              "   'compression_ratio': 1.7788018433179724,\n",
              "   'no_speech_prob': 0.20150095224380493},\n",
              "  {'id': 94,\n",
              "   'seek': 87440,\n",
              "   'start': 875.4,\n",
              "   'end': 884.4,\n",
              "   'text': ' que estamos comparando que una es mejor que otra, son cosas diferentes, en el caso de web relíctres, lo primero que fuimos a analizar es ¿qué tan diferente es la interfaz?',\n",
              "   'tokens': [50414,\n",
              "    631,\n",
              "    10382,\n",
              "    6311,\n",
              "    1806,\n",
              "    631,\n",
              "    2002,\n",
              "    785,\n",
              "    11479,\n",
              "    631,\n",
              "    13623,\n",
              "    11,\n",
              "    1872,\n",
              "    12218,\n",
              "    17686,\n",
              "    11,\n",
              "    465,\n",
              "    806,\n",
              "    9666,\n",
              "    368,\n",
              "    3670,\n",
              "    1039,\n",
              "    870,\n",
              "    349,\n",
              "    495,\n",
              "    11,\n",
              "    450,\n",
              "    21289,\n",
              "    631,\n",
              "    8536,\n",
              "    8372,\n",
              "    257,\n",
              "    2624,\n",
              "    9736,\n",
              "    785,\n",
              "    3841,\n",
              "    16412,\n",
              "    7603,\n",
              "    20973,\n",
              "    785,\n",
              "    635,\n",
              "    14510,\n",
              "    921,\n",
              "    30,\n",
              "    50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2633663507608267,\n",
              "   'compression_ratio': 1.5984555984555984,\n",
              "   'no_speech_prob': 0.06004759669303894},\n",
              "  {'id': 95,\n",
              "   'seek': 87440,\n",
              "   'start': 884.4,\n",
              "   'end': 896.4,\n",
              "   'text': ' Porque esto lo tenemos a replicar en 300 equipos, tenemos aligo un mensaje a 300 equipos de heche, deberíamos empezar a utilizar este herramienta porque ahí lo vamos a ver más adelante, y nos encontramos que si bien no están amigables,',\n",
              "   'tokens': [50864,\n",
              "    11287,\n",
              "    7433,\n",
              "    450,\n",
              "    9914,\n",
              "    257,\n",
              "    3248,\n",
              "    7953,\n",
              "    465,\n",
              "    6641,\n",
              "    5037,\n",
              "    329,\n",
              "    11,\n",
              "    9914,\n",
              "    419,\n",
              "    7483,\n",
              "    517,\n",
              "    10923,\n",
              "    11153,\n",
              "    257,\n",
              "    6641,\n",
              "    5037,\n",
              "    329,\n",
              "    368,\n",
              "    415,\n",
              "    1876,\n",
              "    11,\n",
              "    29671,\n",
              "    16275,\n",
              "    31168,\n",
              "    257,\n",
              "    24060,\n",
              "    4065,\n",
              "    38271,\n",
              "    64,\n",
              "    4021,\n",
              "    12571,\n",
              "    450,\n",
              "    5295,\n",
              "    257,\n",
              "    1306,\n",
              "    3573,\n",
              "    40214,\n",
              "    11,\n",
              "    288,\n",
              "    3269,\n",
              "    45049,\n",
              "    631,\n",
              "    1511,\n",
              "    3610,\n",
              "    572,\n",
              "    10368,\n",
              "    669,\n",
              "    328,\n",
              "    2965,\n",
              "    11,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2633663507608267,\n",
              "   'compression_ratio': 1.5984555984555984,\n",
              "   'no_speech_prob': 0.06004759669303894},\n",
              "  {'id': 96,\n",
              "   'seek': 89640,\n",
              "   'start': 897.4,\n",
              "   'end': 911.4,\n",
              "   'text': ' acá no puede utilizar como así con rico es de no hacer una sesión, acá realmente hay que hacer un pull, lo sision de rico es en el fondo, hace un pull de web relíctres, hay que ser más explícito en los parámetros, no es tan que los adivinos mágicamente,',\n",
              "   'tokens': [50414,\n",
              "    23496,\n",
              "    572,\n",
              "    8919,\n",
              "    24060,\n",
              "    2617,\n",
              "    8582,\n",
              "    416,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    368,\n",
              "    572,\n",
              "    6720,\n",
              "    2002,\n",
              "    5385,\n",
              "    2560,\n",
              "    11,\n",
              "    23496,\n",
              "    14446,\n",
              "    4842,\n",
              "    631,\n",
              "    6720,\n",
              "    517,\n",
              "    2235,\n",
              "    11,\n",
              "    450,\n",
              "    262,\n",
              "    1991,\n",
              "    368,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    465,\n",
              "    806,\n",
              "    38101,\n",
              "    11,\n",
              "    10032,\n",
              "    517,\n",
              "    2235,\n",
              "    368,\n",
              "    3670,\n",
              "    1039,\n",
              "    870,\n",
              "    349,\n",
              "    495,\n",
              "    11,\n",
              "    4842,\n",
              "    631,\n",
              "    816,\n",
              "    3573,\n",
              "    1490,\n",
              "    870,\n",
              "    32030,\n",
              "    465,\n",
              "    1750,\n",
              "    971,\n",
              "    842,\n",
              "    29570,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    7603,\n",
              "    631,\n",
              "    1750,\n",
              "    614,\n",
              "    592,\n",
              "    15220,\n",
              "    12228,\n",
              "    70,\n",
              "    23653,\n",
              "    11,\n",
              "    51114],\n",
              "   'temperature': 0.2,\n",
              "   'avg_logprob': -0.26845689981925386,\n",
              "   'compression_ratio': 1.691699604743083,\n",
              "   'no_speech_prob': 0.09131621569395065},\n",
              "  {'id': 97,\n",
              "   'seek': 89640,\n",
              "   'start': 911.4,\n",
              "   'end': 922.4,\n",
              "   'text': ' igual son dos parámetros, uno dice a cuántos dominios diferente va a mantener una conexión, por ejemplo si me conecto a 5 microservicios, el número de pull es 5,',\n",
              "   'tokens': [51114,\n",
              "    10953,\n",
              "    1872,\n",
              "    4491,\n",
              "    971,\n",
              "    842,\n",
              "    29570,\n",
              "    11,\n",
              "    8526,\n",
              "    10313,\n",
              "    257,\n",
              "    44256,\n",
              "    329,\n",
              "    8859,\n",
              "    2717,\n",
              "    20973,\n",
              "    2773,\n",
              "    257,\n",
              "    42759,\n",
              "    2002,\n",
              "    49509,\n",
              "    2560,\n",
              "    11,\n",
              "    1515,\n",
              "    13358,\n",
              "    1511,\n",
              "    385,\n",
              "    30458,\n",
              "    78,\n",
              "    257,\n",
              "    1025,\n",
              "    15547,\n",
              "    1978,\n",
              "    299,\n",
              "    2717,\n",
              "    11,\n",
              "    806,\n",
              "    14959,\n",
              "    368,\n",
              "    2235,\n",
              "    785,\n",
              "    1025,\n",
              "    11,\n",
              "    51664],\n",
              "   'temperature': 0.2,\n",
              "   'avg_logprob': -0.26845689981925386,\n",
              "   'compression_ratio': 1.691699604743083,\n",
              "   'no_speech_prob': 0.09131621569395065},\n",
              "  {'id': 98,\n",
              "   'seek': 92240,\n",
              "   'start': 923.4,\n",
              "   'end': 935.4,\n",
              "   'text': ' el maxize que está ahí como 10 es la cantidad de hilos que vamos a tener abierto por cada pull, entonces si estamos trabajando con un unicornbudo lsg y estamos haciendo Tridin y vamos a poner 10 hilos,',\n",
              "   'tokens': [50414,\n",
              "    806,\n",
              "    11469,\n",
              "    1125,\n",
              "    631,\n",
              "    3192,\n",
              "    12571,\n",
              "    2617,\n",
              "    1266,\n",
              "    785,\n",
              "    635,\n",
              "    33757,\n",
              "    368,\n",
              "    276,\n",
              "    6136,\n",
              "    631,\n",
              "    5295,\n",
              "    257,\n",
              "    11640,\n",
              "    410,\n",
              "    20747,\n",
              "    1515,\n",
              "    8411,\n",
              "    2235,\n",
              "    11,\n",
              "    13003,\n",
              "    1511,\n",
              "    10382,\n",
              "    40473,\n",
              "    416,\n",
              "    517,\n",
              "    28122,\n",
              "    65,\n",
              "    6207,\n",
              "    287,\n",
              "    82,\n",
              "    70,\n",
              "    288,\n",
              "    10382,\n",
              "    20509,\n",
              "    1765,\n",
              "    327,\n",
              "    259,\n",
              "    288,\n",
              "    5295,\n",
              "    257,\n",
              "    19149,\n",
              "    1266,\n",
              "    276,\n",
              "    6136,\n",
              "    11,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2814634091386171,\n",
              "   'compression_ratio': 1.6900826446280992,\n",
              "   'no_speech_prob': 0.01495232991874218},\n",
              "  {'id': 99,\n",
              "   'seek': 92240,\n",
              "   'start': 935.4,\n",
              "   'end': 944.4,\n",
              "   'text': ' sabemos que ahí tenemos que poner un número 10 o más, esto no es un número duro, no es que si de repente hay más hilos corriendo insestables en más conexiones no nos va a permitir, lo que va a pasar,',\n",
              "   'tokens': [51014,\n",
              "    27200,\n",
              "    631,\n",
              "    12571,\n",
              "    9914,\n",
              "    631,\n",
              "    19149,\n",
              "    517,\n",
              "    14959,\n",
              "    1266,\n",
              "    277,\n",
              "    3573,\n",
              "    11,\n",
              "    7433,\n",
              "    572,\n",
              "    785,\n",
              "    517,\n",
              "    14959,\n",
              "    1581,\n",
              "    340,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    631,\n",
              "    1511,\n",
              "    368,\n",
              "    42884,\n",
              "    4842,\n",
              "    3573,\n",
              "    276,\n",
              "    6136,\n",
              "    47908,\n",
              "    3999,\n",
              "    1028,\n",
              "    377,\n",
              "    2965,\n",
              "    465,\n",
              "    3573,\n",
              "    49509,\n",
              "    5411,\n",
              "    572,\n",
              "    3269,\n",
              "    2773,\n",
              "    257,\n",
              "    46865,\n",
              "    11,\n",
              "    450,\n",
              "    631,\n",
              "    2773,\n",
              "    257,\n",
              "    25344,\n",
              "    11,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2814634091386171,\n",
              "   'compression_ratio': 1.6900826446280992,\n",
              "   'no_speech_prob': 0.01495232991874218},\n",
              "  {'id': 100,\n",
              "   'seek': 94440,\n",
              "   'start': 944.4,\n",
              "   'end': 952.4,\n",
              "   'text': ' que cuando se cumple un timeout va a ir eliminando conexiones y siempre va a dejar 10 establecidas y las otras se van a tener establecer cuando siguen inicion,',\n",
              "   'tokens': [50364,\n",
              "    631,\n",
              "    7767,\n",
              "    369,\n",
              "    12713,\n",
              "    781,\n",
              "    517,\n",
              "    565,\n",
              "    346,\n",
              "    2773,\n",
              "    257,\n",
              "    3418,\n",
              "    7892,\n",
              "    1806,\n",
              "    49509,\n",
              "    5411,\n",
              "    288,\n",
              "    12758,\n",
              "    2773,\n",
              "    257,\n",
              "    24391,\n",
              "    1266,\n",
              "    37444,\n",
              "    66,\n",
              "    11382,\n",
              "    288,\n",
              "    2439,\n",
              "    20244,\n",
              "    369,\n",
              "    3161,\n",
              "    257,\n",
              "    11640,\n",
              "    37444,\n",
              "    1776,\n",
              "    7767,\n",
              "    4556,\n",
              "    7801,\n",
              "    294,\n",
              "    299,\n",
              "    313,\n",
              "    11,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2762568445488958,\n",
              "   'compression_ratio': 1.5851528384279476,\n",
              "   'no_speech_prob': 0.09661535173654556},\n",
              "  {'id': 101,\n",
              "   'seek': 94440,\n",
              "   'start': 953.4,\n",
              "   'end': 967.4,\n",
              "   'text': ' después en el uso y es un poco raro en realidad el get no es un método y es un parámetro, los fields, hay cosas que realmente el interfaz rico es tan buenísima y no la tenemos en un lugar relíctres,',\n",
              "   'tokens': [50814,\n",
              "    15283,\n",
              "    465,\n",
              "    806,\n",
              "    22728,\n",
              "    288,\n",
              "    785,\n",
              "    517,\n",
              "    10639,\n",
              "    367,\n",
              "    9708,\n",
              "    465,\n",
              "    25635,\n",
              "    806,\n",
              "    483,\n",
              "    572,\n",
              "    785,\n",
              "    517,\n",
              "    20275,\n",
              "    17423,\n",
              "    288,\n",
              "    785,\n",
              "    517,\n",
              "    971,\n",
              "    842,\n",
              "    45400,\n",
              "    11,\n",
              "    1750,\n",
              "    7909,\n",
              "    11,\n",
              "    4842,\n",
              "    12218,\n",
              "    631,\n",
              "    14446,\n",
              "    806,\n",
              "    14510,\n",
              "    921,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    7603,\n",
              "    30037,\n",
              "    5113,\n",
              "    4775,\n",
              "    288,\n",
              "    572,\n",
              "    635,\n",
              "    9914,\n",
              "    465,\n",
              "    517,\n",
              "    11467,\n",
              "    1039,\n",
              "    870,\n",
              "    349,\n",
              "    495,\n",
              "    11,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2762568445488958,\n",
              "   'compression_ratio': 1.5851528384279476,\n",
              "   'no_speech_prob': 0.09661535173654556},\n",
              "  {'id': 102,\n",
              "   'seek': 96740,\n",
              "   'start': 967.4,\n",
              "   'end': 979.4,\n",
              "   'text': ' pero haciendo un análisis rápido tampoco es inentendible, no es que hoy vemos esto todo lo que estamos acá y vamos a entender que eso quiere hacer un get a esta URL y que le quiere pasar esta parámetros,',\n",
              "   'tokens': [50364,\n",
              "    4768,\n",
              "    20509,\n",
              "    517,\n",
              "    44113,\n",
              "    28436,\n",
              "    24893,\n",
              "    36838,\n",
              "    785,\n",
              "    294,\n",
              "    317,\n",
              "    521,\n",
              "    964,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    631,\n",
              "    13775,\n",
              "    1241,\n",
              "    3415,\n",
              "    7433,\n",
              "    5149,\n",
              "    450,\n",
              "    631,\n",
              "    10382,\n",
              "    23496,\n",
              "    288,\n",
              "    5295,\n",
              "    257,\n",
              "    20054,\n",
              "    631,\n",
              "    7287,\n",
              "    23877,\n",
              "    6720,\n",
              "    517,\n",
              "    483,\n",
              "    257,\n",
              "    5283,\n",
              "    12905,\n",
              "    288,\n",
              "    631,\n",
              "    476,\n",
              "    23877,\n",
              "    25344,\n",
              "    5283,\n",
              "    971,\n",
              "    842,\n",
              "    29570,\n",
              "    11,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.36582969600318843,\n",
              "   'compression_ratio': 1.7509293680297398,\n",
              "   'no_speech_prob': 0.25923001766204834},\n",
              "  {'id': 103,\n",
              "   'seek': 96740,\n",
              "   'start': 981.4,\n",
              "   'end': 994.4,\n",
              "   'text': ' y simolas mivas pruebas que veníamos haciendo exactamente el mismo escenario y encontramos que con solo esos cambios que no son menores, si uno ya tiene un proveo de acto que está establecido, que es grande y tiene muchos testes escritos con ricos y ricos most,',\n",
              "   'tokens': [51064,\n",
              "    288,\n",
              "    1034,\n",
              "    14104,\n",
              "    275,\n",
              "    24759,\n",
              "    32820,\n",
              "    16342,\n",
              "    631,\n",
              "    6138,\n",
              "    16275,\n",
              "    20509,\n",
              "    48686,\n",
              "    806,\n",
              "    12461,\n",
              "    4721,\n",
              "    49120,\n",
              "    288,\n",
              "    45049,\n",
              "    631,\n",
              "    416,\n",
              "    6944,\n",
              "    22411,\n",
              "    18751,\n",
              "    2717,\n",
              "    631,\n",
              "    572,\n",
              "    1872,\n",
              "    1706,\n",
              "    2706,\n",
              "    11,\n",
              "    1511,\n",
              "    8526,\n",
              "    2478,\n",
              "    7066,\n",
              "    517,\n",
              "    7081,\n",
              "    78,\n",
              "    368,\n",
              "    605,\n",
              "    78,\n",
              "    631,\n",
              "    3192,\n",
              "    37444,\n",
              "    17994,\n",
              "    11,\n",
              "    631,\n",
              "    785,\n",
              "    8883,\n",
              "    288,\n",
              "    7066,\n",
              "    17061,\n",
              "    1500,\n",
              "    279,\n",
              "    4721,\n",
              "    42887,\n",
              "    416,\n",
              "    367,\n",
              "    9940,\n",
              "    288,\n",
              "    367,\n",
              "    9940,\n",
              "    881,\n",
              "    11,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.36582969600318843,\n",
              "   'compression_ratio': 1.7509293680297398,\n",
              "   'no_speech_prob': 0.25923001766204834},\n",
              "  {'id': 104,\n",
              "   'seek': 99440,\n",
              "   'start': 994.4,\n",
              "   'end': 1006.4,\n",
              "   'text': ' son cambios importantes pero ya teníamos un 30% de adancia y no es poco un 30%, 30% es un montón cuando tienen millones de ricos que se están ejecutando,',\n",
              "   'tokens': [50364,\n",
              "    1872,\n",
              "    18751,\n",
              "    2717,\n",
              "    27963,\n",
              "    4768,\n",
              "    2478,\n",
              "    2064,\n",
              "    16275,\n",
              "    517,\n",
              "    2217,\n",
              "    4,\n",
              "    368,\n",
              "    614,\n",
              "    282,\n",
              "    2755,\n",
              "    288,\n",
              "    572,\n",
              "    785,\n",
              "    10639,\n",
              "    517,\n",
              "    2217,\n",
              "    4,\n",
              "    11,\n",
              "    2217,\n",
              "    4,\n",
              "    785,\n",
              "    517,\n",
              "    45259,\n",
              "    7767,\n",
              "    12536,\n",
              "    22416,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    631,\n",
              "    369,\n",
              "    10368,\n",
              "    39564,\n",
              "    6672,\n",
              "    1806,\n",
              "    11,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27501135932074655,\n",
              "   'compression_ratio': 1.278688524590164,\n",
              "   'no_speech_prob': 0.014059198088943958},\n",
              "  {'id': 105,\n",
              "   'seek': 100640,\n",
              "   'start': 1006.4,\n",
              "   'end': 1024.4,\n",
              "   'text': ' entonces pasamos de mil que le teníamos antes a mil 300, en ese momento ya estamos en canchila, habíamos pasado de un mes, no sé si algo que usan acá o una mala palabra que van a Cualombia,',\n",
              "   'tokens': [50364,\n",
              "    13003,\n",
              "    1736,\n",
              "    2151,\n",
              "    368,\n",
              "    1962,\n",
              "    631,\n",
              "    476,\n",
              "    2064,\n",
              "    16275,\n",
              "    11014,\n",
              "    257,\n",
              "    1962,\n",
              "    6641,\n",
              "    11,\n",
              "    465,\n",
              "    10167,\n",
              "    9333,\n",
              "    2478,\n",
              "    10382,\n",
              "    465,\n",
              "    393,\n",
              "    339,\n",
              "    7371,\n",
              "    11,\n",
              "    3025,\n",
              "    16275,\n",
              "    24794,\n",
              "    368,\n",
              "    517,\n",
              "    3813,\n",
              "    11,\n",
              "    572,\n",
              "    7910,\n",
              "    1511,\n",
              "    8655,\n",
              "    631,\n",
              "    505,\n",
              "    282,\n",
              "    23496,\n",
              "    277,\n",
              "    2002,\n",
              "    37508,\n",
              "    31702,\n",
              "    631,\n",
              "    3161,\n",
              "    257,\n",
              "    383,\n",
              "    901,\n",
              "    3548,\n",
              "    654,\n",
              "    11,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4740503484552557,\n",
              "   'compression_ratio': 1.3785714285714286,\n",
              "   'no_speech_prob': 0.33743757009506226},\n",
              "  {'id': 106,\n",
              "   'seek': 102440,\n",
              "   'start': 1024.4,\n",
              "   'end': 1042.4,\n",
              "   'text': ' si no, no es la de la idea, o sea habíamos trabajado un mes aproximadamente haciendo estas pruebas y estos cambios probándolo en API y ya estamos al doble y un poquito más del doble y que muy bueno, investimos un poquito más, vamos más allá, somos una compañía grande, tenemos muchas apes que escrita en Python, tenemos tiempos para hacer estas cosas,',\n",
              "   'tokens': [50364,\n",
              "    1511,\n",
              "    572,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    635,\n",
              "    368,\n",
              "    635,\n",
              "    1558,\n",
              "    11,\n",
              "    277,\n",
              "    4158,\n",
              "    3025,\n",
              "    16275,\n",
              "    9618,\n",
              "    1573,\n",
              "    517,\n",
              "    3813,\n",
              "    48892,\n",
              "    20509,\n",
              "    13897,\n",
              "    32820,\n",
              "    16342,\n",
              "    288,\n",
              "    12585,\n",
              "    18751,\n",
              "    2717,\n",
              "    1239,\n",
              "    18606,\n",
              "    7902,\n",
              "    465,\n",
              "    9362,\n",
              "    288,\n",
              "    2478,\n",
              "    10382,\n",
              "    419,\n",
              "    360,\n",
              "    638,\n",
              "    288,\n",
              "    517,\n",
              "    28229,\n",
              "    3573,\n",
              "    1103,\n",
              "    360,\n",
              "    638,\n",
              "    288,\n",
              "    631,\n",
              "    5323,\n",
              "    11974,\n",
              "    11,\n",
              "    1963,\n",
              "    8372,\n",
              "    517,\n",
              "    28229,\n",
              "    3573,\n",
              "    11,\n",
              "    5295,\n",
              "    3573,\n",
              "    30642,\n",
              "    11,\n",
              "    25244,\n",
              "    2002,\n",
              "    29953,\n",
              "    2686,\n",
              "    8883,\n",
              "    11,\n",
              "    9914,\n",
              "    16072,\n",
              "    1882,\n",
              "    279,\n",
              "    631,\n",
              "    49865,\n",
              "    2786,\n",
              "    465,\n",
              "    15329,\n",
              "    11,\n",
              "    9914,\n",
              "    7582,\n",
              "    2455,\n",
              "    329,\n",
              "    1690,\n",
              "    6720,\n",
              "    13897,\n",
              "    12218,\n",
              "    11,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.44741769854942065,\n",
              "   'compression_ratio': 1.5884955752212389,\n",
              "   'no_speech_prob': 0.6092045903205872},\n",
              "  {'id': 107,\n",
              "   'seek': 104240,\n",
              "   'start': 1042.4,\n",
              "   'end': 1055.4,\n",
              "   'text': ' entonces bueno juguemos, empezamos a investigar y obviamente ir de Python a C, que es Pycool, está hecho en C, sabíamos que vamos a tener alguna ventaja en tiempo,',\n",
              "   'tokens': [50364,\n",
              "    13003,\n",
              "    11974,\n",
              "    9568,\n",
              "    84,\n",
              "    4485,\n",
              "    11,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    4557,\n",
              "    289,\n",
              "    288,\n",
              "    36325,\n",
              "    3418,\n",
              "    368,\n",
              "    15329,\n",
              "    257,\n",
              "    383,\n",
              "    11,\n",
              "    631,\n",
              "    785,\n",
              "    9953,\n",
              "    66,\n",
              "    1092,\n",
              "    11,\n",
              "    3192,\n",
              "    13064,\n",
              "    465,\n",
              "    383,\n",
              "    11,\n",
              "    5560,\n",
              "    16275,\n",
              "    631,\n",
              "    5295,\n",
              "    257,\n",
              "    11640,\n",
              "    20651,\n",
              "    6931,\n",
              "    12908,\n",
              "    465,\n",
              "    11772,\n",
              "    11,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2881814349781383,\n",
              "   'compression_ratio': 1.609375,\n",
              "   'no_speech_prob': 0.5339102745056152},\n",
              "  {'id': 108,\n",
              "   'seek': 104240,\n",
              "   'start': 1055.4,\n",
              "   'end': 1064.4,\n",
              "   'text': ' ahora teníamos enalizar cuáles son las desventajas de usar Pycool, porque no todo de gratis en la vida, entonces empezamos a investigar Cool,',\n",
              "   'tokens': [51014,\n",
              "    9923,\n",
              "    2064,\n",
              "    16275,\n",
              "    465,\n",
              "    304,\n",
              "    9736,\n",
              "    2702,\n",
              "    842,\n",
              "    904,\n",
              "    1872,\n",
              "    2439,\n",
              "    730,\n",
              "    2475,\n",
              "    1805,\n",
              "    296,\n",
              "    368,\n",
              "    14745,\n",
              "    9953,\n",
              "    66,\n",
              "    1092,\n",
              "    11,\n",
              "    4021,\n",
              "    572,\n",
              "    5149,\n",
              "    368,\n",
              "    10158,\n",
              "    271,\n",
              "    465,\n",
              "    635,\n",
              "    7644,\n",
              "    11,\n",
              "    13003,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    4557,\n",
              "    289,\n",
              "    383,\n",
              "    1092,\n",
              "    11,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2881814349781383,\n",
              "   'compression_ratio': 1.609375,\n",
              "   'no_speech_prob': 0.5339102745056152},\n",
              "  {'id': 109,\n",
              "   'seek': 106440,\n",
              "   'start': 1064.4,\n",
              "   'end': 1080.4,\n",
              "   'text': ' lo primero que vimos en la documentación es que es para usuarios avanzados, para hacer docena de conexiones con currentes, esos fichules sustificados y la documentación está escrito en HTML1.0,',\n",
              "   'tokens': [50364,\n",
              "    450,\n",
              "    21289,\n",
              "    631,\n",
              "    49266,\n",
              "    465,\n",
              "    635,\n",
              "    4166,\n",
              "    3482,\n",
              "    785,\n",
              "    631,\n",
              "    785,\n",
              "    1690,\n",
              "    32247,\n",
              "    9720,\n",
              "    42444,\n",
              "    4181,\n",
              "    11,\n",
              "    1690,\n",
              "    6720,\n",
              "    3211,\n",
              "    4118,\n",
              "    368,\n",
              "    49509,\n",
              "    5411,\n",
              "    416,\n",
              "    1262,\n",
              "    81,\n",
              "    9240,\n",
              "    11,\n",
              "    22411,\n",
              "    283,\n",
              "    480,\n",
              "    3473,\n",
              "    5402,\n",
              "    1089,\n",
              "    4181,\n",
              "    288,\n",
              "    635,\n",
              "    4166,\n",
              "    3482,\n",
              "    3192,\n",
              "    49451,\n",
              "    465,\n",
              "    17995,\n",
              "    16,\n",
              "    13,\n",
              "    15,\n",
              "    11,\n",
              "    51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.34830384027390254,\n",
              "   'compression_ratio': 1.6058091286307055,\n",
              "   'no_speech_prob': 0.32353779673576355},\n",
              "  {'id': 110,\n",
              "   'seek': 106440,\n",
              "   'start': 1080.4,\n",
              "   'end': 1092.4,\n",
              "   'text': ' yo que venía de Rit de Doc, si tuviste estas cosas bonitas y con buscadores en pese a leer esa documentación y dije no, o porque me estoy metiendo acá, pero bueno, nada, tenía el tiempo,',\n",
              "   'tokens': [51164,\n",
              "    5290,\n",
              "    631,\n",
              "    6138,\n",
              "    2686,\n",
              "    368,\n",
              "    497,\n",
              "    270,\n",
              "    368,\n",
              "    16024,\n",
              "    11,\n",
              "    1511,\n",
              "    38177,\n",
              "    8375,\n",
              "    13897,\n",
              "    12218,\n",
              "    4428,\n",
              "    14182,\n",
              "    288,\n",
              "    416,\n",
              "    1255,\n",
              "    66,\n",
              "    11856,\n",
              "    465,\n",
              "    280,\n",
              "    1130,\n",
              "    257,\n",
              "    34172,\n",
              "    11342,\n",
              "    4166,\n",
              "    3482,\n",
              "    288,\n",
              "    39414,\n",
              "    572,\n",
              "    11,\n",
              "    277,\n",
              "    4021,\n",
              "    385,\n",
              "    15796,\n",
              "    1131,\n",
              "    7304,\n",
              "    23496,\n",
              "    11,\n",
              "    4768,\n",
              "    11974,\n",
              "    11,\n",
              "    8096,\n",
              "    11,\n",
              "    23718,\n",
              "    806,\n",
              "    11772,\n",
              "    11,\n",
              "    51764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.34830384027390254,\n",
              "   'compression_ratio': 1.6058091286307055,\n",
              "   'no_speech_prob': 0.32353779673576355},\n",
              "  {'id': 111,\n",
              "   'seek': 109240,\n",
              "   'start': 1092.4,\n",
              "   'end': 1100.4,\n",
              "   'text': ' somos informáticos, nos gusta hacer estas cosas, investe un poquito más, empecé a jugar y dije bueno voy a hacer mi primer get in Pycool.',\n",
              "   'tokens': [50364,\n",
              "    25244,\n",
              "    1356,\n",
              "    7656,\n",
              "    9940,\n",
              "    11,\n",
              "    3269,\n",
              "    20576,\n",
              "    6720,\n",
              "    13897,\n",
              "    12218,\n",
              "    11,\n",
              "    1963,\n",
              "    68,\n",
              "    517,\n",
              "    28229,\n",
              "    3573,\n",
              "    11,\n",
              "    846,\n",
              "    494,\n",
              "    13523,\n",
              "    257,\n",
              "    37692,\n",
              "    288,\n",
              "    39414,\n",
              "    11974,\n",
              "    7552,\n",
              "    257,\n",
              "    6720,\n",
              "    2752,\n",
              "    12595,\n",
              "    483,\n",
              "    294,\n",
              "    9953,\n",
              "    66,\n",
              "    1092,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.37452451147214333,\n",
              "   'compression_ratio': 1.4429824561403508,\n",
              "   'no_speech_prob': 0.04143902286887169},\n",
              "  {'id': 112,\n",
              "   'seek': 109240,\n",
              "   'start': 1100.4,\n",
              "   'end': 1109.4,\n",
              "   'text': ' Esto es copy page de la documentación de Pycool, cual disclaíbero en la web page, está buenísimo, el que habéis anotradición.',\n",
              "   'tokens': [50764,\n",
              "    20880,\n",
              "    785,\n",
              "    5055,\n",
              "    3028,\n",
              "    368,\n",
              "    635,\n",
              "    4166,\n",
              "    3482,\n",
              "    368,\n",
              "    9953,\n",
              "    66,\n",
              "    1092,\n",
              "    11,\n",
              "    10911,\n",
              "    2983,\n",
              "    875,\n",
              "    870,\n",
              "    607,\n",
              "    78,\n",
              "    465,\n",
              "    635,\n",
              "    3670,\n",
              "    3028,\n",
              "    11,\n",
              "    3192,\n",
              "    30037,\n",
              "    49889,\n",
              "    11,\n",
              "    806,\n",
              "    631,\n",
              "    3025,\n",
              "    15064,\n",
              "    364,\n",
              "    310,\n",
              "    6206,\n",
              "    15534,\n",
              "    13,\n",
              "    51214],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.37452451147214333,\n",
              "   'compression_ratio': 1.4429824561403508,\n",
              "   'no_speech_prob': 0.04143902286887169},\n",
              "  {'id': 113,\n",
              "   'seek': 109240,\n",
              "   'start': 1109.4,\n",
              "   'end': 1116.4,\n",
              "   'text': ' Y está muy bien, ¿por qué, ¿quién usted usa Pycool?',\n",
              "   'tokens': [51214,\n",
              "    398,\n",
              "    3192,\n",
              "    5323,\n",
              "    3610,\n",
              "    11,\n",
              "    3841,\n",
              "    2816,\n",
              "    8057,\n",
              "    11,\n",
              "    3841,\n",
              "    358,\n",
              "    5770,\n",
              "    10467,\n",
              "    29909,\n",
              "    9953,\n",
              "    66,\n",
              "    1092,\n",
              "    30,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.37452451147214333,\n",
              "   'compression_ratio': 1.4429824561403508,\n",
              "   'no_speech_prob': 0.04143902286887169},\n",
              "  {'id': 114,\n",
              "   'seek': 111640,\n",
              "   'start': 1116.4,\n",
              "   'end': 1119.4,\n",
              "   'text': ' Un valiente, o relíptr…',\n",
              "   'tokens': [50364,\n",
              "    1156,\n",
              "    1323,\n",
              "    8413,\n",
              "    11,\n",
              "    277,\n",
              "    1039,\n",
              "    870,\n",
              "    662,\n",
              "    81,\n",
              "    1260,\n",
              "    50514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6006224496023995,\n",
              "   'compression_ratio': 1.3724489795918366,\n",
              "   'no_speech_prob': 0.07801148295402527},\n",
              "  {'id': 115,\n",
              "   'seek': 111640,\n",
              "   'start': 1119.4,\n",
              "   'end': 1120.4,\n",
              "   'text': ' O relíptr…',\n",
              "   'tokens': [50514, 422, 1039, 870, 662, 81, 1260, 50564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6006224496023995,\n",
              "   'compression_ratio': 1.3724489795918366,\n",
              "   'no_speech_prob': 0.07801148295402527},\n",
              "  {'id': 116,\n",
              "   'seek': 111640,\n",
              "   'start': 1120.4,\n",
              "   'end': 1122.4,\n",
              "   'text': ' O relíptr… ¿quién usa?',\n",
              "   'tokens': [50564,\n",
              "    422,\n",
              "    1039,\n",
              "    870,\n",
              "    662,\n",
              "    81,\n",
              "    1260,\n",
              "    3841,\n",
              "    358,\n",
              "    5770,\n",
              "    29909,\n",
              "    30,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6006224496023995,\n",
              "   'compression_ratio': 1.3724489795918366,\n",
              "   'no_speech_prob': 0.07801148295402527},\n",
              "  {'id': 117,\n",
              "   'seek': 111640,\n",
              "   'start': 1122.4,\n",
              "   'end': 1125.4,\n",
              "   'text': ' Ahí está, va, vámonos.',\n",
              "   'tokens': [50664,\n",
              "    49924,\n",
              "    3192,\n",
              "    11,\n",
              "    2773,\n",
              "    11,\n",
              "    371,\n",
              "    842,\n",
              "    3317,\n",
              "    329,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6006224496023995,\n",
              "   'compression_ratio': 1.3724489795918366,\n",
              "   'no_speech_prob': 0.07801148295402527},\n",
              "  {'id': 118,\n",
              "   'seek': 111640,\n",
              "   'start': 1125.4,\n",
              "   'end': 1128.4,\n",
              "   'text': ' Tengo que trabajar con los audicios, hablemos en un rato.',\n",
              "   'tokens': [50814,\n",
              "    314,\n",
              "    30362,\n",
              "    631,\n",
              "    30793,\n",
              "    416,\n",
              "    1750,\n",
              "    2379,\n",
              "    26817,\n",
              "    11,\n",
              "    26280,\n",
              "    4485,\n",
              "    465,\n",
              "    517,\n",
              "    367,\n",
              "    2513,\n",
              "    13,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6006224496023995,\n",
              "   'compression_ratio': 1.3724489795918366,\n",
              "   'no_speech_prob': 0.07801148295402527},\n",
              "  {'id': 119,\n",
              "   'seek': 111640,\n",
              "   'start': 1128.4,\n",
              "   'end': 1137.4,\n",
              "   'text': ' Pero sí, acá Pycool está diciendo, sin necesitas docenas de llamadas con currentes y unos confusios sofisticados,',\n",
              "   'tokens': [50964,\n",
              "    9377,\n",
              "    8600,\n",
              "    11,\n",
              "    23496,\n",
              "    9953,\n",
              "    66,\n",
              "    1092,\n",
              "    3192,\n",
              "    42797,\n",
              "    11,\n",
              "    3343,\n",
              "    11909,\n",
              "    14182,\n",
              "    3211,\n",
              "    11581,\n",
              "    368,\n",
              "    16848,\n",
              "    6872,\n",
              "    416,\n",
              "    1262,\n",
              "    81,\n",
              "    9240,\n",
              "    288,\n",
              "    17780,\n",
              "    1497,\n",
              "    301,\n",
              "    2717,\n",
              "    37259,\n",
              "    3142,\n",
              "    4181,\n",
              "    11,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.6006224496023995,\n",
              "   'compression_ratio': 1.3724489795918366,\n",
              "   'no_speech_prob': 0.07801148295402527},\n",
              "  {'id': 120,\n",
              "   'seek': 113740,\n",
              "   'start': 1137.4,\n",
              "   'end': 1143.4,\n",
              "   'text': ' entonces ya está avisando que, también, si lo que único que queréis hacerle un post a la lista de,',\n",
              "   'tokens': [50364,\n",
              "    13003,\n",
              "    2478,\n",
              "    3192,\n",
              "    34588,\n",
              "    1806,\n",
              "    631,\n",
              "    11,\n",
              "    6407,\n",
              "    11,\n",
              "    1511,\n",
              "    450,\n",
              "    631,\n",
              "    26113,\n",
              "    631,\n",
              "    7083,\n",
              "    15064,\n",
              "    6720,\n",
              "    306,\n",
              "    517,\n",
              "    2183,\n",
              "    257,\n",
              "    635,\n",
              "    27764,\n",
              "    368,\n",
              "    11,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.39667745467719684,\n",
              "   'compression_ratio': 1.611336032388664,\n",
              "   'no_speech_prob': 0.162156343460083},\n",
              "  {'id': 121,\n",
              "   'seek': 113740,\n",
              "   'start': 1143.4,\n",
              "   'end': 1150.4,\n",
              "   'text': ' no sé qué pública, no hace falta, pero capaz de una vez que más microsaricios, donde queréis hacer docenas de',\n",
              "   'tokens': [50664,\n",
              "    572,\n",
              "    7910,\n",
              "    8057,\n",
              "    38905,\n",
              "    11,\n",
              "    572,\n",
              "    10032,\n",
              "    22111,\n",
              "    11,\n",
              "    4768,\n",
              "    35453,\n",
              "    368,\n",
              "    2002,\n",
              "    5715,\n",
              "    631,\n",
              "    3573,\n",
              "    15547,\n",
              "    289,\n",
              "    26817,\n",
              "    11,\n",
              "    10488,\n",
              "    7083,\n",
              "    15064,\n",
              "    6720,\n",
              "    3211,\n",
              "    11581,\n",
              "    368,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.39667745467719684,\n",
              "   'compression_ratio': 1.611336032388664,\n",
              "   'no_speech_prob': 0.162156343460083},\n",
              "  {'id': 122,\n",
              "   'seek': 113740,\n",
              "   'start': 1150.4,\n",
              "   'end': 1157.4,\n",
              "   'text': ' concurrentes ricos, si tenés advanced developers que se la banquen, puede llegar a tener sentido.',\n",
              "   'tokens': [51014,\n",
              "    1588,\n",
              "    374,\n",
              "    1753,\n",
              "    279,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    1511,\n",
              "    2064,\n",
              "    2191,\n",
              "    7339,\n",
              "    8849,\n",
              "    631,\n",
              "    369,\n",
              "    635,\n",
              "    5643,\n",
              "    358,\n",
              "    268,\n",
              "    11,\n",
              "    8919,\n",
              "    24892,\n",
              "    257,\n",
              "    11640,\n",
              "    19850,\n",
              "    13,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.39667745467719684,\n",
              "   'compression_ratio': 1.611336032388664,\n",
              "   'no_speech_prob': 0.162156343460083},\n",
              "  {'id': 123,\n",
              "   'seek': 113740,\n",
              "   'start': 1157.4,\n",
              "   'end': 1161.4,\n",
              "   'text': ' Igual vamos a llegar a esa parte, avance de nivel, pero sí, vamos a hacer falta.',\n",
              "   'tokens': [51364,\n",
              "    19271,\n",
              "    901,\n",
              "    5295,\n",
              "    257,\n",
              "    24892,\n",
              "    257,\n",
              "    11342,\n",
              "    6975,\n",
              "    11,\n",
              "    1305,\n",
              "    719,\n",
              "    368,\n",
              "    24423,\n",
              "    11,\n",
              "    4768,\n",
              "    8600,\n",
              "    11,\n",
              "    5295,\n",
              "    257,\n",
              "    6720,\n",
              "    22111,\n",
              "    13,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.39667745467719684,\n",
              "   'compression_ratio': 1.611336032388664,\n",
              "   'no_speech_prob': 0.162156343460083},\n",
              "  {'id': 124,\n",
              "   'seek': 116140,\n",
              "   'start': 1161.4,\n",
              "   'end': 1169.4,\n",
              "   'text': ' Lo primero que vimos cuando hicimos las pruebas es que ya duplicamos lo que habíamos duplicado.',\n",
              "   'tokens': [50364,\n",
              "    6130,\n",
              "    21289,\n",
              "    631,\n",
              "    49266,\n",
              "    7767,\n",
              "    23697,\n",
              "    8372,\n",
              "    2439,\n",
              "    32820,\n",
              "    16342,\n",
              "    785,\n",
              "    631,\n",
              "    2478,\n",
              "    17154,\n",
              "    2151,\n",
              "    450,\n",
              "    631,\n",
              "    3025,\n",
              "    16275,\n",
              "    17154,\n",
              "    1573,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3536915056633227,\n",
              "   'compression_ratio': 1.64,\n",
              "   'no_speech_prob': 0.09778901189565659},\n",
              "  {'id': 125,\n",
              "   'seek': 116140,\n",
              "   'start': 1169.4,\n",
              "   'end': 1173.4,\n",
              "   'text': ' La verdad está, súper contento, eso tenía muchísimas ganas de implementar esto, decirlo a todo el mundo.',\n",
              "   'tokens': [50764,\n",
              "    2369,\n",
              "    13692,\n",
              "    3192,\n",
              "    11,\n",
              "    43282,\n",
              "    2701,\n",
              "    78,\n",
              "    11,\n",
              "    7287,\n",
              "    23718,\n",
              "    29353,\n",
              "    17957,\n",
              "    7574,\n",
              "    296,\n",
              "    368,\n",
              "    4445,\n",
              "    289,\n",
              "    7433,\n",
              "    11,\n",
              "    10235,\n",
              "    752,\n",
              "    257,\n",
              "    5149,\n",
              "    806,\n",
              "    7968,\n",
              "    13,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3536915056633227,\n",
              "   'compression_ratio': 1.64,\n",
              "   'no_speech_prob': 0.09778901189565659},\n",
              "  {'id': 126,\n",
              "   'seek': 116140,\n",
              "   'start': 1173.4,\n",
              "   'end': 1180.4,\n",
              "   'text': ' Por favor, usted, en Pycool, es la que va, me junté con listos, con Javi, un poco analizar el Javi,',\n",
              "   'tokens': [50964,\n",
              "    5269,\n",
              "    2294,\n",
              "    11,\n",
              "    10467,\n",
              "    11,\n",
              "    465,\n",
              "    9953,\n",
              "    66,\n",
              "    1092,\n",
              "    11,\n",
              "    785,\n",
              "    635,\n",
              "    631,\n",
              "    2773,\n",
              "    11,\n",
              "    385,\n",
              "    22739,\n",
              "    526,\n",
              "    416,\n",
              "    1329,\n",
              "    329,\n",
              "    11,\n",
              "    416,\n",
              "    508,\n",
              "    18442,\n",
              "    11,\n",
              "    517,\n",
              "    10639,\n",
              "    2624,\n",
              "    9736,\n",
              "    806,\n",
              "    508,\n",
              "    18442,\n",
              "    11,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3536915056633227,\n",
              "   'compression_ratio': 1.64,\n",
              "   'no_speech_prob': 0.09778901189565659},\n",
              "  {'id': 127,\n",
              "   'seek': 116140,\n",
              "   'start': 1180.4,\n",
              "   'end': 1186.4,\n",
              "   'text': ' es un batuchivo de trabajo con nosotros, analizar esto y empezamos a ver un poco cómo se hace el gays y cómo se usa',\n",
              "   'tokens': [51314,\n",
              "    785,\n",
              "    517,\n",
              "    7362,\n",
              "    625,\n",
              "    6340,\n",
              "    368,\n",
              "    18099,\n",
              "    416,\n",
              "    13863,\n",
              "    11,\n",
              "    2624,\n",
              "    9736,\n",
              "    7433,\n",
              "    288,\n",
              "    18730,\n",
              "    2151,\n",
              "    257,\n",
              "    1306,\n",
              "    517,\n",
              "    10639,\n",
              "    12826,\n",
              "    369,\n",
              "    10032,\n",
              "    806,\n",
              "    290,\n",
              "    3772,\n",
              "    288,\n",
              "    12826,\n",
              "    369,\n",
              "    29909,\n",
              "    51614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3536915056633227,\n",
              "   'compression_ratio': 1.64,\n",
              "   'no_speech_prob': 0.09778901189565659},\n",
              "  {'id': 128,\n",
              "   'seek': 116140,\n",
              "   'start': 1186.4,\n",
              "   'end': 1189.4,\n",
              "   'text': ' y no los convencía mucho.',\n",
              "   'tokens': [51614, 288, 572, 1750, 7158, 66, 2686, 9824, 13, 51764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3536915056633227,\n",
              "   'compression_ratio': 1.64,\n",
              "   'no_speech_prob': 0.09778901189565659},\n",
              "  {'id': 129,\n",
              "   'seek': 118940,\n",
              "   'start': 1190.4,\n",
              "   'end': 1195.4,\n",
              "   'text': ' Esto es importantísimo, el uso de CPU se fue al 0.73%',\n",
              "   'tokens': [50414,\n",
              "    20880,\n",
              "    785,\n",
              "    1021,\n",
              "    49889,\n",
              "    11,\n",
              "    806,\n",
              "    22728,\n",
              "    368,\n",
              "    13199,\n",
              "    369,\n",
              "    9248,\n",
              "    419,\n",
              "    1958,\n",
              "    13,\n",
              "    33396,\n",
              "    4,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35971330087396164,\n",
              "   'compression_ratio': 1.3349282296650717,\n",
              "   'no_speech_prob': 0.010005490854382515},\n",
              "  {'id': 130,\n",
              "   'seek': 118940,\n",
              "   'start': 1195.4,\n",
              "   'end': 1203.4,\n",
              "   'text': ' La gente que está usando mucho Python y en mercado libre hace machine learning cada porcentaje de CPU que le liberamos,',\n",
              "   'tokens': [50664,\n",
              "    2369,\n",
              "    3788,\n",
              "    631,\n",
              "    3192,\n",
              "    29798,\n",
              "    9824,\n",
              "    15329,\n",
              "    288,\n",
              "    465,\n",
              "    24775,\n",
              "    29976,\n",
              "    10032,\n",
              "    3479,\n",
              "    2539,\n",
              "    8411,\n",
              "    1515,\n",
              "    2207,\n",
              "    11153,\n",
              "    368,\n",
              "    13199,\n",
              "    631,\n",
              "    476,\n",
              "    6774,\n",
              "    2151,\n",
              "    11,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35971330087396164,\n",
              "   'compression_ratio': 1.3349282296650717,\n",
              "   'no_speech_prob': 0.010005490854382515},\n",
              "  {'id': 131,\n",
              "   'seek': 118940,\n",
              "   'start': 1203.4,\n",
              "   'end': 1205.4,\n",
              "   'text': ' es jugo para eso.',\n",
              "   'tokens': [51064, 785, 9568, 78, 1690, 7287, 13, 51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35971330087396164,\n",
              "   'compression_ratio': 1.3349282296650717,\n",
              "   'no_speech_prob': 0.010005490854382515},\n",
              "  {'id': 132,\n",
              "   'seek': 118940,\n",
              "   'start': 1205.4,\n",
              "   'end': 1209.4,\n",
              "   'text': ' Tenemos que salir con esto rápido producción, ¿cómo hacemos?',\n",
              "   'tokens': [51164,\n",
              "    44903,\n",
              "    631,\n",
              "    31514,\n",
              "    416,\n",
              "    7433,\n",
              "    24893,\n",
              "    48586,\n",
              "    11,\n",
              "    3841,\n",
              "    46614,\n",
              "    33839,\n",
              "    30,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35971330087396164,\n",
              "   'compression_ratio': 1.3349282296650717,\n",
              "   'no_speech_prob': 0.010005490854382515},\n",
              "  {'id': 133,\n",
              "   'seek': 118940,\n",
              "   'start': 1213.4,\n",
              "   'end': 1215.4,\n",
              "   'text': ' Es un get in Pycool.',\n",
              "   'tokens': [51564, 2313, 517, 483, 294, 9953, 66, 1092, 13, 51664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.35971330087396164,\n",
              "   'compression_ratio': 1.3349282296650717,\n",
              "   'no_speech_prob': 0.010005490854382515},\n",
              "  {'id': 134,\n",
              "   'seek': 121540,\n",
              "   'start': 1216.4,\n",
              "   'end': 1221.4,\n",
              "   'text': ' Se recuerdan, bueno, todo usado, un rico es rico es punto get y ya estás haciendo un get.',\n",
              "   'tokens': [50414,\n",
              "    1100,\n",
              "    39092,\n",
              "    10312,\n",
              "    11,\n",
              "    11974,\n",
              "    11,\n",
              "    5149,\n",
              "    505,\n",
              "    1573,\n",
              "    11,\n",
              "    517,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    14326,\n",
              "    483,\n",
              "    288,\n",
              "    2478,\n",
              "    24389,\n",
              "    20509,\n",
              "    517,\n",
              "    483,\n",
              "    13,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3589710848672049,\n",
              "   'compression_ratio': 1.6348547717842323,\n",
              "   'no_speech_prob': 0.04072445631027222},\n",
              "  {'id': 135,\n",
              "   'seek': 121540,\n",
              "   'start': 1224.4,\n",
              "   'end': 1230.4,\n",
              "   'text': ' Y acá hay tan color al tovard 1, no sé si un color ambia bardo significa lo mismo que significa de Argentina.',\n",
              "   'tokens': [50814,\n",
              "    398,\n",
              "    23496,\n",
              "    4842,\n",
              "    7603,\n",
              "    2017,\n",
              "    419,\n",
              "    281,\n",
              "    11303,\n",
              "    502,\n",
              "    11,\n",
              "    572,\n",
              "    7910,\n",
              "    1511,\n",
              "    517,\n",
              "    2017,\n",
              "    3913,\n",
              "    654,\n",
              "    7685,\n",
              "    78,\n",
              "    19957,\n",
              "    450,\n",
              "    12461,\n",
              "    631,\n",
              "    19957,\n",
              "    368,\n",
              "    18336,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3589710848672049,\n",
              "   'compression_ratio': 1.6348547717842323,\n",
              "   'no_speech_prob': 0.04072445631027222},\n",
              "  {'id': 136,\n",
              "   'seek': 121540,\n",
              "   'start': 1230.4,\n",
              "   'end': 1232.4,\n",
              "   'text': ' Un gran problema, uno.',\n",
              "   'tokens': [51114, 1156, 9370, 12395, 11, 8526, 13, 51214],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3589710848672049,\n",
              "   'compression_ratio': 1.6348547717842323,\n",
              "   'no_speech_prob': 0.04072445631027222},\n",
              "  {'id': 137,\n",
              "   'seek': 121540,\n",
              "   'start': 1232.4,\n",
              "   'end': 1234.4,\n",
              "   'text': ' Un gran problema, uno, un gran problema.',\n",
              "   'tokens': [51214,\n",
              "    1156,\n",
              "    9370,\n",
              "    12395,\n",
              "    11,\n",
              "    8526,\n",
              "    11,\n",
              "    517,\n",
              "    9370,\n",
              "    12395,\n",
              "    13,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3589710848672049,\n",
              "   'compression_ratio': 1.6348547717842323,\n",
              "   'no_speech_prob': 0.04072445631027222},\n",
              "  {'id': 138,\n",
              "   'seek': 121540,\n",
              "   'start': 1234.4,\n",
              "   'end': 1241.4,\n",
              "   'text': ' La forma que uno le tiene que pasar los parámetros, no es un diccionario común, realmente es súper complejo, súper confuso.',\n",
              "   'tokens': [51314,\n",
              "    2369,\n",
              "    8366,\n",
              "    631,\n",
              "    8526,\n",
              "    476,\n",
              "    7066,\n",
              "    631,\n",
              "    25344,\n",
              "    1750,\n",
              "    971,\n",
              "    842,\n",
              "    29570,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    517,\n",
              "    14285,\n",
              "    10015,\n",
              "    4912,\n",
              "    45448,\n",
              "    11,\n",
              "    14446,\n",
              "    785,\n",
              "    43282,\n",
              "    44424,\n",
              "    5134,\n",
              "    11,\n",
              "    43282,\n",
              "    1497,\n",
              "    24431,\n",
              "    13,\n",
              "    51664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3589710848672049,\n",
              "   'compression_ratio': 1.6348547717842323,\n",
              "   'no_speech_prob': 0.04072445631027222},\n",
              "  {'id': 139,\n",
              "   'seek': 124140,\n",
              "   'start': 1242.4,\n",
              "   'end': 1246.4,\n",
              "   'text': ' Yo hace 5 años estoy con Python y venía a esto y decía por qué, por favor, ¿por qué es así?',\n",
              "   'tokens': [50414,\n",
              "    7616,\n",
              "    10032,\n",
              "    1025,\n",
              "    11424,\n",
              "    15796,\n",
              "    416,\n",
              "    15329,\n",
              "    288,\n",
              "    6138,\n",
              "    2686,\n",
              "    257,\n",
              "    7433,\n",
              "    288,\n",
              "    37599,\n",
              "    1515,\n",
              "    8057,\n",
              "    11,\n",
              "    1515,\n",
              "    2294,\n",
              "    11,\n",
              "    3841,\n",
              "    2816,\n",
              "    8057,\n",
              "    785,\n",
              "    8582,\n",
              "    30,\n",
              "    50614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.45572895022994236,\n",
              "   'compression_ratio': 1.596551724137931,\n",
              "   'no_speech_prob': 0.20116296410560608},\n",
              "  {'id': 140,\n",
              "   'seek': 124140,\n",
              "   'start': 1246.4,\n",
              "   'end': 1256.4,\n",
              "   'text': ' Pero bueno, tiene sus ventajas, tiene la ventaja de duplicar la cantidad rico de Google, de USB3, de uso de CPU, tenemos que ver que así.',\n",
              "   'tokens': [50614,\n",
              "    9377,\n",
              "    11974,\n",
              "    11,\n",
              "    7066,\n",
              "    3291,\n",
              "    6931,\n",
              "    1805,\n",
              "    296,\n",
              "    11,\n",
              "    7066,\n",
              "    635,\n",
              "    6931,\n",
              "    12908,\n",
              "    368,\n",
              "    17154,\n",
              "    289,\n",
              "    635,\n",
              "    33757,\n",
              "    367,\n",
              "    2789,\n",
              "    368,\n",
              "    3329,\n",
              "    11,\n",
              "    368,\n",
              "    10109,\n",
              "    18,\n",
              "    11,\n",
              "    368,\n",
              "    22728,\n",
              "    368,\n",
              "    13199,\n",
              "    11,\n",
              "    9914,\n",
              "    631,\n",
              "    1306,\n",
              "    631,\n",
              "    8582,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.45572895022994236,\n",
              "   'compression_ratio': 1.596551724137931,\n",
              "   'no_speech_prob': 0.20116296410560608},\n",
              "  {'id': 141,\n",
              "   'seek': 124140,\n",
              "   'start': 1256.4,\n",
              "   'end': 1263.4,\n",
              "   'text': ' Creo que el post no se lo puse, bueno, el post, un get in Pycool es doblemente lo arduo.',\n",
              "   'tokens': [51114,\n",
              "    40640,\n",
              "    631,\n",
              "    806,\n",
              "    2183,\n",
              "    572,\n",
              "    369,\n",
              "    450,\n",
              "    280,\n",
              "    438,\n",
              "    11,\n",
              "    11974,\n",
              "    11,\n",
              "    806,\n",
              "    2183,\n",
              "    11,\n",
              "    517,\n",
              "    483,\n",
              "    294,\n",
              "    9953,\n",
              "    66,\n",
              "    1092,\n",
              "    785,\n",
              "    360,\n",
              "    638,\n",
              "    4082,\n",
              "    450,\n",
              "    594,\n",
              "    769,\n",
              "    78,\n",
              "    13,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.45572895022994236,\n",
              "   'compression_ratio': 1.596551724137931,\n",
              "   'no_speech_prob': 0.20116296410560608},\n",
              "  {'id': 142,\n",
              "   'seek': 124140,\n",
              "   'start': 1263.4,\n",
              "   'end': 1270.4,\n",
              "   'text': ' Imagínense, te esté a adreso, es como te esté a este oeste de pedazo de código, como reparto este código en 300 o 400 aplicaciones.',\n",
              "   'tokens': [51464,\n",
              "    34223,\n",
              "    10973,\n",
              "    1288,\n",
              "    11,\n",
              "    535,\n",
              "    34584,\n",
              "    257,\n",
              "    614,\n",
              "    495,\n",
              "    78,\n",
              "    11,\n",
              "    785,\n",
              "    2617,\n",
              "    535,\n",
              "    34584,\n",
              "    257,\n",
              "    4065,\n",
              "    277,\n",
              "    8887,\n",
              "    368,\n",
              "    5670,\n",
              "    29722,\n",
              "    368,\n",
              "    44195,\n",
              "    11,\n",
              "    2617,\n",
              "    1085,\n",
              "    15864,\n",
              "    4065,\n",
              "    44195,\n",
              "    465,\n",
              "    6641,\n",
              "    277,\n",
              "    8423,\n",
              "    18221,\n",
              "    9188,\n",
              "    13,\n",
              "    51814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.45572895022994236,\n",
              "   'compression_ratio': 1.596551724137931,\n",
              "   'no_speech_prob': 0.20116296410560608},\n",
              "  {'id': 143,\n",
              "   'seek': 127040,\n",
              "   'start': 1270.4,\n",
              "   'end': 1271.4,\n",
              "   'text': ' Muy difícil.',\n",
              "   'tokens': [50364, 39586, 17258, 13, 50414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3063854265816604,\n",
              "   'compression_ratio': 1.7492537313432837,\n",
              "   'no_speech_prob': 0.010322801768779755},\n",
              "  {'id': 144,\n",
              "   'seek': 127040,\n",
              "   'start': 1271.4,\n",
              "   'end': 1278.4,\n",
              "   'text': ' Te he ganado de cuenta que todos conocen ricos, nosotros también conocíamos ricos, entonces, ¿cuándo tienes que hacer una solución?',\n",
              "   'tokens': [50414,\n",
              "    1989,\n",
              "    415,\n",
              "    7574,\n",
              "    1573,\n",
              "    368,\n",
              "    17868,\n",
              "    631,\n",
              "    6321,\n",
              "    15871,\n",
              "    268,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    13863,\n",
              "    6407,\n",
              "    15871,\n",
              "    16275,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    13003,\n",
              "    11,\n",
              "    3841,\n",
              "    12032,\n",
              "    18606,\n",
              "    78,\n",
              "    20716,\n",
              "    631,\n",
              "    6720,\n",
              "    2002,\n",
              "    24807,\n",
              "    5687,\n",
              "    30,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3063854265816604,\n",
              "   'compression_ratio': 1.7492537313432837,\n",
              "   'no_speech_prob': 0.010322801768779755},\n",
              "  {'id': 145,\n",
              "   'seek': 127040,\n",
              "   'start': 1278.4,\n",
              "   'end': 1285.4,\n",
              "   'text': ' ¿Ustedes ricos? El momento 0, no te lo preguntaste, lo cual es un problema en un contexto productivo, si están haciendo un apoc, si están haciendo un prototipo, si están haciendo una prueba,',\n",
              "   'tokens': [50764,\n",
              "    3841,\n",
              "    52,\n",
              "    30115,\n",
              "    279,\n",
              "    367,\n",
              "    9940,\n",
              "    30,\n",
              "    2699,\n",
              "    9333,\n",
              "    1958,\n",
              "    11,\n",
              "    572,\n",
              "    535,\n",
              "    450,\n",
              "    19860,\n",
              "    9079,\n",
              "    11,\n",
              "    450,\n",
              "    10911,\n",
              "    785,\n",
              "    517,\n",
              "    12395,\n",
              "    465,\n",
              "    517,\n",
              "    47685,\n",
              "    1674,\n",
              "    6340,\n",
              "    11,\n",
              "    1511,\n",
              "    10368,\n",
              "    20509,\n",
              "    517,\n",
              "    1882,\n",
              "    905,\n",
              "    11,\n",
              "    1511,\n",
              "    10368,\n",
              "    20509,\n",
              "    517,\n",
              "    1742,\n",
              "    310,\n",
              "    647,\n",
              "    78,\n",
              "    11,\n",
              "    1511,\n",
              "    10368,\n",
              "    20509,\n",
              "    2002,\n",
              "    48241,\n",
              "    11,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3063854265816604,\n",
              "   'compression_ratio': 1.7492537313432837,\n",
              "   'no_speech_prob': 0.010322801768779755},\n",
              "  {'id': 146,\n",
              "   'seek': 127040,\n",
              "   'start': 1285.4,\n",
              "   'end': 1288.4,\n",
              "   'text': ' hay preguntas que no necesitan trabajarnos.',\n",
              "   'tokens': [51114,\n",
              "    4842,\n",
              "    39722,\n",
              "    631,\n",
              "    572,\n",
              "    11909,\n",
              "    9670,\n",
              "    9618,\n",
              "    24979,\n",
              "    13,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3063854265816604,\n",
              "   'compression_ratio': 1.7492537313432837,\n",
              "   'no_speech_prob': 0.010322801768779755},\n",
              "  {'id': 147,\n",
              "   'seek': 127040,\n",
              "   'start': 1288.4,\n",
              "   'end': 1292.4,\n",
              "   'text': ' Pero cuando vamos a un entorno productivo, sobre todo de escala, tenemos que ser mucho más detallas.',\n",
              "   'tokens': [51264,\n",
              "    9377,\n",
              "    7767,\n",
              "    5295,\n",
              "    257,\n",
              "    517,\n",
              "    948,\n",
              "    21998,\n",
              "    1674,\n",
              "    6340,\n",
              "    11,\n",
              "    5473,\n",
              "    5149,\n",
              "    368,\n",
              "    4721,\n",
              "    5159,\n",
              "    11,\n",
              "    9914,\n",
              "    631,\n",
              "    816,\n",
              "    9824,\n",
              "    3573,\n",
              "    1141,\n",
              "    336,\n",
              "    296,\n",
              "    13,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3063854265816604,\n",
              "   'compression_ratio': 1.7492537313432837,\n",
              "   'no_speech_prob': 0.010322801768779755},\n",
              "  {'id': 148,\n",
              "   'seek': 127040,\n",
              "   'start': 1292.4,\n",
              "   'end': 1297.4,\n",
              "   'text': ' Entonces, haber elegido ricos como librería de comunicación entre procesos, es de auto-tech.',\n",
              "   'tokens': [51464,\n",
              "    15097,\n",
              "    11,\n",
              "    15811,\n",
              "    14459,\n",
              "    2925,\n",
              "    367,\n",
              "    9940,\n",
              "    2617,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    368,\n",
              "    31710,\n",
              "    3482,\n",
              "    3962,\n",
              "    17565,\n",
              "    329,\n",
              "    11,\n",
              "    785,\n",
              "    368,\n",
              "    8399,\n",
              "    12,\n",
              "    25970,\n",
              "    13,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3063854265816604,\n",
              "   'compression_ratio': 1.7492537313432837,\n",
              "   'no_speech_prob': 0.010322801768779755},\n",
              "  {'id': 149,\n",
              "   'seek': 129740,\n",
              "   'start': 1298.4,\n",
              "   'end': 1308.4,\n",
              "   'text': ' Es un riesgo que estamos tomando y que en algún momento nos puede costar y que en algún momento, ese costo, como cualquier deuda, con sus literes, se va a ser más caro.',\n",
              "   'tokens': [50414,\n",
              "    2313,\n",
              "    517,\n",
              "    23932,\n",
              "    1571,\n",
              "    631,\n",
              "    10382,\n",
              "    2916,\n",
              "    1806,\n",
              "    288,\n",
              "    631,\n",
              "    465,\n",
              "    26300,\n",
              "    9333,\n",
              "    3269,\n",
              "    8919,\n",
              "    2063,\n",
              "    289,\n",
              "    288,\n",
              "    631,\n",
              "    465,\n",
              "    26300,\n",
              "    9333,\n",
              "    11,\n",
              "    10167,\n",
              "    2063,\n",
              "    78,\n",
              "    11,\n",
              "    2617,\n",
              "    21004,\n",
              "    368,\n",
              "    11152,\n",
              "    11,\n",
              "    416,\n",
              "    3291,\n",
              "    2733,\n",
              "    279,\n",
              "    11,\n",
              "    369,\n",
              "    2773,\n",
              "    257,\n",
              "    816,\n",
              "    3573,\n",
              "    1032,\n",
              "    78,\n",
              "    13,\n",
              "    50914],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.325334811429365,\n",
              "   'compression_ratio': 1.7478260869565216,\n",
              "   'no_speech_prob': 0.013011210598051548},\n",
              "  {'id': 150,\n",
              "   'seek': 129740,\n",
              "   'start': 1308.4,\n",
              "   'end': 1311.4,\n",
              "   'text': ' Y nosotros no nos dimos cuenta.',\n",
              "   'tokens': [50914, 398, 13863, 572, 3269, 5013, 329, 17868, 13, 51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.325334811429365,\n",
              "   'compression_ratio': 1.7478260869565216,\n",
              "   'no_speech_prob': 0.013011210598051548},\n",
              "  {'id': 151,\n",
              "   'seek': 129740,\n",
              "   'start': 1311.4,\n",
              "   'end': 1316.4,\n",
              "   'text': ' Y nos dimos cuenta cuando nos dimos cuenta que había que implementar esto.',\n",
              "   'tokens': [51064,\n",
              "    398,\n",
              "    3269,\n",
              "    5013,\n",
              "    329,\n",
              "    17868,\n",
              "    7767,\n",
              "    3269,\n",
              "    5013,\n",
              "    329,\n",
              "    17868,\n",
              "    631,\n",
              "    16395,\n",
              "    631,\n",
              "    4445,\n",
              "    289,\n",
              "    7433,\n",
              "    13,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.325334811429365,\n",
              "   'compression_ratio': 1.7478260869565216,\n",
              "   'no_speech_prob': 0.013011210598051548},\n",
              "  {'id': 152,\n",
              "   'seek': 129740,\n",
              "   'start': 1316.4,\n",
              "   'end': 1322.4,\n",
              "   'text': ' Con cada rico es que teníamos en cada una de los hoy por hoy cientos de micros servicios de pliego en Python que tenemos.',\n",
              "   'tokens': [51314,\n",
              "    2656,\n",
              "    8411,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    631,\n",
              "    2064,\n",
              "    16275,\n",
              "    465,\n",
              "    8411,\n",
              "    2002,\n",
              "    368,\n",
              "    1750,\n",
              "    13775,\n",
              "    1515,\n",
              "    13775,\n",
              "    269,\n",
              "    20370,\n",
              "    368,\n",
              "    15547,\n",
              "    42722,\n",
              "    368,\n",
              "    499,\n",
              "    12200,\n",
              "    465,\n",
              "    15329,\n",
              "    631,\n",
              "    9914,\n",
              "    13,\n",
              "    51614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.325334811429365,\n",
              "   'compression_ratio': 1.7478260869565216,\n",
              "   'no_speech_prob': 0.013011210598051548},\n",
              "  {'id': 153,\n",
              "   'seek': 132240,\n",
              "   'start': 1323.4,\n",
              "   'end': 1330.4,\n",
              "   'text': ' Son muchos equipos de trabajo trabajando y si cada una de esos equipos se le digo, esa línea no, repasar las por estas 75 que tenemos acá.',\n",
              "   'tokens': [50414,\n",
              "    5185,\n",
              "    17061,\n",
              "    5037,\n",
              "    329,\n",
              "    368,\n",
              "    18099,\n",
              "    40473,\n",
              "    288,\n",
              "    1511,\n",
              "    8411,\n",
              "    2002,\n",
              "    368,\n",
              "    22411,\n",
              "    5037,\n",
              "    329,\n",
              "    369,\n",
              "    476,\n",
              "    22990,\n",
              "    11,\n",
              "    11342,\n",
              "    37452,\n",
              "    572,\n",
              "    11,\n",
              "    1085,\n",
              "    296,\n",
              "    289,\n",
              "    2439,\n",
              "    1515,\n",
              "    13897,\n",
              "    9562,\n",
              "    631,\n",
              "    9914,\n",
              "    23496,\n",
              "    13,\n",
              "    50764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.42139218304608317,\n",
              "   'compression_ratio': 1.4130434782608696,\n",
              "   'no_speech_prob': 0.019700488075613976},\n",
              "  {'id': 154,\n",
              "   'seek': 132240,\n",
              "   'start': 1331.4,\n",
              "   'end': 1332.4,\n",
              "   'text': ' Y listo.',\n",
              "   'tokens': [50814, 398, 1329, 78, 13, 50864],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.42139218304608317,\n",
              "   'compression_ratio': 1.4130434782608696,\n",
              "   'no_speech_prob': 0.019700488075613976},\n",
              "  {'id': 155,\n",
              "   'seek': 132240,\n",
              "   'start': 1338.4,\n",
              "   'end': 1344.4,\n",
              "   'text': ' Otra cosa que teníamos en Python y que era súper interesante y no logramos hacer con ricos y vos relic tres.',\n",
              "   'tokens': [51164,\n",
              "    12936,\n",
              "    424,\n",
              "    10163,\n",
              "    631,\n",
              "    2064,\n",
              "    16275,\n",
              "    465,\n",
              "    15329,\n",
              "    288,\n",
              "    631,\n",
              "    4249,\n",
              "    43282,\n",
              "    36396,\n",
              "    288,\n",
              "    572,\n",
              "    450,\n",
              "    1342,\n",
              "    329,\n",
              "    6720,\n",
              "    416,\n",
              "    367,\n",
              "    9940,\n",
              "    288,\n",
              "    13845,\n",
              "    1039,\n",
              "    299,\n",
              "    15890,\n",
              "    13,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.42139218304608317,\n",
              "   'compression_ratio': 1.4130434782608696,\n",
              "   'no_speech_prob': 0.019700488075613976},\n",
              "  {'id': 156,\n",
              "   'seek': 134440,\n",
              "   'start': 1345.4,\n",
              "   'end': 1350.4,\n",
              "   'text': ' En un entorno productivo hacer monitoring es súper importante medir.',\n",
              "   'tokens': [50414,\n",
              "    2193,\n",
              "    517,\n",
              "    948,\n",
              "    21998,\n",
              "    1674,\n",
              "    6340,\n",
              "    6720,\n",
              "    11028,\n",
              "    785,\n",
              "    43282,\n",
              "    9416,\n",
              "    1205,\n",
              "    347,\n",
              "    13,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2411210852933217,\n",
              "   'compression_ratio': 1.4825870646766168,\n",
              "   'no_speech_prob': 0.1819392591714859},\n",
              "  {'id': 157,\n",
              "   'seek': 134440,\n",
              "   'start': 1350.4,\n",
              "   'end': 1357.4,\n",
              "   'text': ' Hay que medir todo lo que se pueda. En mercado de libre nos gusta medir mucho y medimos cada cosa que sucede.',\n",
              "   'tokens': [50664,\n",
              "    8721,\n",
              "    631,\n",
              "    1205,\n",
              "    347,\n",
              "    5149,\n",
              "    450,\n",
              "    631,\n",
              "    369,\n",
              "    31907,\n",
              "    13,\n",
              "    2193,\n",
              "    24775,\n",
              "    368,\n",
              "    29976,\n",
              "    3269,\n",
              "    20576,\n",
              "    1205,\n",
              "    347,\n",
              "    9824,\n",
              "    288,\n",
              "    1205,\n",
              "    8372,\n",
              "    8411,\n",
              "    10163,\n",
              "    631,\n",
              "    459,\n",
              "    29815,\n",
              "    13,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2411210852933217,\n",
              "   'compression_ratio': 1.4825870646766168,\n",
              "   'no_speech_prob': 0.1819392591714859},\n",
              "  {'id': 158,\n",
              "   'seek': 134440,\n",
              "   'start': 1357.4,\n",
              "   'end': 1365.4,\n",
              "   'text': ' Por ejemplo, si val de NS, nos queremos medir por cada rico, es que sale cuánto tiempo tardó y en ir y volver al NS.',\n",
              "   'tokens': [51014,\n",
              "    5269,\n",
              "    13358,\n",
              "    11,\n",
              "    1511,\n",
              "    1323,\n",
              "    368,\n",
              "    15943,\n",
              "    11,\n",
              "    3269,\n",
              "    26813,\n",
              "    1205,\n",
              "    347,\n",
              "    1515,\n",
              "    8411,\n",
              "    367,\n",
              "    2789,\n",
              "    11,\n",
              "    785,\n",
              "    631,\n",
              "    8680,\n",
              "    44256,\n",
              "    78,\n",
              "    11772,\n",
              "    21057,\n",
              "    812,\n",
              "    288,\n",
              "    465,\n",
              "    3418,\n",
              "    288,\n",
              "    33998,\n",
              "    419,\n",
              "    15943,\n",
              "    13,\n",
              "    51414],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2411210852933217,\n",
              "   'compression_ratio': 1.4825870646766168,\n",
              "   'no_speech_prob': 0.1819392591714859},\n",
              "  {'id': 159,\n",
              "   'seek': 136540,\n",
              "   'start': 1365.4,\n",
              "   'end': 1369.4,\n",
              "   'text': ' Si hay una conexión cuánto tiempo se tardó en establecer esa conexión.',\n",
              "   'tokens': [50364,\n",
              "    4909,\n",
              "    4842,\n",
              "    2002,\n",
              "    49509,\n",
              "    2560,\n",
              "    44256,\n",
              "    78,\n",
              "    11772,\n",
              "    369,\n",
              "    21057,\n",
              "    812,\n",
              "    465,\n",
              "    37444,\n",
              "    1776,\n",
              "    11342,\n",
              "    49509,\n",
              "    2560,\n",
              "    13,\n",
              "    50564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2591007385253906,\n",
              "   'compression_ratio': 1.7272727272727273,\n",
              "   'no_speech_prob': 0.1537577509880066},\n",
              "  {'id': 160,\n",
              "   'seek': 136540,\n",
              "   'start': 1369.4,\n",
              "   'end': 1376.4,\n",
              "   'text': ' Si el payload cuánto tiempo tardó todos esos detalles en librerías de bajo nivel como parical podíamos obtener las y en el de alto nivel,',\n",
              "   'tokens': [50564,\n",
              "    4909,\n",
              "    806,\n",
              "    30918,\n",
              "    44256,\n",
              "    78,\n",
              "    11772,\n",
              "    21057,\n",
              "    812,\n",
              "    6321,\n",
              "    22411,\n",
              "    1141,\n",
              "    37927,\n",
              "    465,\n",
              "    4939,\n",
              "    260,\n",
              "    10025,\n",
              "    368,\n",
              "    30139,\n",
              "    24423,\n",
              "    2617,\n",
              "    971,\n",
              "    804,\n",
              "    2497,\n",
              "    16275,\n",
              "    28326,\n",
              "    260,\n",
              "    2439,\n",
              "    288,\n",
              "    465,\n",
              "    806,\n",
              "    368,\n",
              "    21275,\n",
              "    24423,\n",
              "    11,\n",
              "    50914],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2591007385253906,\n",
              "   'compression_ratio': 1.7272727272727273,\n",
              "   'no_speech_prob': 0.1537577509880066},\n",
              "  {'id': 161,\n",
              "   'seek': 136540,\n",
              "   'start': 1376.4,\n",
              "   'end': 1380.4,\n",
              "   'text': ' realmente teníamos de entrar a muyificar el código en la librería y era bastante complejo.',\n",
              "   'tokens': [50914,\n",
              "    14446,\n",
              "    2064,\n",
              "    16275,\n",
              "    368,\n",
              "    20913,\n",
              "    257,\n",
              "    5323,\n",
              "    25625,\n",
              "    806,\n",
              "    44195,\n",
              "    465,\n",
              "    635,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    288,\n",
              "    4249,\n",
              "    14651,\n",
              "    44424,\n",
              "    5134,\n",
              "    13,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2591007385253906,\n",
              "   'compression_ratio': 1.7272727272727273,\n",
              "   'no_speech_prob': 0.1537577509880066},\n",
              "  {'id': 162,\n",
              "   'seek': 136540,\n",
              "   'start': 1380.4,\n",
              "   'end': 1391.4,\n",
              "   'text': ' Entonces hay un poco gran y veíamos como la ventaja de poder monitorear muchísimo mejor los micros servicios que te veníamos y era otra cosa a favor que nos decías che tenemos aquí por este camino.',\n",
              "   'tokens': [51114,\n",
              "    15097,\n",
              "    4842,\n",
              "    517,\n",
              "    10639,\n",
              "    9370,\n",
              "    288,\n",
              "    1241,\n",
              "    16275,\n",
              "    2617,\n",
              "    635,\n",
              "    6931,\n",
              "    12908,\n",
              "    368,\n",
              "    8152,\n",
              "    32001,\n",
              "    418,\n",
              "    289,\n",
              "    44722,\n",
              "    11479,\n",
              "    1750,\n",
              "    15547,\n",
              "    42722,\n",
              "    631,\n",
              "    535,\n",
              "    6138,\n",
              "    16275,\n",
              "    288,\n",
              "    4249,\n",
              "    13623,\n",
              "    10163,\n",
              "    257,\n",
              "    2294,\n",
              "    631,\n",
              "    3269,\n",
              "    979,\n",
              "    10025,\n",
              "    947,\n",
              "    9914,\n",
              "    6661,\n",
              "    1515,\n",
              "    4065,\n",
              "    34124,\n",
              "    13,\n",
              "    51664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2591007385253906,\n",
              "   'compression_ratio': 1.7272727272727273,\n",
              "   'no_speech_prob': 0.1537577509880066},\n",
              "  {'id': 163,\n",
              "   'seek': 139540,\n",
              "   'start': 1396.4,\n",
              "   'end': 1398.4,\n",
              "   'text': ' ¿Tío, ¿no?',\n",
              "   'tokens': [50414, 3841, 51, 20492, 11, 3841, 1771, 30, 50514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3996094556955191,\n",
              "   'compression_ratio': 1.5517241379310345,\n",
              "   'no_speech_prob': 0.049525294452905655},\n",
              "  {'id': 164,\n",
              "   'seek': 139540,\n",
              "   'start': 1398.4,\n",
              "   'end': 1406.4,\n",
              "   'text': ' Insay, un poco lo que venimos charlando, lo que venimos contando. Ricos desde alto nivel, está buenísimo para empezar.',\n",
              "   'tokens': [50514,\n",
              "    9442,\n",
              "    320,\n",
              "    11,\n",
              "    517,\n",
              "    10639,\n",
              "    450,\n",
              "    631,\n",
              "    6138,\n",
              "    8372,\n",
              "    1290,\n",
              "    16201,\n",
              "    11,\n",
              "    450,\n",
              "    631,\n",
              "    6138,\n",
              "    8372,\n",
              "    660,\n",
              "    1806,\n",
              "    13,\n",
              "    497,\n",
              "    9940,\n",
              "    10188,\n",
              "    21275,\n",
              "    24423,\n",
              "    11,\n",
              "    3192,\n",
              "    30037,\n",
              "    49889,\n",
              "    1690,\n",
              "    31168,\n",
              "    13,\n",
              "    50914],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3996094556955191,\n",
              "   'compression_ratio': 1.5517241379310345,\n",
              "   'no_speech_prob': 0.049525294452905655},\n",
              "  {'id': 165,\n",
              "   'seek': 139540,\n",
              "   'start': 1406.4,\n",
              "   'end': 1411.4,\n",
              "   'text': ' Está buenísimo si una cedata science y tiene que hacer algunas búsqueda.',\n",
              "   'tokens': [50914,\n",
              "    27304,\n",
              "    30037,\n",
              "    49889,\n",
              "    1511,\n",
              "    2002,\n",
              "    269,\n",
              "    292,\n",
              "    3274,\n",
              "    3497,\n",
              "    288,\n",
              "    7066,\n",
              "    631,\n",
              "    6720,\n",
              "    27316,\n",
              "    272,\n",
              "    10227,\n",
              "    358,\n",
              "    8801,\n",
              "    13,\n",
              "    51164],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3996094556955191,\n",
              "   'compression_ratio': 1.5517241379310345,\n",
              "   'no_speech_prob': 0.049525294452905655},\n",
              "  {'id': 166,\n",
              "   'seek': 139540,\n",
              "   'start': 1411.4,\n",
              "   'end': 1418.4,\n",
              "   'text': ' No quiero un mail que me diga después che, me dijiste paico de buenísimo, mirad, tenía que hacer un rico Google para sacar algo estuve tres días.',\n",
              "   'tokens': [51164,\n",
              "    883,\n",
              "    16811,\n",
              "    517,\n",
              "    10071,\n",
              "    631,\n",
              "    385,\n",
              "    2528,\n",
              "    64,\n",
              "    15283,\n",
              "    947,\n",
              "    11,\n",
              "    385,\n",
              "    47709,\n",
              "    8375,\n",
              "    2502,\n",
              "    2789,\n",
              "    368,\n",
              "    30037,\n",
              "    49889,\n",
              "    11,\n",
              "    3149,\n",
              "    345,\n",
              "    11,\n",
              "    23718,\n",
              "    631,\n",
              "    6720,\n",
              "    517,\n",
              "    41529,\n",
              "    3329,\n",
              "    1690,\n",
              "    43823,\n",
              "    8655,\n",
              "    871,\n",
              "    31564,\n",
              "    15890,\n",
              "    19527,\n",
              "    13,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3996094556955191,\n",
              "   'compression_ratio': 1.5517241379310345,\n",
              "   'no_speech_prob': 0.049525294452905655},\n",
              "  {'id': 167,\n",
              "   'seek': 141840,\n",
              "   'start': 1419.4,\n",
              "   'end': 1427.4,\n",
              "   'text': ' No estamos vendiendo eso. Ricos es un excelente herramienta para utilizarla en el contexto que se tiene que utilizar.',\n",
              "   'tokens': [50414,\n",
              "    883,\n",
              "    10382,\n",
              "    10169,\n",
              "    7304,\n",
              "    7287,\n",
              "    13,\n",
              "    497,\n",
              "    9940,\n",
              "    785,\n",
              "    517,\n",
              "    24015,\n",
              "    1576,\n",
              "    38271,\n",
              "    64,\n",
              "    1690,\n",
              "    24060,\n",
              "    875,\n",
              "    465,\n",
              "    806,\n",
              "    47685,\n",
              "    631,\n",
              "    369,\n",
              "    7066,\n",
              "    631,\n",
              "    24060,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.1512806694786828,\n",
              "   'compression_ratio': 1.7174721189591078,\n",
              "   'no_speech_prob': 0.3069498538970947},\n",
              "  {'id': 168,\n",
              "   'seek': 141840,\n",
              "   'start': 1427.4,\n",
              "   'end': 1436.4,\n",
              "   'text': ' Hay opciones de optimizaciones, hay que leerla, a mí me he dado mucho la atención que la opción de optimización de esto decision en Ricos está en uso avanzado.',\n",
              "   'tokens': [50814,\n",
              "    8721,\n",
              "    999,\n",
              "    23469,\n",
              "    368,\n",
              "    5028,\n",
              "    590,\n",
              "    9188,\n",
              "    11,\n",
              "    4842,\n",
              "    631,\n",
              "    34172,\n",
              "    875,\n",
              "    11,\n",
              "    257,\n",
              "    14692,\n",
              "    385,\n",
              "    415,\n",
              "    29568,\n",
              "    9824,\n",
              "    635,\n",
              "    33488,\n",
              "    631,\n",
              "    635,\n",
              "    999,\n",
              "    5687,\n",
              "    368,\n",
              "    5028,\n",
              "    27603,\n",
              "    368,\n",
              "    7433,\n",
              "    3537,\n",
              "    465,\n",
              "    497,\n",
              "    9940,\n",
              "    3192,\n",
              "    465,\n",
              "    22728,\n",
              "    42444,\n",
              "    1573,\n",
              "    13,\n",
              "    51264],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.1512806694786828,\n",
              "   'compression_ratio': 1.7174721189591078,\n",
              "   'no_speech_prob': 0.3069498538970947},\n",
              "  {'id': 169,\n",
              "   'seek': 141840,\n",
              "   'start': 1436.4,\n",
              "   'end': 1445.4,\n",
              "   'text': ' Personalmente considero que no están avanzados, me parece bastante sencillo poder utilizar un feature como eso, capaz que entender en el fondo que lo que hace puede ser complejo,',\n",
              "   'tokens': [51264,\n",
              "    25317,\n",
              "    4082,\n",
              "    1949,\n",
              "    78,\n",
              "    631,\n",
              "    572,\n",
              "    10368,\n",
              "    42444,\n",
              "    4181,\n",
              "    11,\n",
              "    385,\n",
              "    14120,\n",
              "    14651,\n",
              "    46749,\n",
              "    78,\n",
              "    8152,\n",
              "    24060,\n",
              "    517,\n",
              "    4111,\n",
              "    2617,\n",
              "    7287,\n",
              "    11,\n",
              "    35453,\n",
              "    631,\n",
              "    20054,\n",
              "    465,\n",
              "    806,\n",
              "    38101,\n",
              "    631,\n",
              "    450,\n",
              "    631,\n",
              "    10032,\n",
              "    8919,\n",
              "    816,\n",
              "    44424,\n",
              "    5134,\n",
              "    11,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.1512806694786828,\n",
              "   'compression_ratio': 1.7174721189591078,\n",
              "   'no_speech_prob': 0.3069498538970947},\n",
              "  {'id': 170,\n",
              "   'seek': 144540,\n",
              "   'start': 1446.4,\n",
              "   'end': 1449.4,\n",
              "   'text': ' pero como feature de la librería es algo relativamente básico.',\n",
              "   'tokens': [50414,\n",
              "    4768,\n",
              "    2617,\n",
              "    4111,\n",
              "    368,\n",
              "    635,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    785,\n",
              "    8655,\n",
              "    21960,\n",
              "    3439,\n",
              "    25545,\n",
              "    2789,\n",
              "    13,\n",
              "    50564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3668567921855662,\n",
              "   'compression_ratio': 1.6583333333333334,\n",
              "   'no_speech_prob': 0.030631879344582558},\n",
              "  {'id': 171,\n",
              "   'seek': 144540,\n",
              "   'start': 1449.4,\n",
              "   'end': 1458.4,\n",
              "   'text': ' Como toda optimización, siempre, avoy de early optimization, early optimization, is the root of all evil, dijo algún viejo pop de la informática.',\n",
              "   'tokens': [50564,\n",
              "    11913,\n",
              "    11687,\n",
              "    5028,\n",
              "    27603,\n",
              "    11,\n",
              "    12758,\n",
              "    11,\n",
              "    1305,\n",
              "    939,\n",
              "    368,\n",
              "    2440,\n",
              "    19618,\n",
              "    11,\n",
              "    2440,\n",
              "    19618,\n",
              "    11,\n",
              "    307,\n",
              "    264,\n",
              "    5593,\n",
              "    295,\n",
              "    439,\n",
              "    6724,\n",
              "    11,\n",
              "    27024,\n",
              "    26300,\n",
              "    4941,\n",
              "    5134,\n",
              "    1665,\n",
              "    368,\n",
              "    635,\n",
              "    1356,\n",
              "    23432,\n",
              "    13,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3668567921855662,\n",
              "   'compression_ratio': 1.6583333333333334,\n",
              "   'no_speech_prob': 0.030631879344582558},\n",
              "  {'id': 172,\n",
              "   'seek': 144540,\n",
              "   'start': 1458.4,\n",
              "   'end': 1467.4,\n",
              "   'text': ' Bueno, no acabamos de optimizar la entrada, entonces sí, a camismo estamos viendo que informas de optimizar la manera de hacer ricos, tengo la en cuenta de función de su caso de uso.',\n",
              "   'tokens': [51014,\n",
              "    16046,\n",
              "    11,\n",
              "    572,\n",
              "    13281,\n",
              "    2151,\n",
              "    368,\n",
              "    5028,\n",
              "    9736,\n",
              "    635,\n",
              "    37119,\n",
              "    11,\n",
              "    13003,\n",
              "    8600,\n",
              "    11,\n",
              "    257,\n",
              "    1945,\n",
              "    271,\n",
              "    3280,\n",
              "    10382,\n",
              "    34506,\n",
              "    631,\n",
              "    1356,\n",
              "    296,\n",
              "    368,\n",
              "    5028,\n",
              "    9736,\n",
              "    635,\n",
              "    13913,\n",
              "    368,\n",
              "    6720,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    13989,\n",
              "    635,\n",
              "    465,\n",
              "    17868,\n",
              "    368,\n",
              "    43735,\n",
              "    368,\n",
              "    459,\n",
              "    9666,\n",
              "    368,\n",
              "    22728,\n",
              "    13,\n",
              "    51464],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3668567921855662,\n",
              "   'compression_ratio': 1.6583333333333334,\n",
              "   'no_speech_prob': 0.030631879344582558},\n",
              "  {'id': 173,\n",
              "   'seek': 146740,\n",
              "   'start': 1468.4,\n",
              "   'end': 1478.4,\n",
              "   'text': ' Después, las buenas prácticas en que nierías aplican para todos, las prácticas que conocemos, de no optimizar antes de tiempo, de empezar,',\n",
              "   'tokens': [50414,\n",
              "    40995,\n",
              "    11,\n",
              "    2439,\n",
              "    43852,\n",
              "    27300,\n",
              "    349,\n",
              "    9150,\n",
              "    465,\n",
              "    631,\n",
              "    3867,\n",
              "    260,\n",
              "    10025,\n",
              "    18221,\n",
              "    282,\n",
              "    1690,\n",
              "    6321,\n",
              "    11,\n",
              "    2439,\n",
              "    27300,\n",
              "    349,\n",
              "    9150,\n",
              "    631,\n",
              "    33029,\n",
              "    38173,\n",
              "    11,\n",
              "    368,\n",
              "    572,\n",
              "    5028,\n",
              "    9736,\n",
              "    11014,\n",
              "    368,\n",
              "    11772,\n",
              "    11,\n",
              "    368,\n",
              "    31168,\n",
              "    11,\n",
              "    50914],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28187085057164096,\n",
              "   'compression_ratio': 1.7377049180327868,\n",
              "   'no_speech_prob': 0.0401473231613636},\n",
              "  {'id': 174,\n",
              "   'seek': 146740,\n",
              "   'start': 1478.4,\n",
              "   'end': 1486.4,\n",
              "   'text': ' esto es algo que me lo discuta, a mí me gusta empezar a desarrollar pensando que está todo bien y después pensar en las cosas que pueden fallar,',\n",
              "   'tokens': [50914,\n",
              "    7433,\n",
              "    785,\n",
              "    8655,\n",
              "    631,\n",
              "    385,\n",
              "    450,\n",
              "    2983,\n",
              "    12093,\n",
              "    11,\n",
              "    257,\n",
              "    14692,\n",
              "    385,\n",
              "    20576,\n",
              "    31168,\n",
              "    257,\n",
              "    32501,\n",
              "    289,\n",
              "    34525,\n",
              "    631,\n",
              "    3192,\n",
              "    5149,\n",
              "    3610,\n",
              "    288,\n",
              "    15283,\n",
              "    18321,\n",
              "    465,\n",
              "    2439,\n",
              "    12218,\n",
              "    631,\n",
              "    14714,\n",
              "    2100,\n",
              "    289,\n",
              "    11,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28187085057164096,\n",
              "   'compression_ratio': 1.7377049180327868,\n",
              "   'no_speech_prob': 0.0401473231613636},\n",
              "  {'id': 175,\n",
              "   'seek': 146740,\n",
              "   'start': 1486.4,\n",
              "   'end': 1492.4,\n",
              "   'text': ' creo que una charla hace unos días, de 100 todos los contrarios, a mí me gusta hacer optimista y después ir agregando complejidad.',\n",
              "   'tokens': [51314,\n",
              "    14336,\n",
              "    631,\n",
              "    2002,\n",
              "    1290,\n",
              "    875,\n",
              "    10032,\n",
              "    17780,\n",
              "    19527,\n",
              "    11,\n",
              "    368,\n",
              "    2319,\n",
              "    6321,\n",
              "    1750,\n",
              "    660,\n",
              "    5352,\n",
              "    2717,\n",
              "    11,\n",
              "    257,\n",
              "    14692,\n",
              "    385,\n",
              "    20576,\n",
              "    6720,\n",
              "    5028,\n",
              "    5236,\n",
              "    288,\n",
              "    15283,\n",
              "    3418,\n",
              "    623,\n",
              "    3375,\n",
              "    1806,\n",
              "    44424,\n",
              "    73,\n",
              "    4580,\n",
              "    13,\n",
              "    51614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28187085057164096,\n",
              "   'compression_ratio': 1.7377049180327868,\n",
              "   'no_speech_prob': 0.0401473231613636},\n",
              "  {'id': 176,\n",
              "   'seek': 149240,\n",
              "   'start': 1493.4,\n",
              "   'end': 1498.4,\n",
              "   'text': ' Entonces, esas buenas prácticas que hay que hemos estudiado sirven para los macros y para los micros también, en este caso.',\n",
              "   'tokens': [50414,\n",
              "    15097,\n",
              "    11,\n",
              "    23388,\n",
              "    43852,\n",
              "    27300,\n",
              "    349,\n",
              "    9150,\n",
              "    631,\n",
              "    4842,\n",
              "    631,\n",
              "    15396,\n",
              "    13542,\n",
              "    72,\n",
              "    1573,\n",
              "    4735,\n",
              "    553,\n",
              "    1690,\n",
              "    1750,\n",
              "    7912,\n",
              "    2635,\n",
              "    288,\n",
              "    1690,\n",
              "    1750,\n",
              "    3123,\n",
              "    2635,\n",
              "    6407,\n",
              "    11,\n",
              "    465,\n",
              "    4065,\n",
              "    9666,\n",
              "    13,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27036297626984424,\n",
              "   'compression_ratio': 1.7037037037037037,\n",
              "   'no_speech_prob': 0.040815319865942},\n",
              "  {'id': 177,\n",
              "   'seek': 149240,\n",
              "   'start': 1500.4,\n",
              "   'end': 1512.4,\n",
              "   'text': ' Entonces bueno, les mostramos lo que estamos haciendo, les contamos que encontramos formas de optimizarlo, entonces ahora le queremos contarlo el próximo paso, no el final, sino el próximo paso,',\n",
              "   'tokens': [50764,\n",
              "    15097,\n",
              "    11974,\n",
              "    11,\n",
              "    1512,\n",
              "    881,\n",
              "    30227,\n",
              "    450,\n",
              "    631,\n",
              "    10382,\n",
              "    20509,\n",
              "    11,\n",
              "    1512,\n",
              "    660,\n",
              "    2151,\n",
              "    631,\n",
              "    45049,\n",
              "    33463,\n",
              "    368,\n",
              "    5028,\n",
              "    9736,\n",
              "    752,\n",
              "    11,\n",
              "    13003,\n",
              "    9923,\n",
              "    476,\n",
              "    26813,\n",
              "    27045,\n",
              "    752,\n",
              "    806,\n",
              "    21177,\n",
              "    29212,\n",
              "    11,\n",
              "    572,\n",
              "    806,\n",
              "    2572,\n",
              "    11,\n",
              "    18108,\n",
              "    806,\n",
              "    21177,\n",
              "    29212,\n",
              "    11,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.27036297626984424,\n",
              "   'compression_ratio': 1.7037037037037037,\n",
              "   'no_speech_prob': 0.040815319865942},\n",
              "  {'id': 178,\n",
              "   'seek': 151240,\n",
              "   'start': 1513.4,\n",
              "   'end': 1524.4,\n",
              "   'text': ' que hicimos en Mercado Libre con todo esto o por lo menos en el marco nuestros equipos, primero lo queremos esta filmina de marketing, es un poco para que entienda la cuestión de envergadura y de escala,',\n",
              "   'tokens': [50414,\n",
              "    631,\n",
              "    23697,\n",
              "    8372,\n",
              "    465,\n",
              "    18897,\n",
              "    1573,\n",
              "    15834,\n",
              "    265,\n",
              "    416,\n",
              "    5149,\n",
              "    7433,\n",
              "    277,\n",
              "    1515,\n",
              "    450,\n",
              "    8902,\n",
              "    465,\n",
              "    806,\n",
              "    1849,\n",
              "    1291,\n",
              "    24099,\n",
              "    5037,\n",
              "    329,\n",
              "    11,\n",
              "    21289,\n",
              "    450,\n",
              "    26813,\n",
              "    5283,\n",
              "    1387,\n",
              "    76,\n",
              "    1426,\n",
              "    368,\n",
              "    6370,\n",
              "    11,\n",
              "    785,\n",
              "    517,\n",
              "    10639,\n",
              "    1690,\n",
              "    631,\n",
              "    948,\n",
              "    30498,\n",
              "    635,\n",
              "    50216,\n",
              "    368,\n",
              "    465,\n",
              "    331,\n",
              "    70,\n",
              "    25154,\n",
              "    288,\n",
              "    368,\n",
              "    4721,\n",
              "    5159,\n",
              "    11,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.29550912839557053,\n",
              "   'compression_ratio': 1.7219917012448134,\n",
              "   'no_speech_prob': 0.4910614788532257},\n",
              "  {'id': 179,\n",
              "   'seek': 151240,\n",
              "   'start': 1524.4,\n",
              "   'end': 1536.4,\n",
              "   'text': ' que realmente en nuestro caso, porque tiene sentido hacer lo que hicimos, lo que lo podemos demostrar, en Mercado Libre hay 6 mil busques por segundo, una búsqueda desde el browser dispara un montón de ricos,',\n",
              "   'tokens': [50964,\n",
              "    631,\n",
              "    14446,\n",
              "    465,\n",
              "    14726,\n",
              "    9666,\n",
              "    11,\n",
              "    4021,\n",
              "    7066,\n",
              "    19850,\n",
              "    6720,\n",
              "    450,\n",
              "    631,\n",
              "    23697,\n",
              "    8372,\n",
              "    11,\n",
              "    450,\n",
              "    631,\n",
              "    450,\n",
              "    12234,\n",
              "    41556,\n",
              "    5352,\n",
              "    11,\n",
              "    465,\n",
              "    18897,\n",
              "    1573,\n",
              "    15834,\n",
              "    265,\n",
              "    4842,\n",
              "    1386,\n",
              "    1962,\n",
              "    1255,\n",
              "    7519,\n",
              "    1515,\n",
              "    17954,\n",
              "    11,\n",
              "    2002,\n",
              "    272,\n",
              "    10227,\n",
              "    358,\n",
              "    8801,\n",
              "    10188,\n",
              "    806,\n",
              "    11185,\n",
              "    14548,\n",
              "    64,\n",
              "    517,\n",
              "    45259,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.29550912839557053,\n",
              "   'compression_ratio': 1.7219917012448134,\n",
              "   'no_speech_prob': 0.4910614788532257},\n",
              "  {'id': 180,\n",
              "   'seek': 153640,\n",
              "   'start': 1537.4,\n",
              "   'end': 1549.4,\n",
              "   'text': ' y cada uno de esos ricos adentro nuestro sistema se multiplica, entonces imagínese el volumen de transacciones con los envíos, con las compras, con cada uno de los pagos a través de mercados pagos cada item que se crea cada usuario que entra,',\n",
              "   'tokens': [50414,\n",
              "    288,\n",
              "    8411,\n",
              "    8526,\n",
              "    368,\n",
              "    22411,\n",
              "    367,\n",
              "    9940,\n",
              "    614,\n",
              "    317,\n",
              "    340,\n",
              "    14726,\n",
              "    13245,\n",
              "    369,\n",
              "    12788,\n",
              "    2262,\n",
              "    11,\n",
              "    13003,\n",
              "    2576,\n",
              "    10973,\n",
              "    1130,\n",
              "    806,\n",
              "    1996,\n",
              "    16988,\n",
              "    368,\n",
              "    1145,\n",
              "    8476,\n",
              "    5411,\n",
              "    416,\n",
              "    1750,\n",
              "    2267,\n",
              "    870,\n",
              "    329,\n",
              "    11,\n",
              "    416,\n",
              "    2439,\n",
              "    715,\n",
              "    3906,\n",
              "    11,\n",
              "    416,\n",
              "    8411,\n",
              "    8526,\n",
              "    368,\n",
              "    1750,\n",
              "    11812,\n",
              "    329,\n",
              "    257,\n",
              "    24463,\n",
              "    368,\n",
              "    10811,\n",
              "    4181,\n",
              "    11812,\n",
              "    329,\n",
              "    8411,\n",
              "    3174,\n",
              "    631,\n",
              "    369,\n",
              "    1197,\n",
              "    64,\n",
              "    8411,\n",
              "    32247,\n",
              "    4912,\n",
              "    631,\n",
              "    22284,\n",
              "    11,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.23432114816481067,\n",
              "   'compression_ratio': 1.8646616541353382,\n",
              "   'no_speech_prob': 0.12244658172130585},\n",
              "  {'id': 181,\n",
              "   'seek': 153640,\n",
              "   'start': 1549.4,\n",
              "   'end': 1564.4,\n",
              "   'text': ' son literalmente millones de ricos por segundo, que se multiplica dentro nuestro sistema, probablemente se no sea el caso de uso de todos ustedes, lo cual no significa que les cala, la que esté trabajando, no sea importante considerar esto lo mismo,',\n",
              "   'tokens': [51014,\n",
              "    1872,\n",
              "    20411,\n",
              "    4082,\n",
              "    22416,\n",
              "    368,\n",
              "    367,\n",
              "    9940,\n",
              "    1515,\n",
              "    17954,\n",
              "    11,\n",
              "    631,\n",
              "    369,\n",
              "    12788,\n",
              "    2262,\n",
              "    10856,\n",
              "    14726,\n",
              "    13245,\n",
              "    11,\n",
              "    21759,\n",
              "    4082,\n",
              "    369,\n",
              "    572,\n",
              "    4158,\n",
              "    806,\n",
              "    9666,\n",
              "    368,\n",
              "    22728,\n",
              "    368,\n",
              "    6321,\n",
              "    17110,\n",
              "    11,\n",
              "    450,\n",
              "    10911,\n",
              "    572,\n",
              "    19957,\n",
              "    631,\n",
              "    1512,\n",
              "    2104,\n",
              "    64,\n",
              "    11,\n",
              "    635,\n",
              "    631,\n",
              "    34584,\n",
              "    40473,\n",
              "    11,\n",
              "    572,\n",
              "    4158,\n",
              "    9416,\n",
              "    1949,\n",
              "    289,\n",
              "    7433,\n",
              "    450,\n",
              "    12461,\n",
              "    11,\n",
              "    51764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.23432114816481067,\n",
              "   'compression_ratio': 1.8646616541353382,\n",
              "   'no_speech_prob': 0.12244658172130585},\n",
              "  {'id': 182,\n",
              "   'seek': 156440,\n",
              "   'start': 1564.4,\n",
              "   'end': 1573.4,\n",
              "   'text': ' pero para nosotros que veníamos de la empresa más chica, que en Mercado Libre del Quirio nos encontramos con esta escala y el día de hoy sigue siendo impresionante, porque lo vemos en el día de día,',\n",
              "   'tokens': [50364,\n",
              "    4768,\n",
              "    1690,\n",
              "    13863,\n",
              "    631,\n",
              "    6138,\n",
              "    16275,\n",
              "    368,\n",
              "    635,\n",
              "    22682,\n",
              "    3573,\n",
              "    417,\n",
              "    2262,\n",
              "    11,\n",
              "    631,\n",
              "    465,\n",
              "    18897,\n",
              "    1573,\n",
              "    15834,\n",
              "    265,\n",
              "    1103,\n",
              "    2326,\n",
              "    347,\n",
              "    1004,\n",
              "    3269,\n",
              "    45049,\n",
              "    416,\n",
              "    5283,\n",
              "    4721,\n",
              "    5159,\n",
              "    288,\n",
              "    806,\n",
              "    12271,\n",
              "    368,\n",
              "    13775,\n",
              "    34532,\n",
              "    31423,\n",
              "    35672,\n",
              "    313,\n",
              "    2879,\n",
              "    11,\n",
              "    4021,\n",
              "    450,\n",
              "    20909,\n",
              "    465,\n",
              "    806,\n",
              "    12271,\n",
              "    368,\n",
              "    12271,\n",
              "    11,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2723919020758735,\n",
              "   'compression_ratio': 1.6370656370656371,\n",
              "   'no_speech_prob': 0.024789612740278244},\n",
              "  {'id': 183,\n",
              "   'seek': 156440,\n",
              "   'start': 1573.4,\n",
              "   'end': 1578.4,\n",
              "   'text': ' entonces quéis hicimos con todo esto de sabemos que podemos optimizar la forma de conectar microciarizos en Python,',\n",
              "   'tokens': [50814,\n",
              "    13003,\n",
              "    421,\n",
              "    15064,\n",
              "    23697,\n",
              "    8372,\n",
              "    416,\n",
              "    5149,\n",
              "    7433,\n",
              "    368,\n",
              "    27200,\n",
              "    631,\n",
              "    12234,\n",
              "    5028,\n",
              "    9736,\n",
              "    635,\n",
              "    8366,\n",
              "    368,\n",
              "    30458,\n",
              "    289,\n",
              "    4532,\n",
              "    537,\n",
              "    289,\n",
              "    590,\n",
              "    329,\n",
              "    465,\n",
              "    15329,\n",
              "    11,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2723919020758735,\n",
              "   'compression_ratio': 1.6370656370656371,\n",
              "   'no_speech_prob': 0.024789612740278244},\n",
              "  {'id': 184,\n",
              "   'seek': 156440,\n",
              "   'start': 1579.4,\n",
              "   'end': 1587.4,\n",
              "   'text': ' básicamente hicimos una librería, una rest client, una abstractión de la capa de comunicación HTTP,',\n",
              "   'tokens': [51114,\n",
              "    48282,\n",
              "    23697,\n",
              "    8372,\n",
              "    2002,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    11,\n",
              "    2002,\n",
              "    1472,\n",
              "    6423,\n",
              "    11,\n",
              "    2002,\n",
              "    12649,\n",
              "    2560,\n",
              "    368,\n",
              "    635,\n",
              "    1410,\n",
              "    64,\n",
              "    368,\n",
              "    31710,\n",
              "    3482,\n",
              "    33283,\n",
              "    11,\n",
              "    51514],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2723919020758735,\n",
              "   'compression_ratio': 1.6370656370656371,\n",
              "   'no_speech_prob': 0.024789612740278244},\n",
              "  {'id': 185,\n",
              "   'seek': 158740,\n",
              "   'start': 1587.4,\n",
              "   'end': 1596.4,\n",
              "   'text': ' hay que poder que podriamos haber hecho desde el inicio, lo que pasa es que esa rico es tan fácil, no veíamos la necesidad de hacerlo raper.',\n",
              "   'tokens': [50364,\n",
              "    4842,\n",
              "    631,\n",
              "    8152,\n",
              "    631,\n",
              "    2497,\n",
              "    470,\n",
              "    2151,\n",
              "    15811,\n",
              "    13064,\n",
              "    10188,\n",
              "    806,\n",
              "    294,\n",
              "    18322,\n",
              "    11,\n",
              "    450,\n",
              "    631,\n",
              "    20260,\n",
              "    785,\n",
              "    631,\n",
              "    11342,\n",
              "    367,\n",
              "    2789,\n",
              "    785,\n",
              "    7603,\n",
              "    17474,\n",
              "    11,\n",
              "    572,\n",
              "    1241,\n",
              "    16275,\n",
              "    635,\n",
              "    11909,\n",
              "    4580,\n",
              "    368,\n",
              "    32039,\n",
              "    367,\n",
              "    2332,\n",
              "    13,\n",
              "    50814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.36284956755461517,\n",
              "   'compression_ratio': 1.6351791530944626,\n",
              "   'no_speech_prob': 0.0912386029958725},\n",
              "  {'id': 186,\n",
              "   'seek': 158740,\n",
              "   'start': 1596.4,\n",
              "   'end': 1606.4,\n",
              "   'text': ' Sí, a partir de eso yo recuerdo entre en un proyecto el primer día y dije, bueno, cinco mil ricos, voy a tener dos mil ricos, esto lo hizo una prueba en mi máquina esta bandar,',\n",
              "   'tokens': [50814,\n",
              "    12375,\n",
              "    11,\n",
              "    257,\n",
              "    13906,\n",
              "    368,\n",
              "    7287,\n",
              "    5290,\n",
              "    850,\n",
              "    22412,\n",
              "    3962,\n",
              "    465,\n",
              "    517,\n",
              "    32285,\n",
              "    806,\n",
              "    12595,\n",
              "    12271,\n",
              "    288,\n",
              "    39414,\n",
              "    11,\n",
              "    11974,\n",
              "    11,\n",
              "    21350,\n",
              "    1962,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    7552,\n",
              "    257,\n",
              "    11640,\n",
              "    4491,\n",
              "    1962,\n",
              "    367,\n",
              "    9940,\n",
              "    11,\n",
              "    7433,\n",
              "    450,\n",
              "    28803,\n",
              "    2002,\n",
              "    48241,\n",
              "    465,\n",
              "    2752,\n",
              "    49360,\n",
              "    5283,\n",
              "    4116,\n",
              "    289,\n",
              "    11,\n",
              "    51314],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.36284956755461517,\n",
              "   'compression_ratio': 1.6351791530944626,\n",
              "   'no_speech_prob': 0.0912386029958725},\n",
              "  {'id': 187,\n",
              "   'seek': 158740,\n",
              "   'start': 1606.4,\n",
              "   'end': 1616.4,\n",
              "   'text': ' después salió producción, tenía 200 mil ricos por segundo, entonces ahí me di cuenta que ahí me va a discutirme el che para, hay que hacer cosas con esto, no es tan senciso,',\n",
              "   'tokens': [51314,\n",
              "    15283,\n",
              "    1845,\n",
              "    7138,\n",
              "    48586,\n",
              "    11,\n",
              "    23718,\n",
              "    2331,\n",
              "    1962,\n",
              "    367,\n",
              "    9940,\n",
              "    1515,\n",
              "    17954,\n",
              "    11,\n",
              "    13003,\n",
              "    12571,\n",
              "    385,\n",
              "    1026,\n",
              "    17868,\n",
              "    631,\n",
              "    12571,\n",
              "    385,\n",
              "    2773,\n",
              "    257,\n",
              "    42085,\n",
              "    347,\n",
              "    1398,\n",
              "    806,\n",
              "    947,\n",
              "    1690,\n",
              "    11,\n",
              "    4842,\n",
              "    631,\n",
              "    6720,\n",
              "    12218,\n",
              "    416,\n",
              "    7433,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    7603,\n",
              "    3151,\n",
              "    66,\n",
              "    19227,\n",
              "    11,\n",
              "    51814],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.36284956755461517,\n",
              "   'compression_ratio': 1.6351791530944626,\n",
              "   'no_speech_prob': 0.0912386029958725},\n",
              "  {'id': 188,\n",
              "   'seek': 161640,\n",
              "   'start': 1617.4,\n",
              "   'end': 1623.4,\n",
              "   'text': ' El happy, en Mercado Libre no funciona, el approach naive de entrada, no funciona nunca,',\n",
              "   'tokens': [50414,\n",
              "    2699,\n",
              "    2055,\n",
              "    11,\n",
              "    465,\n",
              "    18897,\n",
              "    1573,\n",
              "    15834,\n",
              "    265,\n",
              "    572,\n",
              "    26210,\n",
              "    11,\n",
              "    806,\n",
              "    3109,\n",
              "    29052,\n",
              "    368,\n",
              "    37119,\n",
              "    11,\n",
              "    572,\n",
              "    26210,\n",
              "    13768,\n",
              "    11,\n",
              "    50714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3705599286914927,\n",
              "   'compression_ratio': 1.591093117408907,\n",
              "   'no_speech_prob': 0.025919770821928978},\n",
              "  {'id': 189,\n",
              "   'seek': 161640,\n",
              "   'start': 1623.4,\n",
              "   'end': 1631.4,\n",
              "   'text': ' de entrada tienes que pensar entre 10 mil y 50 mil ricos por minuto, el 10KRPB, el 50KRPB, es algo que para nosotros todavía es chico,',\n",
              "   'tokens': [50714,\n",
              "    368,\n",
              "    37119,\n",
              "    20716,\n",
              "    631,\n",
              "    18321,\n",
              "    3962,\n",
              "    1266,\n",
              "    1962,\n",
              "    288,\n",
              "    2625,\n",
              "    1962,\n",
              "    367,\n",
              "    9940,\n",
              "    1515,\n",
              "    923,\n",
              "    8262,\n",
              "    11,\n",
              "    806,\n",
              "    1266,\n",
              "    42,\n",
              "    49,\n",
              "    47,\n",
              "    33,\n",
              "    11,\n",
              "    806,\n",
              "    2625,\n",
              "    42,\n",
              "    49,\n",
              "    47,\n",
              "    33,\n",
              "    11,\n",
              "    785,\n",
              "    8655,\n",
              "    631,\n",
              "    1690,\n",
              "    13863,\n",
              "    28388,\n",
              "    785,\n",
              "    417,\n",
              "    2789,\n",
              "    11,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3705599286914927,\n",
              "   'compression_ratio': 1.591093117408907,\n",
              "   'no_speech_prob': 0.025919770821928978},\n",
              "  {'id': 190,\n",
              "   'seek': 161640,\n",
              "   'start': 1631.4,\n",
              "   'end': 1640.4,\n",
              "   'text': ' cuando queremos probar infraestructuras, por ejemplo, haremos un happy de 600, 700KRPB, son happy que se les está pegando fuerte, pero no son la más grande del sitio,',\n",
              "   'tokens': [51114,\n",
              "    7767,\n",
              "    26813,\n",
              "    1239,\n",
              "    289,\n",
              "    23654,\n",
              "    43056,\n",
              "    12907,\n",
              "    11,\n",
              "    1515,\n",
              "    13358,\n",
              "    11,\n",
              "    324,\n",
              "    28343,\n",
              "    517,\n",
              "    2055,\n",
              "    368,\n",
              "    11849,\n",
              "    11,\n",
              "    15204,\n",
              "    42,\n",
              "    49,\n",
              "    47,\n",
              "    33,\n",
              "    11,\n",
              "    1872,\n",
              "    2055,\n",
              "    631,\n",
              "    369,\n",
              "    1512,\n",
              "    3192,\n",
              "    17199,\n",
              "    1806,\n",
              "    37129,\n",
              "    11,\n",
              "    4768,\n",
              "    572,\n",
              "    1872,\n",
              "    635,\n",
              "    3573,\n",
              "    8883,\n",
              "    1103,\n",
              "    40621,\n",
              "    11,\n",
              "    51564],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3705599286914927,\n",
              "   'compression_ratio': 1.591093117408907,\n",
              "   'no_speech_prob': 0.025919770821928978},\n",
              "  {'id': 191,\n",
              "   'seek': 164040,\n",
              "   'start': 1640.4,\n",
              "   'end': 1646.4,\n",
              "   'text': ' se nos va a meter el escalje grande, cuando estamos en esta máquina, nos metemos al medio de casi todos los flujos importantes del negocio,',\n",
              "   'tokens': [50364,\n",
              "    369,\n",
              "    3269,\n",
              "    2773,\n",
              "    257,\n",
              "    9255,\n",
              "    806,\n",
              "    17871,\n",
              "    2884,\n",
              "    8883,\n",
              "    11,\n",
              "    7767,\n",
              "    10382,\n",
              "    465,\n",
              "    5283,\n",
              "    49360,\n",
              "    11,\n",
              "    3269,\n",
              "    1131,\n",
              "    4485,\n",
              "    419,\n",
              "    22123,\n",
              "    368,\n",
              "    22567,\n",
              "    6321,\n",
              "    1750,\n",
              "    932,\n",
              "    4579,\n",
              "    329,\n",
              "    27963,\n",
              "    1103,\n",
              "    26722,\n",
              "    8529,\n",
              "    11,\n",
              "    50664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4007408142089844,\n",
              "   'compression_ratio': 1.6523178807947019,\n",
              "   'no_speech_prob': 0.05179935693740845},\n",
              "  {'id': 192,\n",
              "   'seek': 164040,\n",
              "   'start': 1646.4,\n",
              "   'end': 1655.4,\n",
              "   'text': ' perdiciendo, categorizando, recomendando, entonces por más que hay mucho go dando vuelta en la compañía, pero utilizar estas cosas es mucho jable en el lógica de negocios,',\n",
              "   'tokens': [50664,\n",
              "    12611,\n",
              "    299,\n",
              "    7304,\n",
              "    11,\n",
              "    19250,\n",
              "    590,\n",
              "    1806,\n",
              "    11,\n",
              "    40292,\n",
              "    1806,\n",
              "    11,\n",
              "    13003,\n",
              "    1515,\n",
              "    3573,\n",
              "    631,\n",
              "    4842,\n",
              "    9824,\n",
              "    352,\n",
              "    29854,\n",
              "    41542,\n",
              "    465,\n",
              "    635,\n",
              "    29953,\n",
              "    2686,\n",
              "    11,\n",
              "    4768,\n",
              "    24060,\n",
              "    13897,\n",
              "    12218,\n",
              "    785,\n",
              "    9824,\n",
              "    361,\n",
              "    712,\n",
              "    465,\n",
              "    806,\n",
              "    48475,\n",
              "    2262,\n",
              "    368,\n",
              "    26722,\n",
              "    23132,\n",
              "    11,\n",
              "    51114],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4007408142089844,\n",
              "   'compression_ratio': 1.6523178807947019,\n",
              "   'no_speech_prob': 0.05179935693740845},\n",
              "  {'id': 193,\n",
              "   'seek': 164040,\n",
              "   'start': 1655.4,\n",
              "   'end': 1665.4,\n",
              "   'text': ' Python de repente con una capillaria muy grande, apalancado por el Machine Learning, se ve a ti, entonces lo que hicimos hace poco es esta hora librería para que los desarrolladores',\n",
              "   'tokens': [51114,\n",
              "    15329,\n",
              "    368,\n",
              "    42884,\n",
              "    416,\n",
              "    2002,\n",
              "    1410,\n",
              "    373,\n",
              "    9831,\n",
              "    5323,\n",
              "    8883,\n",
              "    11,\n",
              "    1882,\n",
              "    304,\n",
              "    4463,\n",
              "    1573,\n",
              "    1515,\n",
              "    806,\n",
              "    22155,\n",
              "    15205,\n",
              "    11,\n",
              "    369,\n",
              "    1241,\n",
              "    257,\n",
              "    8757,\n",
              "    11,\n",
              "    13003,\n",
              "    450,\n",
              "    631,\n",
              "    23697,\n",
              "    8372,\n",
              "    10032,\n",
              "    10639,\n",
              "    785,\n",
              "    5283,\n",
              "    15098,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    1690,\n",
              "    631,\n",
              "    1750,\n",
              "    32501,\n",
              "    11856,\n",
              "    51614],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4007408142089844,\n",
              "   'compression_ratio': 1.6523178807947019,\n",
              "   'no_speech_prob': 0.05179935693740845},\n",
              "  {'id': 194,\n",
              "   'seek': 166540,\n",
              "   'start': 1666.4,\n",
              "   'end': 1678.4,\n",
              "   'text': ' ahora instancia en una librería un res client, que esconder todos los detalles de implementación y toda la lógica de negocios relacionada a conectar microservices de la compañía',\n",
              "   'tokens': [50414,\n",
              "    9923,\n",
              "    1058,\n",
              "    22862,\n",
              "    465,\n",
              "    2002,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    517,\n",
              "    725,\n",
              "    6423,\n",
              "    11,\n",
              "    631,\n",
              "    4721,\n",
              "    8548,\n",
              "    6321,\n",
              "    1750,\n",
              "    1141,\n",
              "    37927,\n",
              "    368,\n",
              "    4445,\n",
              "    3482,\n",
              "    288,\n",
              "    11687,\n",
              "    635,\n",
              "    48475,\n",
              "    2262,\n",
              "    368,\n",
              "    26722,\n",
              "    23132,\n",
              "    27189,\n",
              "    1538,\n",
              "    257,\n",
              "    30458,\n",
              "    289,\n",
              "    15547,\n",
              "    47480,\n",
              "    368,\n",
              "    635,\n",
              "    29953,\n",
              "    2686,\n",
              "    51014],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3092795662257982,\n",
              "   'compression_ratio': 1.4973544973544974,\n",
              "   'no_speech_prob': 0.02159976214170456},\n",
              "  {'id': 195,\n",
              "   'seek': 166540,\n",
              "   'start': 1680.4,\n",
              "   'end': 1685.4,\n",
              "   'text': ' y obviamente ya que nos gustaba tanto el interfaz rico, si intentamos hacer algo, realmente parecido',\n",
              "   'tokens': [51114,\n",
              "    288,\n",
              "    36325,\n",
              "    2478,\n",
              "    631,\n",
              "    3269,\n",
              "    9679,\n",
              "    5509,\n",
              "    10331,\n",
              "    806,\n",
              "    14510,\n",
              "    921,\n",
              "    41529,\n",
              "    11,\n",
              "    1511,\n",
              "    8446,\n",
              "    2151,\n",
              "    6720,\n",
              "    8655,\n",
              "    11,\n",
              "    14446,\n",
              "    7448,\n",
              "    17994,\n",
              "    51364],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3092795662257982,\n",
              "   'compression_ratio': 1.4973544973544974,\n",
              "   'no_speech_prob': 0.02159976214170456},\n",
              "  {'id': 196,\n",
              "   'seek': 168540,\n",
              "   'start': 1686.4,\n",
              "   'end': 1699.4,\n",
              "   'text': ' y ahí varios desafíos, toda la comunidad patónica que está trabajando, están muy familiarizadas con rico, entonces no fue solamente hacer una buena interfaz parecida a la de rico, es para esta herramienta,',\n",
              "   'tokens': [50414,\n",
              "    288,\n",
              "    12571,\n",
              "    33665,\n",
              "    34587,\n",
              "    870,\n",
              "    329,\n",
              "    11,\n",
              "    11687,\n",
              "    635,\n",
              "    35695,\n",
              "    1947,\n",
              "    1801,\n",
              "    2262,\n",
              "    631,\n",
              "    3192,\n",
              "    40473,\n",
              "    11,\n",
              "    10368,\n",
              "    5323,\n",
              "    4963,\n",
              "    590,\n",
              "    6872,\n",
              "    416,\n",
              "    41529,\n",
              "    11,\n",
              "    13003,\n",
              "    572,\n",
              "    9248,\n",
              "    27814,\n",
              "    6720,\n",
              "    2002,\n",
              "    25710,\n",
              "    14510,\n",
              "    921,\n",
              "    7448,\n",
              "    37200,\n",
              "    257,\n",
              "    635,\n",
              "    368,\n",
              "    41529,\n",
              "    11,\n",
              "    785,\n",
              "    1690,\n",
              "    5283,\n",
              "    38271,\n",
              "    64,\n",
              "    11,\n",
              "    51064],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2564218975248791,\n",
              "   'compression_ratio': 1.7701149425287357,\n",
              "   'no_speech_prob': 0.17085833847522736},\n",
              "  {'id': 197,\n",
              "   'seek': 168540,\n",
              "   'start': 1699.4,\n",
              "   'end': 1711.4,\n",
              "   'text': ' sino que después nos encontramos que todas las herramientas que hay alrededor de rico es como rico es mo, para testiarla nos dejaban de servir, entonces también tuvimos que desarrollar herramientas para testiar nuestro res client que sean parecidas,',\n",
              "   'tokens': [51064,\n",
              "    18108,\n",
              "    631,\n",
              "    15283,\n",
              "    3269,\n",
              "    45049,\n",
              "    631,\n",
              "    10906,\n",
              "    2439,\n",
              "    38271,\n",
              "    296,\n",
              "    631,\n",
              "    4842,\n",
              "    43663,\n",
              "    368,\n",
              "    41529,\n",
              "    785,\n",
              "    2617,\n",
              "    41529,\n",
              "    785,\n",
              "    705,\n",
              "    11,\n",
              "    1690,\n",
              "    1500,\n",
              "    9448,\n",
              "    875,\n",
              "    3269,\n",
              "    21259,\n",
              "    18165,\n",
              "    368,\n",
              "    29463,\n",
              "    11,\n",
              "    13003,\n",
              "    6407,\n",
              "    38177,\n",
              "    8372,\n",
              "    631,\n",
              "    32501,\n",
              "    289,\n",
              "    38271,\n",
              "    296,\n",
              "    1690,\n",
              "    1500,\n",
              "    9448,\n",
              "    14726,\n",
              "    725,\n",
              "    6423,\n",
              "    631,\n",
              "    37670,\n",
              "    7448,\n",
              "    66,\n",
              "    11382,\n",
              "    11,\n",
              "    51664],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.2564218975248791,\n",
              "   'compression_ratio': 1.7701149425287357,\n",
              "   'no_speech_prob': 0.17085833847522736},\n",
              "  {'id': 198,\n",
              "   'seek': 171140,\n",
              "   'start': 1711.4,\n",
              "   'end': 1723.4,\n",
              "   'text': ' porque la comunidad estaba acostumbrada, no fue trivial de sentarse una, dos semanas y grabiéral algo, sino que realmente hubo que sentarse, hacer ni que ni hería, diseñarlo, pensarlo, probarlo ir y volver',\n",
              "   'tokens': [50364,\n",
              "    4021,\n",
              "    635,\n",
              "    35695,\n",
              "    17544,\n",
              "    44126,\n",
              "    449,\n",
              "    1443,\n",
              "    1538,\n",
              "    11,\n",
              "    572,\n",
              "    9248,\n",
              "    26703,\n",
              "    368,\n",
              "    2279,\n",
              "    11668,\n",
              "    2002,\n",
              "    11,\n",
              "    4491,\n",
              "    42507,\n",
              "    288,\n",
              "    4444,\n",
              "    72,\n",
              "    4198,\n",
              "    304,\n",
              "    8655,\n",
              "    11,\n",
              "    18108,\n",
              "    631,\n",
              "    14446,\n",
              "    11838,\n",
              "    78,\n",
              "    631,\n",
              "    2279,\n",
              "    11668,\n",
              "    11,\n",
              "    6720,\n",
              "    3867,\n",
              "    631,\n",
              "    3867,\n",
              "    720,\n",
              "    2686,\n",
              "    11,\n",
              "    3814,\n",
              "    2791,\n",
              "    19457,\n",
              "    11,\n",
              "    18321,\n",
              "    752,\n",
              "    11,\n",
              "    1239,\n",
              "    19457,\n",
              "    3418,\n",
              "    288,\n",
              "    33998,\n",
              "    50964],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28413993971688406,\n",
              "   'compression_ratio': 1.649056603773585,\n",
              "   'no_speech_prob': 0.13642293214797974},\n",
              "  {'id': 199,\n",
              "   'seek': 171140,\n",
              "   'start': 1723.4,\n",
              "   'end': 1739.4,\n",
              "   'text': ' y algunas cosas interesantes que sucedieron, hoy por una cuestión de que uno no puede aplicar un cambio masivamente en toda la compañía, porque es muy riesgoso, el res client nosotros vamos agregando lo que llamamos en jeans,',\n",
              "   'tokens': [50964,\n",
              "    288,\n",
              "    27316,\n",
              "    12218,\n",
              "    20157,\n",
              "    9327,\n",
              "    631,\n",
              "    41928,\n",
              "    14440,\n",
              "    11,\n",
              "    13775,\n",
              "    1515,\n",
              "    2002,\n",
              "    50216,\n",
              "    368,\n",
              "    631,\n",
              "    8526,\n",
              "    572,\n",
              "    8919,\n",
              "    18221,\n",
              "    289,\n",
              "    517,\n",
              "    28731,\n",
              "    2300,\n",
              "    23957,\n",
              "    465,\n",
              "    11687,\n",
              "    635,\n",
              "    29953,\n",
              "    2686,\n",
              "    11,\n",
              "    4021,\n",
              "    785,\n",
              "    5323,\n",
              "    23932,\n",
              "    70,\n",
              "    9869,\n",
              "    11,\n",
              "    806,\n",
              "    725,\n",
              "    6423,\n",
              "    13863,\n",
              "    5295,\n",
              "    623,\n",
              "    3375,\n",
              "    1806,\n",
              "    450,\n",
              "    631,\n",
              "    16848,\n",
              "    2151,\n",
              "    465,\n",
              "    18880,\n",
              "    11,\n",
              "    51764],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.28413993971688406,\n",
              "   'compression_ratio': 1.649056603773585,\n",
              "   'no_speech_prob': 0.13642293214797974},\n",
              "  {'id': 200,\n",
              "   'seek': 173940,\n",
              "   'start': 1739.4,\n",
              "   'end': 1769.4,\n",
              "   'text': ' que básicamente empezamos con un rico es en el fondo, que estamos seguro que andaba con sesión, despagaramos un relipter y de a poquito fuimos migrando algunas apicas, usan esta implementación y después anpaiculi, simulos mismos fuimos migrando, y fue muy interesante ver como equipos hacían los diploi y decían, mira no sé qué hicimos, no es súper rapidora, nosotros estamos haciendo todo a H, me parece que está funcionando esto, pero esto que se lo cuento como chiste es, es el valor de por',\n",
              "   'tokens': [50364,\n",
              "    631,\n",
              "    48282,\n",
              "    18730,\n",
              "    2151,\n",
              "    416,\n",
              "    517,\n",
              "    41529,\n",
              "    785,\n",
              "    465,\n",
              "    806,\n",
              "    38101,\n",
              "    11,\n",
              "    631,\n",
              "    10382,\n",
              "    31424,\n",
              "    631,\n",
              "    293,\n",
              "    5509,\n",
              "    416,\n",
              "    5385,\n",
              "    2560,\n",
              "    11,\n",
              "    730,\n",
              "    79,\n",
              "    29124,\n",
              "    2151,\n",
              "    517,\n",
              "    1039,\n",
              "    647,\n",
              "    391,\n",
              "    288,\n",
              "    368,\n",
              "    257,\n",
              "    28229,\n",
              "    8536,\n",
              "    8372,\n",
              "    6186,\n",
              "    19845,\n",
              "    27316,\n",
              "    1882,\n",
              "    9150,\n",
              "    11,\n",
              "    505,\n",
              "    282,\n",
              "    5283,\n",
              "    4445,\n",
              "    3482,\n",
              "    288,\n",
              "    15283,\n",
              "    364,\n",
              "    79,\n",
              "    1301,\n",
              "    2444,\n",
              "    72,\n",
              "    11,\n",
              "    1034,\n",
              "    28348,\n",
              "    47458,\n",
              "    8536,\n",
              "    8372,\n",
              "    6186,\n",
              "    19845,\n",
              "    11,\n",
              "    288,\n",
              "    9248,\n",
              "    5323,\n",
              "    36396,\n",
              "    1306,\n",
              "    2617,\n",
              "    5037,\n",
              "    329,\n",
              "    46093,\n",
              "    11084,\n",
              "    1750,\n",
              "    11432,\n",
              "    4869,\n",
              "    288,\n",
              "    979,\n",
              "    11084,\n",
              "    11,\n",
              "    30286,\n",
              "    572,\n",
              "    7910,\n",
              "    8057,\n",
              "    23697,\n",
              "    8372,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    43282,\n",
              "    5099,\n",
              "    327,\n",
              "    3252,\n",
              "    11,\n",
              "    13863,\n",
              "    10382,\n",
              "    20509,\n",
              "    5149,\n",
              "    257,\n",
              "    389,\n",
              "    11,\n",
              "    385,\n",
              "    14120,\n",
              "    631,\n",
              "    3192,\n",
              "    14186,\n",
              "    1806,\n",
              "    7433,\n",
              "    11,\n",
              "    4768,\n",
              "    7433,\n",
              "    631,\n",
              "    369,\n",
              "    450,\n",
              "    2702,\n",
              "    15467,\n",
              "    2617,\n",
              "    417,\n",
              "    8375,\n",
              "    785,\n",
              "    11,\n",
              "    785,\n",
              "    806,\n",
              "    15367,\n",
              "    368,\n",
              "    1515],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.44870123267173767,\n",
              "   'compression_ratio': 1.6822742474916388,\n",
              "   'no_speech_prob': 0.035642027854919434},\n",
              "  {'id': 201,\n",
              "   'seek': 176940,\n",
              "   'start': 1769.4,\n",
              "   'end': 1796.4,\n",
              "   'text': ' poder tener herramientas de la compañía que impacten en toda la compañía con un solo cambio, nosotros hacemos una nueva versión de esta librería y estamos impactando en todos los microservicios que están en Python, que si no lo hubiéramos hecho tendríamos que haber hecho que decía delito que decir che bueno esta línea ahora la cambia en por esta 70, entonces tomar decisión y adicuñar es parte de comunicar microservicio, no es solamente una cuestión de optimizar la performance.',\n",
              "   'tokens': [50364,\n",
              "    8152,\n",
              "    11640,\n",
              "    38271,\n",
              "    296,\n",
              "    368,\n",
              "    635,\n",
              "    29953,\n",
              "    2686,\n",
              "    631,\n",
              "    2712,\n",
              "    268,\n",
              "    465,\n",
              "    11687,\n",
              "    635,\n",
              "    29953,\n",
              "    2686,\n",
              "    416,\n",
              "    517,\n",
              "    6944,\n",
              "    28731,\n",
              "    11,\n",
              "    13863,\n",
              "    33839,\n",
              "    2002,\n",
              "    28963,\n",
              "    47248,\n",
              "    368,\n",
              "    5283,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    288,\n",
              "    10382,\n",
              "    2712,\n",
              "    1806,\n",
              "    465,\n",
              "    6321,\n",
              "    1750,\n",
              "    15547,\n",
              "    1978,\n",
              "    26817,\n",
              "    631,\n",
              "    10368,\n",
              "    465,\n",
              "    15329,\n",
              "    11,\n",
              "    631,\n",
              "    1511,\n",
              "    572,\n",
              "    450,\n",
              "    11838,\n",
              "    72,\n",
              "    4198,\n",
              "    2151,\n",
              "    13064,\n",
              "    3928,\n",
              "    81,\n",
              "    16275,\n",
              "    631,\n",
              "    15811,\n",
              "    13064,\n",
              "    631,\n",
              "    37599,\n",
              "    1103,\n",
              "    3528,\n",
              "    631,\n",
              "    10235,\n",
              "    947,\n",
              "    11974,\n",
              "    5283,\n",
              "    37452,\n",
              "    9923,\n",
              "    635,\n",
              "    18751,\n",
              "    654,\n",
              "    465,\n",
              "    1515,\n",
              "    5283,\n",
              "    5285,\n",
              "    11,\n",
              "    13003,\n",
              "    22048,\n",
              "    18206,\n",
              "    2560,\n",
              "    288,\n",
              "    614,\n",
              "    299,\n",
              "    84,\n",
              "    2791,\n",
              "    289,\n",
              "    785,\n",
              "    6975,\n",
              "    368,\n",
              "    11040,\n",
              "    7953,\n",
              "    15547,\n",
              "    1978,\n",
              "    18322,\n",
              "    11,\n",
              "    572,\n",
              "    785,\n",
              "    27814,\n",
              "    2002,\n",
              "    50216,\n",
              "    368,\n",
              "    5028,\n",
              "    9736,\n",
              "    635,\n",
              "    3389,\n",
              "    13,\n",
              "    51714],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.31082601714552494,\n",
              "   'compression_ratio': 1.71875,\n",
              "   'no_speech_prob': 0.0025101618375629187},\n",
              "  {'id': 202,\n",
              "   'seek': 179640,\n",
              "   'start': 1796.4,\n",
              "   'end': 1797.4,\n",
              "   'text': ' Bueno luego que llevamos con partidos este es un caso de uso propio es parte de lo que lo que nos sirvió tiene sus prois sus contras, porque ahora esta librería le tiene que mantener a alguien, si el sistema de recomendaciones de mercado libre encuentro un vaga o una limitación de esta librería obviamente alguien lo tiene que resolver y ese alguien en este caso somos nosotros, entonces de nuevo depende el caso de uso hay que responsabilizarse por las herramientas que hacemos, como dice Rudy los pros son muchísimos, las contras no tantas como para que nos animamos, lo que tenemos',\n",
              "   'tokens': [50414,\n",
              "    16046,\n",
              "    17222,\n",
              "    631,\n",
              "    27124,\n",
              "    2151,\n",
              "    416,\n",
              "    644,\n",
              "    7895,\n",
              "    4065,\n",
              "    785,\n",
              "    517,\n",
              "    9666,\n",
              "    368,\n",
              "    22728,\n",
              "    40098,\n",
              "    785,\n",
              "    6975,\n",
              "    368,\n",
              "    450,\n",
              "    631,\n",
              "    450,\n",
              "    631,\n",
              "    3269,\n",
              "    4735,\n",
              "    4917,\n",
              "    812,\n",
              "    7066,\n",
              "    3291,\n",
              "    447,\n",
              "    271,\n",
              "    3291,\n",
              "    660,\n",
              "    3906,\n",
              "    11,\n",
              "    4021,\n",
              "    9923,\n",
              "    5283,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    476,\n",
              "    7066,\n",
              "    631,\n",
              "    42759,\n",
              "    257,\n",
              "    25814,\n",
              "    11,\n",
              "    1511,\n",
              "    806,\n",
              "    13245,\n",
              "    368,\n",
              "    40292,\n",
              "    9188,\n",
              "    368,\n",
              "    24775,\n",
              "    29976,\n",
              "    23708,\n",
              "    340,\n",
              "    517,\n",
              "    371,\n",
              "    9286,\n",
              "    277,\n",
              "    2002,\n",
              "    4948,\n",
              "    3482,\n",
              "    368,\n",
              "    5283,\n",
              "    4939,\n",
              "    260,\n",
              "    2686,\n",
              "    36325,\n",
              "    25814,\n",
              "    450,\n",
              "    7066,\n",
              "    631,\n",
              "    34480,\n",
              "    288,\n",
              "    10167,\n",
              "    25814,\n",
              "    465,\n",
              "    4065,\n",
              "    9666,\n",
              "    25244,\n",
              "    13863,\n",
              "    11,\n",
              "    13003,\n",
              "    368,\n",
              "    18591,\n",
              "    47091,\n",
              "    806,\n",
              "    9666,\n",
              "    368,\n",
              "    22728,\n",
              "    4842,\n",
              "    631,\n",
              "    29829,\n",
              "    9736,\n",
              "    405,\n",
              "    1515,\n",
              "    2439,\n",
              "    38271,\n",
              "    296,\n",
              "    631,\n",
              "    33839,\n",
              "    11,\n",
              "    2617,\n",
              "    10313,\n",
              "    38690,\n",
              "    1750,\n",
              "    6267,\n",
              "    1872,\n",
              "    29353,\n",
              "    8372,\n",
              "    11,\n",
              "    2439,\n",
              "    660,\n",
              "    3906,\n",
              "    572,\n",
              "    12095,\n",
              "    296,\n",
              "    2617,\n",
              "    1690,\n",
              "    631,\n",
              "    3269,\n",
              "    2383,\n",
              "    2151,\n",
              "    11,\n",
              "    450,\n",
              "    631,\n",
              "    9914],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.32203064542828186,\n",
              "   'compression_ratio': 1.8495297805642634,\n",
              "   'no_speech_prob': 0.151815727353096},\n",
              "  {'id': 203,\n",
              "   'seek': 182640,\n",
              "   'start': 1826.4,\n",
              "   'end': 1838.0400000000002,\n",
              "   'text': ' el Thermal Marcha, ¡Uchan ausosIO!',\n",
              "   'tokens': [50364,\n",
              "    806,\n",
              "    38957,\n",
              "    304,\n",
              "    6129,\n",
              "    64,\n",
              "    11,\n",
              "    6514,\n",
              "    52,\n",
              "    3484,\n",
              "    3437,\n",
              "    329,\n",
              "    15167,\n",
              "    0,\n",
              "    50946],\n",
              "   'temperature': 1.0,\n",
              "   'avg_logprob': -3.162125587463379,\n",
              "   'compression_ratio': 0.8333333333333334,\n",
              "   'no_speech_prob': 0.0034284349530935287}],\n",
              " 'language': 'es'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por tiempo se transcribieron los textos procesando el diccionario interno que contiene, id, seek, start, end, text"
      ],
      "metadata": {
        "id": "a5Vpg0WSOtBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_transcripts = pd.read_csv(\"/content/PyCon-co audios/all_transcribes.csv\", sep=\"|\")"
      ],
      "metadata": {
        "id": "fA4TNIjgOPfH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_transcripts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ-AiEhNOb4n",
        "outputId": "a6b22f22-d462-4522-9141-172bfac427bf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5873, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_transcripts.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "_sbmc6DLOixO",
        "outputId": "56fb8dc0-6700-4eb0-9b2c-4e94a551e9e0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Lorena Aldana - Using Python to listen to your...   \n",
              "1  Lorena Aldana - Using Python to listen to your...   \n",
              "2  Lorena Aldana - Using Python to listen to your...   \n",
              "3  Lorena Aldana - Using Python to listen to your...   \n",
              "4  Lorena Aldana - Using Python to listen to your...   \n",
              "\n",
              "                                           url  \\\n",
              "0  https://www.youtube.com/watch?v=YrCSME1jT6U   \n",
              "1  https://www.youtube.com/watch?v=YrCSME1jT6U   \n",
              "2  https://www.youtube.com/watch?v=YrCSME1jT6U   \n",
              "3  https://www.youtube.com/watch?v=YrCSME1jT6U   \n",
              "4  https://www.youtube.com/watch?v=YrCSME1jT6U   \n",
              "\n",
              "                                                path  views          author  \\\n",
              "0  PyCon-co audios/audios/Lorena Aldana - Using P...    200  PyCon Colombia   \n",
              "1  PyCon-co audios/audios/Lorena Aldana - Using P...    200  PyCon Colombia   \n",
              "2  PyCon-co audios/audios/Lorena Aldana - Using P...    200  PyCon Colombia   \n",
              "3  PyCon-co audios/audios/Lorena Aldana - Using P...    200  PyCon Colombia   \n",
              "4  PyCon-co audios/audios/Lorena Aldana - Using P...    200  PyCon Colombia   \n",
              "\n",
              "  publish_date keywords                channel_id  position   start     end  \\\n",
              "0   2021-09-09       []  UCjor6U0ZF5zGAYLJJt9gr0A         1    0.00   86.32   \n",
              "1   2021-09-09       []  UCjor6U0ZF5zGAYLJJt9gr0A         2   86.32   92.60   \n",
              "2   2021-09-09       []  UCjor6U0ZF5zGAYLJJt9gr0A         3   92.60   97.40   \n",
              "3   2021-09-09       []  UCjor6U0ZF5zGAYLJJt9gr0A         4   97.40  103.08   \n",
              "4   2021-09-09       []  UCjor6U0ZF5zGAYLJJt9gr0A         5  103.08  106.36   \n",
              "\n",
              "                                                text  \n",
              "0   Música. . Entonces, quisiera comenzar por con...  \n",
              "1   palabra listen, escuchar y acá de pronto si t...  \n",
              "2   se los recomiendo vamos a estar escuchando al...  \n",
              "3   tienen audígonos no se preocupen no hay probl...  \n",
              "4   sería una buena idea, si les, digamos, a la m...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b17522b6-f1d2-4652-af6a-e427f01fe19e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>path</th>\n",
              "      <th>views</th>\n",
              "      <th>author</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>keywords</th>\n",
              "      <th>channel_id</th>\n",
              "      <th>position</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "      <td>PyCon-co audios/audios/Lorena Aldana - Using P...</td>\n",
              "      <td>200</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>86.32</td>\n",
              "      <td>Música. . Entonces, quisiera comenzar por con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "      <td>PyCon-co audios/audios/Lorena Aldana - Using P...</td>\n",
              "      <td>200</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>2</td>\n",
              "      <td>86.32</td>\n",
              "      <td>92.60</td>\n",
              "      <td>palabra listen, escuchar y acá de pronto si t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "      <td>PyCon-co audios/audios/Lorena Aldana - Using P...</td>\n",
              "      <td>200</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>3</td>\n",
              "      <td>92.60</td>\n",
              "      <td>97.40</td>\n",
              "      <td>se los recomiendo vamos a estar escuchando al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "      <td>PyCon-co audios/audios/Lorena Aldana - Using P...</td>\n",
              "      <td>200</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>4</td>\n",
              "      <td>97.40</td>\n",
              "      <td>103.08</td>\n",
              "      <td>tienen audígonos no se preocupen no hay probl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lorena Aldana - Using Python to listen to your...</td>\n",
              "      <td>https://www.youtube.com/watch?v=YrCSME1jT6U</td>\n",
              "      <td>PyCon-co audios/audios/Lorena Aldana - Using P...</td>\n",
              "      <td>200</td>\n",
              "      <td>PyCon Colombia</td>\n",
              "      <td>2021-09-09</td>\n",
              "      <td>[]</td>\n",
              "      <td>UCjor6U0ZF5zGAYLJJt9gr0A</td>\n",
              "      <td>5</td>\n",
              "      <td>103.08</td>\n",
              "      <td>106.36</td>\n",
              "      <td>sería una buena idea, si les, digamos, a la m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b17522b6-f1d2-4652-af6a-e427f01fe19e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b17522b6-f1d2-4652-af6a-e427f01fe19e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b17522b6-f1d2-4652-af6a-e427f01fe19e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para una busqueda lo mejor es combinar los textos para que no se pierda el contexto.\n",
        "\n",
        "**IMPORTANTE: Para busqueda contextual hay que combinar los textos**"
      ],
      "metadata": {
        "id": "_k2zDl1IQBiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = []\n",
        "\n",
        "window = 6\n",
        "stride = 3\n",
        "\n",
        "for i in tqdm(range(0, len(df_transcripts), stride)):\n",
        "  i_end = min(len(df_transcripts)-1, i + window)\n",
        "  if df_transcripts.iloc[i]['title'] != df_transcripts.iloc[i_end]['title']:\n",
        "    continue\n",
        "  text = ' '.join(df_transcripts[i: i_end]['text'])\n",
        "  new_data.append({\n",
        "      \"start\" : df_transcripts.iloc[i][\"start\"],\n",
        "      \"end\" : df_transcripts.iloc[i_end][\"end\"],\n",
        "      \"title\" : df_transcripts.iloc[i][\"title\"],\n",
        "      \"views\" : df_transcripts.iloc[i][\"views\"],\n",
        "      \"publish_date\" : df_transcripts.iloc[i][\"publish_date\"],\n",
        "      \"keywords\" : df_transcripts.iloc[i][\"keywords\"],\n",
        "      \"text\": text,\n",
        "      \"id\": df_transcripts.iloc[i][\"position\"],\n",
        "      \"url\": df_transcripts.iloc[i][\"url\"],\n",
        "  })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzcYKzRrPrK_",
        "outputId": "78f2e92a-3e39-4422-e3bc-d9ba42714a3c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1958/1958 [00:02<00:00, 821.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_overlap = pd.DataFrame(new_data)"
      ],
      "metadata": {
        "id": "-NGOY_CqQV8D"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "YPA8DWu3TxRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch"
      ],
      "metadata": {
        "id": "vH7m9zINR53g"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "e7725046e9c349d0a8ad0c08094c77d0",
            "d2c79311cb8d44f294078ce0a4516468",
            "82ae4c64639644d3bcc13dda73920566",
            "a4ae18eea3074337bd5599a900c80099",
            "b4d7e2925ad442c1a28b7bd8b45af6f0",
            "6971668e781f4714bf0bc8dd9f78ac7c",
            "fa24311c0426492ba3d64b7944466e61",
            "cefd48f8d96e4360b3a81374448c3f0c",
            "75b1be251d1b483eb872cd617a0a1a8f",
            "2665694a2e7e4fecb501b907f6210f74",
            "fb0fe6af8a61419e93d89b9e2dcb5d54",
            "66c94d08bd5447a6bd11c752ce4fa609",
            "3b9f655d55ae460dbb059e06c4d5a4f2",
            "baa0db6980e6413f971aae428ba56003",
            "4f62814e5bbc47c1936e952a54fb0765",
            "ed1453a1b471477aa829bcc9597b56a2",
            "7f40283483fc450292e998650fee3d4b",
            "bf678d576426446a855ee6ebc371b28b",
            "8bd1a18b400a430cb182af219b85989c",
            "6744d3c0309345a684ece2dc321022ea",
            "cd4bcde6c9794284a234be576bbfcdff",
            "5d62bf985d6f4d1090dd4b96d562691b",
            "f6fba38d6d5f4a3db94d6722cec99da4",
            "93648fc402fc47d0a91848e910bc93c9",
            "c305636ef93d4b489aa363238fd9fabf",
            "19403e00193b47de96e4374ee543183f",
            "3284408d329147caa83671f5c65a12c9",
            "eb01333d1e904957ae8c832cd7324cb9",
            "bbda2327904d40cdb5b54122296467ad",
            "7ee8f012e7474a32bdf5fca371bc1b25",
            "fca04c2ff4fb40a68c4dbe802b9167a5",
            "c9a662ef78804baa9e434e489ec8cad2",
            "49e3e2638f8a48d2bf0f4e4533a4daba",
            "81769f55edab4afd862d99a10a316cf8",
            "4920fed905584029b215123ff0adb1c7",
            "62fddd129cab4a04b5bb7ab0e90d1d95",
            "8de9b33a00ab451fbbd09ee704697f05",
            "45e2ad9d2c03477cb9b62c41b59b2f5a",
            "ae006f3ba55b487c97890d511a911cd4",
            "8ad11d49086c4431bbe70d9ce30a4370",
            "c0e92a4b9f47420bbf49ee89f81c22c0",
            "32185cd0a899445b911e50b43d081eb0",
            "6ded271f69704dc281740de57f24b40e",
            "15e8cf0d496c4393bb49961be840f7c2",
            "0b4f13fdd39242a8b1b6e99d0529073f",
            "cd774274bad44619bcf7304c58c7572d",
            "53298433ae434666b4bf75498b7036d0",
            "1d03255e80d54cbaad136f847ba420e2",
            "e139202777a14fb1b902add336366796",
            "3bac459a660b4e75be0b3e7844f41bcc",
            "cbdbe05177e94226b4333262d30a9166",
            "1c1a0beda1034a628ea1bf3743e87b57",
            "10be183ca5de4440886c1a959e41434d",
            "c3bbf326a2ec430284bc159b2722c65d",
            "4709bc17e8e344a8ac6a418deec7995c",
            "9b27c0d1ff464297aaaf90229594b9c3",
            "9dc582ac37f442adaa00f53170b394c6",
            "ebc7f758b079443a94684eecc1d73f5c",
            "bcd2caea17df405fbbee4fdaee98a230",
            "c0411fd8d6e2419fbaf1b69172fae707",
            "9b769dcd13bb4ac3bcdc0a095ff1a835",
            "057d5a2a20094b5cb3bab9fddf0d1873",
            "3d47fc4f4d4446f6ad39817d06d83c46",
            "175a6340e01340549a6c19bd1e86804e",
            "b398541e2a904d409092b586877ed002",
            "ca9730acdf9946db8cb25134a40b8a47",
            "86d3b3d9ab304e1a9356bdd76e1b8a2a",
            "2214cf97cd814d0297abc6776a969843",
            "f2cf06bb0ee7498990b9d71eff4f1b7e",
            "71de75ebcb104d80b07c2028fec2a463",
            "29ff56b1159149238a73d653fa14945a",
            "8b155d498dc24e1b8168672ddeffd11f",
            "934cf236b8a144629b2747989cac93f5",
            "bd2f753824ee413a966ddddd1d087475",
            "e28d993f288c4b7a85c7639504135af3",
            "2401e6276c3f43c9beb2d84fefac5417",
            "34051f9f44a74a76acc485c19ea4d6ac",
            "0415aa9f75ba49c8ac12573c540fa6d8",
            "9ca2f04afdad49a7a7a21049b90f2da3",
            "f1599e3572b24232939082dba77ce9cb",
            "faaefb602ac04d03937aa7119bf4992e",
            "a32389fe8f7a4f07af04e908a66cc2f3",
            "3ee77023f9694d8d844a5490c6f3bbf3",
            "932e9b5af41c4fc28ec4bc81b11b9b1d",
            "95b1e2d0e2e44581821cfba578dea7a7",
            "93b77b703afc49b8bba75e53f29aa8ad",
            "2eaf40df4b0f473eab472c4b9372472e",
            "1273fde65ad94e2696ec415a01416394",
            "aa47f32514044ba396dd29796d5c4605",
            "552c2a7da502454db6ed87cf0f031eaf",
            "752c0d1bd7444a8ca7519b7a933e3152",
            "ef2fc71322b24d52b40d00e2918506a3",
            "2749684b7cf4409ea3047ac8a91b05cf",
            "885241aeb23f45869e3f953cacf3ca07",
            "0d457d6eccf046f68cb424842d381b86",
            "245388a5367e400ea8948e779e8c5f2f",
            "7ffbd6d479a04ec3b0e7e7f5693e478c",
            "b426508b405b4d39ac77fa9ba86d48e1",
            "10ce1af01c554ee1858ae01b61d7df45",
            "a4342b2f5fda4ed9a29ab875e1c62c06",
            "5a30073c099649bd975d6783fd59fb16",
            "f76157b4b99441eba5c177fa4d5b95c0",
            "9aaac1e9727749f2bcc41edb76164311",
            "c9ae7a2048254da6a33f91a4006a0321",
            "7d984075e2984876be970a63161ac7ee",
            "5913edf81336465c8231ff17b105355a",
            "1a06a965c1184052af911597c726d0e3",
            "c7e34946b0c342ebb2985e427b9ee677",
            "237460d18a8d460d81226738061de73f",
            "6b98f3e193d14c2799155c19475d7ab9",
            "0d45a4ae1e784c56ac7804c64a200f29",
            "dc7f6b75f8d0431c8639f86c6d01e152",
            "554708d31e6f490ba091bdfabeeafb61",
            "634fc48bd7904cf78c9b998a7eab131e",
            "eb432f0a06094142a21306598e315052",
            "e66b531fbae84576b84be06c70ff571e",
            "c73e65bdab5b4a7280594c163cb2bd1f",
            "d0db86bd2cb542238efb538b5207f415",
            "51d142d54b4a4435af8c962e1d657b46",
            "84a131b8ee844fa7b5a4ae603df4dc81",
            "9f8a25e0f55a4d539135eae0bad8a9a0",
            "db800c48916d485799c95bfa90e13ab4",
            "06721bfc794e45c8bf3416cbd61286c8",
            "61ffdca4c2df4eaa8ef55fb15c8b2108",
            "fd1137f7d08b4308b0bea399b26ca408",
            "dfc5e0dea0b94451a23fe9e767263d3f",
            "8bddf0fa368346158fd36b96e4182610",
            "3f2611dd97bc4ab89fa3c1240eb29658",
            "6b173363d984468d9ccb7685ab79d997",
            "098e538997884e7281b53149707d6d8a",
            "c38956f078a643fc807c8717b5fd72af",
            "ed341c3731da4b7ca18340be668fb6aa",
            "3145e680dbd740fa9ff678b9dc28e82f",
            "ebe157faf4bb477eb23e06f23f8feaff",
            "9581ae0f99e54bfea5400ad803eb573d",
            "0ddceb407a344702a64d6ea7c80fcbba",
            "6fc7874c081f4ab5afec4bf163722693",
            "0cff70debcc447788d447c10b1a6e0e5",
            "17be188ae9b744b6b33796ef3a05f760",
            "62e20816ff274f909f8a266a0d8eeaee",
            "625d4f1f3c3f4c3d8dff8d8731662b08",
            "b68df0c5d4064e4ebc77fa8423ff4254",
            "4d92e0070218494d817432b929fbcc47",
            "cac90c7cde36411082a5c7de2aa2d364",
            "7d7dccabc5854d8ea037ac77df4590b8",
            "124d0cfd57d648f28c54e60fca0a401d",
            "cfac92a7357a4a5cbe3f6c2630a52177",
            "b616743e58f24b3e999e8d759c6961ed",
            "da57121f37324da2b25e8ade9917c8d8",
            "be68ea7c5b0c46b0be497ca1cf064b11",
            "f9bea44725c14386875ec58707a07425",
            "4b43551aa6ee46a2abbe6b2ab9043858",
            "027ae06d35944ccd9efb69ec011d284e",
            "a19733b1b0e341eaa67a640db48a6a59"
          ]
        },
        "id": "xeI00HLTT90z",
        "outputId": "22ed33b1-7923-4c58-c748-ba24963f23e1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7725046e9c349d0a8ad0c08094c77d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66c94d08bd5447a6bd11c752ce4fa609"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6fba38d6d5f4a3db94d6722cec99da4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81769f55edab4afd862d99a10a316cf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b4f13fdd39242a8b1b6e99d0529073f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b27c0d1ff464297aaaf90229594b9c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86d3b3d9ab304e1a9356bdd76e1b8a2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0415aa9f75ba49c8ac12573c540fa6d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa47f32514044ba396dd29796d5c4605"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4342b2f5fda4ed9a29ab875e1c62c06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d45a4ae1e784c56ac7804c64a200f29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db800c48916d485799c95bfa90e13ab4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3145e680dbd740fa9ff678b9dc28e82f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cac90c7cde36411082a5c7de2aa2d364"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\"Esto es un ejemplo\", \"Este es otro ejemplo\"]\n",
        "embeddings = model.encode (sentences)"
      ],
      "metadata": {
        "id": "6WBrUF0EUIdE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP1ecZJJUYGm",
        "outputId": "0b475d7c-c48a-4e55-8cd7-5fe95626e4f6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = model.encode(df_overlap['text'], batch_size=64)"
      ],
      "metadata": {
        "id": "uO5H_AoXUcGw"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_overlap[\"embeddings\"] = embeddings.tolist()"
      ],
      "metadata": {
        "id": "8bd_D9SEU9e_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_overlap.sample(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "Js2bSNwiVAls",
        "outputId": "d220b273-224c-44d9-c346-1c6d458dab28"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        start      end                                              title  \\\n",
              "1806  1505.22  1545.18  David Delgado Ruiz - Story of an junior engine...   \n",
              "1206  1701.76  1763.96  Navid Shelkhol - FBJE is a framework used at F...   \n",
              "\n",
              "      views publish_date keywords  \\\n",
              "1806    110   2019-05-24       []   \n",
              "1206    152   2018-12-26       []   \n",
              "\n",
              "                                                   text   id  \\\n",
              "1806   create a key and then put that zero, put a on...  343   \n",
              "1206   going to get notified somehow that there must...  254   \n",
              "\n",
              "                                              url  \\\n",
              "1806  https://www.youtube.com/watch?v=c8y2yS_p8wM   \n",
              "1206  https://www.youtube.com/watch?v=5rgZQw0F0w0   \n",
              "\n",
              "                                             embeddings  \n",
              "1806  [-0.05237895995378494, 0.07013235986232758, -0...  \n",
              "1206  [-0.07436706870794296, -0.07518796622753143, -...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aee57ff1-75d8-49ad-9f70-829298e44407\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>title</th>\n",
              "      <th>views</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>keywords</th>\n",
              "      <th>text</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1806</th>\n",
              "      <td>1505.22</td>\n",
              "      <td>1545.18</td>\n",
              "      <td>David Delgado Ruiz - Story of an junior engine...</td>\n",
              "      <td>110</td>\n",
              "      <td>2019-05-24</td>\n",
              "      <td>[]</td>\n",
              "      <td>create a key and then put that zero, put a on...</td>\n",
              "      <td>343</td>\n",
              "      <td>https://www.youtube.com/watch?v=c8y2yS_p8wM</td>\n",
              "      <td>[-0.05237895995378494, 0.07013235986232758, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1206</th>\n",
              "      <td>1701.76</td>\n",
              "      <td>1763.96</td>\n",
              "      <td>Navid Shelkhol - FBJE is a framework used at F...</td>\n",
              "      <td>152</td>\n",
              "      <td>2018-12-26</td>\n",
              "      <td>[]</td>\n",
              "      <td>going to get notified somehow that there must...</td>\n",
              "      <td>254</td>\n",
              "      <td>https://www.youtube.com/watch?v=5rgZQw0F0w0</td>\n",
              "      <td>[-0.07436706870794296, -0.07518796622753143, -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aee57ff1-75d8-49ad-9f70-829298e44407')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aee57ff1-75d8-49ad-9f70-829298e44407 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aee57ff1-75d8-49ad-9f70-829298e44407');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query =  model.encode([\"Que es Machine Learning\"])"
      ],
      "metadata": {
        "id": "C-IZShfuVJM2"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_overlap['similarity'] = df_overlap[\"embeddings\"].apply(lambda x: util.cos_sim(x, query[0]))"
      ],
      "metadata": {
        "id": "aGsB4GHTVZkW"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_overlap.sort_values('similarity', ascending=False).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q7Nmo9DhVr7m",
        "outputId": "59fa67d7-0c40-4dea-8e77-192aef5c12ec"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       start     end                                              title  \\\n",
              "992   788.48  808.16  Sebastián Arango - Enhancing Data Privacy thro...   \n",
              "292    89.04  109.32  Rodolfo Edelmann & Carlos de la Torre - Conect...   \n",
              "1863   61.08  178.00  Rafael Carrascosa - Software engineering for m...   \n",
              "1876  714.40  779.00  Rafael Carrascosa - Software engineering for m...   \n",
              "1864   64.08  205.98  Rafael Carrascosa - Software engineering for m...   \n",
              "1872  335.00  617.00  Rafael Carrascosa - Software engineering for m...   \n",
              "964   326.20  367.00  Sebastián Arango - Enhancing Data Privacy thro...   \n",
              "993   800.20  817.00  Sebastián Arango - Enhancing Data Privacy thro...   \n",
              "1873  397.00  643.52  Rafael Carrascosa - Software engineering for m...   \n",
              "1886  253.56  304.12  Interview Rodolfo Edelmann & Carlos de la Torr...   \n",
              "\n",
              "      views publish_date keywords  \\\n",
              "992     208   2020-03-06       []   \n",
              "292     503   2020-04-20       []   \n",
              "1863    503   2021-08-05       []   \n",
              "1876    503   2021-08-05       []   \n",
              "1864    503   2021-08-05       []   \n",
              "1872    503   2021-08-05       []   \n",
              "964     208   2020-03-06       []   \n",
              "993     208   2020-03-06       []   \n",
              "1873    503   2021-08-05       []   \n",
              "1886    274   2020-04-21       []   \n",
              "\n",
              "                                                   text   id  \\\n",
              "992    posean.  Entonces, ¿qué es realmente el apren...  138   \n",
              "292    Ahora en Mercado Libre estamos, como hizo Rud...    5   \n",
              "1863   El que se llama la.  El que se llama la.  El ...   35   \n",
              "1876   estas y otras, en Mercado Libre tenemos proce...   74   \n",
              "1864   El que se llama la. El que se llama la. El qu...   38   \n",
              "1872   Para planificar y estimar un proyecto que tie...   62   \n",
              "964    haga posible identificar al usuario esté tota...   54   \n",
              "993    nuevo, Machine Learning.  De hecho, utiliza l...  141   \n",
              "1873   El primero es la herramienta de factibilidad ...   65   \n",
              "1886   lo que es el Machine Learning en la organizac...   18   \n",
              "\n",
              "                                              url  \\\n",
              "992   https://www.youtube.com/watch?v=mEPw36JE_8w   \n",
              "292   https://www.youtube.com/watch?v=N3czkxo2JJw   \n",
              "1863  https://www.youtube.com/watch?v=OVe1GzubDP8   \n",
              "1876  https://www.youtube.com/watch?v=OVe1GzubDP8   \n",
              "1864  https://www.youtube.com/watch?v=OVe1GzubDP8   \n",
              "1872  https://www.youtube.com/watch?v=OVe1GzubDP8   \n",
              "964   https://www.youtube.com/watch?v=mEPw36JE_8w   \n",
              "993   https://www.youtube.com/watch?v=mEPw36JE_8w   \n",
              "1873  https://www.youtube.com/watch?v=OVe1GzubDP8   \n",
              "1886  https://www.youtube.com/watch?v=IvKQkp2CYqs   \n",
              "\n",
              "                                             embeddings          similarity  \n",
              "992   [0.017229102551937103, -0.04375387355685234, -...  [[tensor(0.6721)]]  \n",
              "292   [-0.012716985307633877, 0.01819167099893093, -...  [[tensor(0.6704)]]  \n",
              "1863  [-0.05274017155170441, -0.019284287467598915, ...  [[tensor(0.6415)]]  \n",
              "1876  [-0.02382172830402851, 0.037150848656892776, -...  [[tensor(0.6105)]]  \n",
              "1864  [-0.057171739637851715, -0.005716548301279545,...  [[tensor(0.6085)]]  \n",
              "1872  [-0.04295634850859642, 0.01834726333618164, 0....  [[tensor(0.5897)]]  \n",
              "964   [-0.03910747542977333, -0.0779929831624031, -0...  [[tensor(0.5723)]]  \n",
              "993   [0.055914122611284256, -0.0326554998755455, -0...  [[tensor(0.5699)]]  \n",
              "1873  [-0.01800951361656189, 0.038617558777332306, -...  [[tensor(0.5664)]]  \n",
              "1886  [0.04165314510464668, -0.005298386327922344, -...  [[tensor(0.5547)]]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c40f1ec3-a274-478b-91fb-be800c25ccb1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>title</th>\n",
              "      <th>views</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>keywords</th>\n",
              "      <th>text</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>embeddings</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>788.48</td>\n",
              "      <td>808.16</td>\n",
              "      <td>Sebastián Arango - Enhancing Data Privacy thro...</td>\n",
              "      <td>208</td>\n",
              "      <td>2020-03-06</td>\n",
              "      <td>[]</td>\n",
              "      <td>posean.  Entonces, ¿qué es realmente el apren...</td>\n",
              "      <td>138</td>\n",
              "      <td>https://www.youtube.com/watch?v=mEPw36JE_8w</td>\n",
              "      <td>[0.017229102551937103, -0.04375387355685234, -...</td>\n",
              "      <td>[[tensor(0.6721)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>89.04</td>\n",
              "      <td>109.32</td>\n",
              "      <td>Rodolfo Edelmann &amp; Carlos de la Torre - Conect...</td>\n",
              "      <td>503</td>\n",
              "      <td>2020-04-20</td>\n",
              "      <td>[]</td>\n",
              "      <td>Ahora en Mercado Libre estamos, como hizo Rud...</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.youtube.com/watch?v=N3czkxo2JJw</td>\n",
              "      <td>[-0.012716985307633877, 0.01819167099893093, -...</td>\n",
              "      <td>[[tensor(0.6704)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1863</th>\n",
              "      <td>61.08</td>\n",
              "      <td>178.00</td>\n",
              "      <td>Rafael Carrascosa - Software engineering for m...</td>\n",
              "      <td>503</td>\n",
              "      <td>2021-08-05</td>\n",
              "      <td>[]</td>\n",
              "      <td>El que se llama la.  El que se llama la.  El ...</td>\n",
              "      <td>35</td>\n",
              "      <td>https://www.youtube.com/watch?v=OVe1GzubDP8</td>\n",
              "      <td>[-0.05274017155170441, -0.019284287467598915, ...</td>\n",
              "      <td>[[tensor(0.6415)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1876</th>\n",
              "      <td>714.40</td>\n",
              "      <td>779.00</td>\n",
              "      <td>Rafael Carrascosa - Software engineering for m...</td>\n",
              "      <td>503</td>\n",
              "      <td>2021-08-05</td>\n",
              "      <td>[]</td>\n",
              "      <td>estas y otras, en Mercado Libre tenemos proce...</td>\n",
              "      <td>74</td>\n",
              "      <td>https://www.youtube.com/watch?v=OVe1GzubDP8</td>\n",
              "      <td>[-0.02382172830402851, 0.037150848656892776, -...</td>\n",
              "      <td>[[tensor(0.6105)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864</th>\n",
              "      <td>64.08</td>\n",
              "      <td>205.98</td>\n",
              "      <td>Rafael Carrascosa - Software engineering for m...</td>\n",
              "      <td>503</td>\n",
              "      <td>2021-08-05</td>\n",
              "      <td>[]</td>\n",
              "      <td>El que se llama la. El que se llama la. El qu...</td>\n",
              "      <td>38</td>\n",
              "      <td>https://www.youtube.com/watch?v=OVe1GzubDP8</td>\n",
              "      <td>[-0.057171739637851715, -0.005716548301279545,...</td>\n",
              "      <td>[[tensor(0.6085)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1872</th>\n",
              "      <td>335.00</td>\n",
              "      <td>617.00</td>\n",
              "      <td>Rafael Carrascosa - Software engineering for m...</td>\n",
              "      <td>503</td>\n",
              "      <td>2021-08-05</td>\n",
              "      <td>[]</td>\n",
              "      <td>Para planificar y estimar un proyecto que tie...</td>\n",
              "      <td>62</td>\n",
              "      <td>https://www.youtube.com/watch?v=OVe1GzubDP8</td>\n",
              "      <td>[-0.04295634850859642, 0.01834726333618164, 0....</td>\n",
              "      <td>[[tensor(0.5897)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>326.20</td>\n",
              "      <td>367.00</td>\n",
              "      <td>Sebastián Arango - Enhancing Data Privacy thro...</td>\n",
              "      <td>208</td>\n",
              "      <td>2020-03-06</td>\n",
              "      <td>[]</td>\n",
              "      <td>haga posible identificar al usuario esté tota...</td>\n",
              "      <td>54</td>\n",
              "      <td>https://www.youtube.com/watch?v=mEPw36JE_8w</td>\n",
              "      <td>[-0.03910747542977333, -0.0779929831624031, -0...</td>\n",
              "      <td>[[tensor(0.5723)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>800.20</td>\n",
              "      <td>817.00</td>\n",
              "      <td>Sebastián Arango - Enhancing Data Privacy thro...</td>\n",
              "      <td>208</td>\n",
              "      <td>2020-03-06</td>\n",
              "      <td>[]</td>\n",
              "      <td>nuevo, Machine Learning.  De hecho, utiliza l...</td>\n",
              "      <td>141</td>\n",
              "      <td>https://www.youtube.com/watch?v=mEPw36JE_8w</td>\n",
              "      <td>[0.055914122611284256, -0.0326554998755455, -0...</td>\n",
              "      <td>[[tensor(0.5699)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1873</th>\n",
              "      <td>397.00</td>\n",
              "      <td>643.52</td>\n",
              "      <td>Rafael Carrascosa - Software engineering for m...</td>\n",
              "      <td>503</td>\n",
              "      <td>2021-08-05</td>\n",
              "      <td>[]</td>\n",
              "      <td>El primero es la herramienta de factibilidad ...</td>\n",
              "      <td>65</td>\n",
              "      <td>https://www.youtube.com/watch?v=OVe1GzubDP8</td>\n",
              "      <td>[-0.01800951361656189, 0.038617558777332306, -...</td>\n",
              "      <td>[[tensor(0.5664)]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1886</th>\n",
              "      <td>253.56</td>\n",
              "      <td>304.12</td>\n",
              "      <td>Interview Rodolfo Edelmann &amp; Carlos de la Torr...</td>\n",
              "      <td>274</td>\n",
              "      <td>2020-04-21</td>\n",
              "      <td>[]</td>\n",
              "      <td>lo que es el Machine Learning en la organizac...</td>\n",
              "      <td>18</td>\n",
              "      <td>https://www.youtube.com/watch?v=IvKQkp2CYqs</td>\n",
              "      <td>[0.04165314510464668, -0.005298386327922344, -...</td>\n",
              "      <td>[[tensor(0.5547)]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c40f1ec3-a274-478b-91fb-be800c25ccb1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c40f1ec3-a274-478b-91fb-be800c25ccb1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c40f1ec3-a274-478b-91fb-be800c25ccb1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "\n",
        "client = chromadb.Client()\n",
        "collection = client.create_collection(\"pycon\") # Se le puede dar la ruta de un storage"
      ],
      "metadata": {
        "id": "GAbazvxyVvVM"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_overlap[\"id_database\"] = df_overlap.apply(lambda x: str(hash(x[\"title\"])) + \"-\" + str(x[\"id\"]), axis=1)"
      ],
      "metadata": {
        "id": "mFkLqX9UXnDC"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection.add(\n",
        "    ids=df_overlap[\"id_database\"].tolist(),\n",
        "    embeddings=df_overlap[\"embeddings\"].tolist(),\n",
        "    metadatas= df_overlap[[\"start\", \"end\", \"text\", \"views\", \"publish_date\", \"url\", \"title\"]].to_dict(\"records\")\n",
        ")"
      ],
      "metadata": {
        "id": "Kh9L1_6FX_Gt"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content = collection.query(\n",
        "    query_texts = [\"data visualization\", \"inteligencia artificial\"], # By Default use sentence transformers\n",
        "    n_results = 5\n",
        "    )\n",
        "\n",
        "\n",
        "# chromadb: https://docs.trychroma.com/embeddings"
      ],
      "metadata": {
        "id": "FmIfM1FwYiRh"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content['metadatas'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh3kRJ2gZZ6h",
        "outputId": "4891a796-4a4e-4ede-c34d-07c4eb23e63c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'start': 89.04,\n",
              "  'end': 109.32,\n",
              "  'text': ' Ahora en Mercado Libre estamos, como hizo Rudy,  armando la infraestructura para ejecutar Machine Learning en  producción y a escala.  Bueno, queremos entonces contarles un poquito de qué va  a ser la charla.  Primero que todos, para entender el motivo de la charla,',\n",
              "  'views': 503,\n",
              "  'publish_date': '2020-04-20',\n",
              "  'url': 'https://www.youtube.com/watch?v=N3czkxo2JJw',\n",
              "  'title': 'Rodolfo Edelmann & Carlos de la Torre - Conectando microservicios con Python'},\n",
              " {'start': 2504.84,\n",
              "  'end': 2599.3,\n",
              "  'text': \" their job is to observe and question, right? Like science is mostly about theory and asking why and how can we do this? Computer scientists especially, like right now, there's computer scientists around the world working on some incredible problems that will affect you in about 15 to 20 years. Like they're doing amazing research into type systems, into algorithms, into P  equals NP, into proofs, and all sorts of other things I don't even know about. AI is where,  obviously, machine learning is where these two meet very strongly. And it's an amazing  piece and a lot of their work is fantastically important as they're analysing. Engineers  are much more practical. Engineers take problems, they build solutions, they invent the solutions. I bet you that every single large project ever has someone who's gone, I'll just hammer it in. They've just got on engines to make sure they work fine. It looks really hacky, but it's perfectly fine. That stuff's rated for like a good 20 or 30 flights. It's a case of understanding when to do things a quick way and when to do things the slow way and the correct way. Part of this is like all software we write has consequences. You may not think about it like, you know,  you're not putting up writing software for self-driving cars or that does money transactions or that handles people's like, you know,\",\n",
              "  'views': 587,\n",
              "  'publish_date': '2020-02-19',\n",
              "  'url': 'https://www.youtube.com/watch?v=862xL6jm_PQ',\n",
              "  'title': 'Andrew Godwin - Keynote - PyCon Colombia 2020'},\n",
              " {'start': 868.28,\n",
              "  'end': 909.0,\n",
              "  'text': ' O sea, es un centralizador y es el centralizador.  Lo que hago es, o sea, le mando los datos,  que aquí están representados también como matrices X.  Y entonces, en el centralizador hago yo todo lo que es la  inteligencia, cierto?  Si quiero hacer un modelo, si quiero simplemente hacer BI, etcétera, pero todo pasa en un nodo central.',\n",
              "  'views': 208,\n",
              "  'publish_date': '2020-03-06',\n",
              "  'url': 'https://www.youtube.com/watch?v=mEPw36JE_8w',\n",
              "  'title': 'Sebastián Arango - Enhancing Data Privacy through Federated (Machine) Learning - Pycon Colombia 2020'},\n",
              " {'start': 120.68,\n",
              "  'end': 180.72,\n",
              "  'text': \" appreciate. And also automation gives us a very repeatable and predictable way to perform actions on these servers. If we were to do these things manually, it would be hard to do it exactly the same way every time, right? So it would also not scale, because we have a limited number of engineers, and we have a very large number of servers, and that keeps growing every time. So, we have a very large number of engineers, and we have a very large number of servers, and that keeps growing every time. So, we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number of engineers, and we have a very large number also not scale because we have a limited number of  engineers and we have a very large number of servers and that keeps growing every time.  So using automation, which effectively means writing code to do things on the infrastructure,  also fits in well with everything else we do because if we're writing code for managing  our servers, we can use the same tools that  we normally use for doing other type of development. So that means that we can also use the same\",\n",
              "  'views': 152,\n",
              "  'publish_date': '2018-12-26',\n",
              "  'url': 'https://www.youtube.com/watch?v=5rgZQw0F0w0',\n",
              "  'title': 'Navid Shelkhol - FBJE is a framework used at Facebook for developing workflows in Python'},\n",
              " {'start': 221.56,\n",
              "  'end': 277.52,\n",
              "  'text': ' Métricas.  Mercado libre nosotros separamos las métricas en estas categorías que están acá y somos muy religiosos al respecto. Nosotros decimos que el éxito del sistema es mover un KPI. Y al mismo tiempo sabemos que el trabajo del Machine Learning Engineer es mover el Outrock o alguna otra métrica muy cercana al modelo. Entonces, qué conecta al Outrock de un ingeniero con el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe el KPI de negocio? Cómo sabe conecta al outrock de un ingeniero con el KPI de  negocio? ¿Cómo sabemos que si el outrock mejora, el KPI mejora? Para sistematizar esa respuesta y todas  las inversiones de ingeniería que uno hace en un proyecto, tenemos, están estos cuatro bloques de  métrica donde esperamos que una, una bloque sea  proxy del otro. Es decir, si uno mejora, el otro mejora. Entonces, esperamos que las métricas de',\n",
              "  'views': 503,\n",
              "  'publish_date': '2021-08-05',\n",
              "  'url': 'https://www.youtube.com/watch?v=OVe1GzubDP8',\n",
              "  'title': 'Rafael Carrascosa - Software engineering for machine learning at Mercado Libre'}]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a0ZrycztZh6E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}